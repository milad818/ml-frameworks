{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## What is Transfer Learning?"
      ],
      "metadata": {
        "id": "Y1D6Xu0JAQ-g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transfer Learning** is a deep learning technique where a pre-trained model (trained on a large dataset) is fine-tuned or adapted to a new task, usually with a smaller dataset. This significantly reduces training time, computational cost, and data requirements while improving performance."
      ],
      "metadata": {
        "id": "JR4vWX0iAm3d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we apply transfer learning, we typically freeze the early layers of a pre-trained model and only fine-tune the later layers or add a custom classifier.\n",
        "\n",
        "1. Pre-Trained Feature Extractor:\n",
        "\n",
        "The lower layers of a CNN (for vision tasks) or Transformer (for NLP tasks) extract generic low-level features such as edges, textures, or general patterns.\n",
        "These features are universal across many datasets and do not need to be retrained.\n",
        "\n",
        "2. Freezing Lower Layers:\n",
        "\n",
        "Since early layers capture general features, they remain frozen to retain learned representations.\n",
        "Freezing prevents unnecessary weight updates, allowing the model to leverage prior knowledge.\n",
        "\n",
        "3. Fine-Tuning Higher Layers:\n",
        "\n",
        "The deeper layers of the model are task-specific and need fine-tuning to adapt to new data.\n",
        "These layers learn complex, high-level features such as object parts, shapes, or specific language patterns.\n",
        "\n",
        "4. Adding a Custom Classifier:\n",
        "\n",
        "The final fully connected layers are often replaced with a new classifier tailored for the target task.\n",
        "This part of the model is trained from scratch while leveraging extracted features."
      ],
      "metadata": {
        "id": "pL0q8PGgA956"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE!** Transfer learning helps you get reliable results with less data."
      ],
      "metadata": {
        "id": "ZVOk3zaXC8mp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's firstly check the processor info."
      ],
      "metadata": {
        "id": "RKRhl1eNDOaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU or CPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOeu9zqhAnjX",
        "outputId": "57f3c16a-93f8-48d8-e461-1e9f16c07170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Sep  7 14:18:31 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paho0o!**\n",
        "Apprently, we're not on GPU for now.\n",
        "\n",
        "No worries, we will take care of it as soon as GPU is needed."
      ],
      "metadata": {
        "id": "latXFjF9CKjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let us install the necessary tools and packages."
      ],
      "metadata": {
        "id": "mE0c5BkJIjO2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE!** At the time when I was authoring this notebook, I came across an issue while fitting the model where it kept raising the error below:\n",
        "```\n",
        "ValueError: Only instances of `keras.Layer` can be added to a Sequential model. Received: <tensorflow_hub.keras_layer.KerasLayer object at 0x78180cf9a7d0> (of type <class 'tensorflow_hub.keras_layer.KerasLayer'>)\n",
        "```\n",
        "Hence, it would be a good practice to install and try an older version of tensorflow (`tensorflow==2.15.0`) and keras (`keras==2.15.0`) just in case you face the same problem. Otherwise, why not keep up with the latest versions (This doesn't work any longer, but you can give it a try to see it for yourself)."
      ],
      "metadata": {
        "id": "Fa0s_FkZTrtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U tensorflow_hub\n",
        "# !pip install tensorflow==2.15.0 tensorflow-hub keras==2.15.0"
      ],
      "metadata": {
        "id": "qMpVSOSJDWH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall -y keras keras-nlp keras-cv\n",
        "# !pip install -U \"tensorflow==2.15.*\" tensorflow-hub==0.16.1\n",
        "# !pip install -U \"tensorflow==2.16.*\" tensorflow-hub==0.16.1"
      ],
      "metadata": {
        "id": "rbDZqVasYcyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip list"
      ],
      "metadata": {
        "id": "kQgbTqp9YxAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation"
      ],
      "metadata": {
        "id": "EmiYZuOnK5Zm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is clear that we will need a load of data to implement our model. So let's download one provided by [Daniel Bourke](https://www.mrdbourke.com/) (Food Classes). By the way, the whole document is inspired by his work."
      ],
      "metadata": {
        "id": "-cXLTKVTDjB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Download data\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "# Unzip the file\n",
        "zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\", \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6Cpk98yB864",
        "outputId": "a23db408-a95d-4035-d075-fbdf7636b253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-07 14:18:31--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.98.207, 74.125.135.207, 74.125.142.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.98.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M   221MB/s    in 0.7s    \n",
            "\n",
            "2025-09-07 14:18:32 (221 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# explore the data\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzLnkfQtETpZ",
        "outputId": "bb624a39-92f8-442b-c2db-3dffae301d1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in '10_food_classes_10_percent'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/train'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/test'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our data is composed of 10 classes, that is, 10 different types of food."
      ],
      "metadata": {
        "id": "KQ54rRNMFfKV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to be able to load our images we will have to `ImageDataGenerator()`. `ImageDataGenerator()` is a class in Keras (part of TensorFlow) that allows real-time data augmentation and efficient loading of images during model training. It is mainly used to:\n",
        "\n",
        "- **Augment images** (apply transformations like rotation, flipping, scaling, etc.).\n",
        "- **Normalize pixel values** (rescale intensity to a certain range).\n",
        "- **Load images in batches** (useful for handling large datasets without loading everything into memory at once)."
      ],
      "metadata": {
        "id": "1d31XQXIFzrn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How Does It Work?** When you create an ImageDataGenerator object, you specify the transformations you want to apply to your images. Then, you generate augmented batches from the dataset using `.flow()` or `.flow_from_directory()`."
      ],
      "metadata": {
        "id": "NWi3fmXCJXgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# import tensorflow as tf\n",
        "\n",
        "IMAGE_SHAPE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dir = \"10_food_classes_10_percent/train/\"\n",
        "test_dir = \"10_food_classes_10_percent/test/\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size=IMAGE_SHAPE,\n",
        "                                               batch_size=BATCH_SIZE,\n",
        "                                               class_mode=\"categorical\")\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size=IMAGE_SHAPE,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             class_mode=\"categorical\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH_-PaQBFbDM",
        "outputId": "d588c481-ef94-4595-fefb-ae59611b9882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 images belonging to 10 classes.\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TensorBoard Callback\n",
        "**TensorBoard** is a visualization tool that helps monitor and debug deep learning models by tracking metrics like loss, accuracy, gradients, histograms, and more during training. A **TensorBoard Callback** is a function in deep learning frameworks (like TensorFlow/Keras) that automatically logs this data while training a model."
      ],
      "metadata": {
        "id": "Rfh6Z2eKMi_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "import datetime"
      ],
      "metadata": {
        "id": "zPJJlEt0O6JG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function to create tensorboard callback\n",
        "# log name pattern: [dir_name]/[experiment_name]/[current_timestamp]\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback"
      ],
      "metadata": {
        "id": "55wLoZ0LIaK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Models using TensorFlow Hub"
      ],
      "metadata": {
        "id": "G8-ejhv9QeZr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TensorFlow Hub** is a repository of pre-trained machine learning models (e.g., ResNetV2, EfficientNet, etc.) that can be reused for various tasks like image classification, text embedding, object detection, and more. It provides a way to easily download, fine-tune, or use models without training from scratch."
      ],
      "metadata": {
        "id": "9lIWBnt-QukQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comparison with Other Model Hubs:"
      ],
      "metadata": {
        "id": "L14pnZRkR1XL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Feature        | TensorFlow Hub         | Hugging Face Model Hub | PyTorch Hub  |\n",
        "|:---------------|:------------------------|:------------------------|:-------------|\n",
        "| **Library**   | TensorFlow/Keras        | Mainly PyTorch (some TensorFlow) | PyTorch |\n",
        "| **Models**    | Vision, NLP, Generative, Speech | NLP, Vision, Multimodal | Vision, NLP |\n",
        "| **Fine-tuning** | Supported              | Highly supported       | Supported |\n",
        "| **Ease of Use** | Very easy              | Very easy              | Easy |\n"
      ],
      "metadata": {
        "id": "oJt3nsQbR3tL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Different Approaches for Transfer Learning"
      ],
      "metadata": {
        "id": "p9t_P0vRVi7n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer learning is a technique where a pre-trained model is adapted to a new task. Depending on how much of the pre-trained model is reused or fine-tuned, transfer learning can be implemented in different ways:"
      ],
      "metadata": {
        "id": "tTATu-AzV2yt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Feature Extraction (Frozen Pre-Trained Model)**\n",
        "\n",
        "Implementation:\n",
        "- Use a pre-trained model as a fixed feature extractor.\n",
        "- Freeze the convolutional (or encoder) layers so they retain learned features.\n",
        "- Replace the fully connected (FC) layers with a new classifier suited for the new task.\n",
        "- Train only the new classifier layers."
      ],
      "metadata": {
        "id": "6dIs5n5GV9qh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Fine-Tuning (Partial Transfer Learning)\n",
        "Implementation:**\n",
        "\n",
        "- Use a pre-trained model and fine-tune some of its layers.\n",
        "- Freeze the initial layers (low-level features) but allow later layers to update.\n",
        "- Fine-tune with a lower learning rate to prevent catastrophic forgetting."
      ],
      "metadata": {
        "id": "gfYJmVdPWSdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub"
      ],
      "metadata": {
        "id": "HCsKGLfYatUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TF:\", tf.__version__)\n",
        "print(\"Hub:\", hub.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6UOA_dKYuFO",
        "outputId": "28485ec6-30ad-4443-e337-ffa050e75566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF: 2.19.0\n",
            "Hub: 0.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resnet 50\n",
        "resnet50v1_url = \"https://www.kaggle.com/models/tensorflow/resnet-50/TensorFlow2/feature-vector/1\"\n",
        "\n",
        "# Resnet 50 V2 feature vector\n",
        "resnet50v2_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n",
        "\n",
        "# EfficientNetB0 feature vector (version 1)\n",
        "efficientnetb0_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\"\n",
        "\n",
        "# EfficientNetB0 feature vector (version 2 NEW)\n",
        "# efficientnet_url = \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2\""
      ],
      "metadata": {
        "id": "9dRtNPIzYJqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Model"
      ],
      "metadata": {
        "id": "sWuUMoaS-GJh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can create the models separately or define a function for it saving a good deal of unnecessary code.\n",
        "\n",
        "On approach could be as presented below, which is not really recommended. It used to work fine, but then later some incompatibilities were noticed when creating the model."
      ],
      "metadata": {
        "id": "vehdjy3I-IrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # define a function to create model\n",
        "# def create_model(model_url, num_classes=10):\n",
        "#   \"\"\"\n",
        "#   Takes a TensorFlow Hub URL and creates a Keras Sequential model\n",
        "#   Args:\n",
        "#     model_url (str): A TensorFlow Hub feature extraction URL\n",
        "#     num_classes (int): Number of output neurons in the output layer\n",
        "#     equal to number of target classes, default 10\n",
        "#   Returns:\n",
        "#     An uncompiled Keras Sequential model\n",
        "#   \"\"\"\n",
        "\n",
        "#   # Download the pretrained model and store it as keras layer\n",
        "#   feature_extractor_layer = hub.KerasLayer(model_url,\n",
        "#                                            trainable=False, # freeze the underlying patterns\n",
        "#                                            name='feature_extraction_layer',\n",
        "#                                            input_shape=IMAGE_SHAPE+(3,))\n",
        "\n",
        "#   # JUST IN CASE!\n",
        "#   # hub_layer_wrapper = tf.keras.layers.Lambda(lambda x: feature_extractor_layer(x))\n",
        "\n",
        "#   # Create the model\n",
        "#   model = tf.keras.Sequential([\n",
        "#     # hub_layer_wrapper,\n",
        "#     feature_extractor_layer,\n",
        "#     layers.Dense(num_classes, activation='softmax', name='output_layer')\n",
        "#   ])\n",
        "\n",
        "#   return model"
      ],
      "metadata": {
        "id": "3od9LAgX2KbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second would be using a wrapper to tell the standalone Keras 3 to use the TensorFlow backend."
      ],
      "metadata": {
        "id": "-W9AbJ92gzKs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANT NOTE**: In case you want to use `HubWrapper` to create the model (which is recommended), apply the configuration change below. It tells standalone Keras 3 to use the TensorFlow backend. Without it, Keras might default (or be configured) to another backend (e.g. JAX or Torch), and TensorFlow Hub’s KerasLayer requires TensorFlow ops, so this forces compatibility."
      ],
      "metadata": {
        "id": "rw6A3Llbe-x1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ensure TensorFlow backend\n",
        "keras.config.set_backend(\"tensorflow\")"
      ],
      "metadata": {
        "id": "pDLRFs0we7yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HubWrapper(keras.layers.Layer):\n",
        "    def __init__(self, handle, trainable=False, **kwargs):\n",
        "        super().__init__()\n",
        "        self._inner = hub.KerasLayer(handle, trainable=trainable)\n",
        "    def call(self, inputs):\n",
        "        return self._inner(inputs)\n",
        "\n",
        "def create_model(model_url, num_classes=10):\n",
        "    feature_extractor = HubWrapper(model_url, trainable=False, name=\"feature_extraction_layer\")\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.InputLayer(input_shape=IMAGE_SHAPE + (3,)),\n",
        "        feature_extractor,\n",
        "        keras.layers.Dense(num_classes, activation=\"softmax\", name=\"output_layer\")\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "ugrixTycZ_ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "resnet_model = create_model(resnet50v1_url, num_classes=train_data.num_classes)"
      ],
      "metadata": {
        "id": "z8UVDqgT2OgE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b4c6d38-5d9c-42ec-be36-7cc7b2653480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is created now; however, there will be a few more step afterwards. Let's carry on and see what they are..."
      ],
      "metadata": {
        "id": "iY6blZSfHoSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile\n",
        "resnet_model.compile(loss='categorical_crossentropy',\n",
        "                     optimizer=tf.keras.optimizers.Adam(),\n",
        "                     metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "oXVAUR7SFWta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model\n",
        "resnet_history = resnet_model.fit(train_data,\n",
        "                                  epochs=5,\n",
        "                                  steps_per_epoch=len(train_data),\n",
        "                                  validation_data=test_data,\n",
        "                                  validation_steps=len(test_data),\n",
        "                                  batch_size=16,\n",
        "                                  callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub_dir\",\n",
        "                                                                         experiment_name=\"tensorflow_exp_resnet50V1\")])"
      ],
      "metadata": {
        "id": "CGbtTBW3T_Q5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7613b8a-9c09-4e90-f47f-3d3d6dfaf789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: tensorflow_hub_dir/tensorflow_exp_resnet50V1/20250907-141854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m16/24\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m12:06\u001b[0m 91s/step - accuracy: 0.1445 - loss: 2.5940"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results indicate that using `ResNet-50-v1` as a feature extractor (with frozen convolutional layers and only training the classifier) is effective even with just 5 epochs. Here's what we can infer:\n",
        "\n",
        "1. **Rapid Performance Improvement**\n",
        "\n",
        "The training accuracy jumped from 34.13% to 93.60%, and the validation accuracy improved from 68.32% to 82.48% in just 5 epochs and with only 10 percent of the training images.\n",
        "\n",
        "*This suggests that the model is leveraging the pre-trained feature representations well.*\n",
        "\n",
        "2. **Loss Decreasing Steadily**\n",
        "\n",
        "The training loss dropped from 1.9170 to 0.3349, and the validation loss decreased from 1.0706 to 0.5614.\n",
        "\n",
        "*A consistent decrease in loss without a sharp divergence between training and validation suggests that the model is generalizing well so far.*\n",
        "\n",
        "3. **No Signs of Severe Overfitting Yet**\n",
        "\n",
        "The validation accuracy is still improving, and there isn’t a major gap between training accuracy (93.6%) and validation accuracy (82.48%).\n",
        "\n",
        "**However**,\n",
        "\n",
        "*if training continues, the model might start overfitting, as the training accuracy is already very high.*\n",
        "\n",
        "4. **Validation Accuracy Plateauing?**\n",
        "\n",
        "The rate of improvement in validation accuracy is slowing down (from 79.88% → 81.64% → 82.48%).\n",
        "\n",
        "*This suggests that further improvements might require fine-tuning the deeper layers of ResNet-50 rather than just using it as a frozen feature extractor.*"
      ],
      "metadata": {
        "id": "FUsLaukv6nvJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next steps for optimization could be...\n",
        "\n",
        "* Fine-tuning some layers of ResNet-50: Instead of keeping all convolutional layers frozen, unfreeze the later layers for further training.\n",
        "\n",
        "* Data augmentation: If the dataset is small, applying transformations can help generalization.\n",
        "\n",
        "* Hyperparameter tuning: Adjusting learning rates, optimizers, or adding dropout can improve performance.\n",
        "\n",
        "Overall, these results show that transfer learning with feature extraction is effective, but fine-tuning could push the model further! 🚀"
      ],
      "metadata": {
        "id": "r1-ujmto_Dh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us plot loss and accuracy curves and make our results more comprehensibel, visualizing the results."
      ],
      "metadata": {
        "id": "lhaOqlEV_yMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the results through pyplot\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_acc_curves(hiistory):\n",
        "  # Assuming you have resnet_history from your model training\n",
        "  # Access the training and validation accuracy and loss from resnet_history.history\n",
        "\n",
        "  acc = resnet_history.history['accuracy']\n",
        "  val_acc = resnet_history.history['val_accuracy']\n",
        "\n",
        "  loss = resnet_history.history['loss']\n",
        "  val_loss = resnet_history.history['val_loss']\n",
        "\n",
        "  epochs = range(len(acc))\n",
        "\n",
        "  # Plot training and validation accuracy per epoch\n",
        "  plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "  plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.legend(loc=0)\n",
        "  plt.figure()\n",
        "\n",
        "  # Plot training and validation loss per epoch\n",
        "  plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "  plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.legend(loc=0)\n",
        "  plt.figure()\n",
        "\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "VRfYBOKlIYC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_acc_curves(resnet_history)"
      ],
      "metadata": {
        "id": "oxi15aV0-mWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Summary\n",
        "resnet_model.summary()"
      ],
      "metadata": {
        "id": "rGqRrs-HAJ1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now it is time to do the same with the other two models `ResNet-50-v2` and `EfficientNetB0` and compare their results."
      ],
      "metadata": {
        "id": "pkOY0okHAfHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model via EfficientNetB0\n",
        "efficientnet_model = create_model(resnet50v2_url,\n",
        "                                  num_classes=train_data.num_classes)\n",
        "\n",
        "# Compile the model\n",
        "efficientnet_model.compile(loss='categorical_crossentropy',\n",
        "                           optimizer=tf.keras.optimizers.Adam(),\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "efficientnet_history = efficientnet_model.fit(train_data,\n",
        "                                              epochs=5,\n",
        "                                              steps_per_epoch=len(train_data),\n",
        "                                              validation_data=test_data,\n",
        "                                              validation_steps=len(test_data),\n",
        "                                              callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub_dir\",\n",
        "                                                                                     experiment_name=\"tensorflow_exp_resnet50V2\")])\n",
        "                                            )"
      ],
      "metadata": {
        "id": "gwxbn-_eAT58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There other main transfer learning approach to fine-tune models (Fine-tuning transfer learning ) is presented in the following notebook (`04_tf_transfer_learning_fine-tuning.ipynb`)."
      ],
      "metadata": {
        "id": "RrliNSrTmeNd"
      }
    }
  ]
}