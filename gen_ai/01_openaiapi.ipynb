{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7f178733-7143-445e-8fdf-ea8ba55b8419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cc1854-3b74-487b-b5dd-4a2c140d3df2",
   "metadata": {},
   "source": [
    "#### What is OpenAI API?\n",
    "\n",
    "OpenAI’s API enables users to leverage the power of their AI models, but what exactly does that mean? Put plainly, the API allows you to send requests to OpenAI’s models and receive information in return.\n",
    "\n",
    "This is really the function of any API, but this article is specific to OpenAI’s REST API. The models that you can currently access with OpenAI’s API are GPT, DALL-E, and Whisper, a speech recognition model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d555a0-fe0c-4e8a-b3dc-98a1c2179e5c",
   "metadata": {},
   "source": [
    "#### What is OpenAI API used for?\n",
    "\n",
    "OpenAI API (Application Programming Interface) serves as a bridge to OpenAI's powerful machine learning models, allowing you to integrate cutting-edge AI capabilities into your projects with relative ease. In simpler terms, the API is like a helper that lets you use OpenAI's smart programs in your projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1e95b574-0815-4a3b-840d-afc9bd660403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate API Key\n",
    "my_openaiapi_key = \"Add your own key here!\"\n",
    "openai.api_key = my_openaiapi_key\n",
    "models = openai.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5b6dd6cb-731f-4216-a4ed-beb5daa581ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created</th>\n",
       "      <th>object</th>\n",
       "      <th>owned_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(id, gpt-4o-audio-preview-2024-10-01)</td>\n",
       "      <td>(created, 1727389042)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(id, gpt-4o-mini-audio-preview)</td>\n",
       "      <td>(created, 1734387424)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(id, gpt-4o-realtime-preview)</td>\n",
       "      <td>(created, 1727659998)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(id, gpt-4o-mini-audio-preview-2024-12-17)</td>\n",
       "      <td>(created, 1734115920)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(id, gpt-4o-mini-realtime-preview)</td>\n",
       "      <td>(created, 1734387380)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(id, dall-e-2)</td>\n",
       "      <td>(created, 1698798177)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(id, o1-preview-2024-09-12)</td>\n",
       "      <td>(created, 1725648865)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(id, gpt-4o-mini)</td>\n",
       "      <td>(created, 1721172741)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(id, gpt-4-1106-preview)</td>\n",
       "      <td>(created, 1698957206)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(id, gpt-4o-mini-2024-07-18)</td>\n",
       "      <td>(created, 1721172717)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(id, gpt-3.5-turbo)</td>\n",
       "      <td>(created, 1677610602)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(id, gpt-3.5-turbo-0125)</td>\n",
       "      <td>(created, 1706048358)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(id, gpt-3.5-turbo-instruct)</td>\n",
       "      <td>(created, 1692901427)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(id, gpt-4-0613)</td>\n",
       "      <td>(created, 1686588896)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(id, babbage-002)</td>\n",
       "      <td>(created, 1692634615)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(id, o1-mini)</td>\n",
       "      <td>(created, 1725649008)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(id, gpt-4o-2024-08-06)</td>\n",
       "      <td>(created, 1722814719)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(id, o1-mini-2024-09-12)</td>\n",
       "      <td>(created, 1725648979)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(id, whisper-1)</td>\n",
       "      <td>(created, 1677532384)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(id, gpt-4o)</td>\n",
       "      <td>(created, 1715367049)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(id, dall-e-3)</td>\n",
       "      <td>(created, 1698785189)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(id, gpt-3.5-turbo-16k)</td>\n",
       "      <td>(created, 1683758102)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(id, gpt-4o-realtime-preview-2024-10-01)</td>\n",
       "      <td>(created, 1727131766)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(id, omni-moderation-latest)</td>\n",
       "      <td>(created, 1731689265)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(id, omni-moderation-2024-09-26)</td>\n",
       "      <td>(created, 1732734466)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(id, tts-1-hd-1106)</td>\n",
       "      <td>(created, 1699053533)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(id, o1-preview)</td>\n",
       "      <td>(created, 1725648897)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(id, gpt-4)</td>\n",
       "      <td>(created, 1687882411)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(id, chatgpt-4o-latest)</td>\n",
       "      <td>(created, 1723515131)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(id, tts-1-hd)</td>\n",
       "      <td>(created, 1699046015)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(id, davinci-002)</td>\n",
       "      <td>(created, 1692634301)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(id, text-embedding-ada-002)</td>\n",
       "      <td>(created, 1671217299)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(id, gpt-4-turbo-2024-04-09)</td>\n",
       "      <td>(created, 1712601677)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(id, gpt-4-turbo)</td>\n",
       "      <td>(created, 1712361441)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(id, tts-1)</td>\n",
       "      <td>(created, 1681940951)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(id, tts-1-1106)</td>\n",
       "      <td>(created, 1699053241)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>(id, gpt-3.5-turbo-instruct-0914)</td>\n",
       "      <td>(created, 1694122472)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>(id, gpt-4-turbo-preview)</td>\n",
       "      <td>(created, 1706037777)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>(id, gpt-4o-mini-realtime-preview-2024-12-17)</td>\n",
       "      <td>(created, 1734112601)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>(id, gpt-4o-audio-preview)</td>\n",
       "      <td>(created, 1727460443)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>(id, gpt-4o-2024-05-13)</td>\n",
       "      <td>(created, 1715368132)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>(id, text-embedding-3-small)</td>\n",
       "      <td>(created, 1705948997)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>(id, gpt-4o-2024-11-20)</td>\n",
       "      <td>(created, 1731975040)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>(id, gpt-4o-audio-preview-2024-12-17)</td>\n",
       "      <td>(created, 1734034239)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>(id, gpt-4o-realtime-preview-2024-12-17)</td>\n",
       "      <td>(created, 1733945430)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>(id, gpt-3.5-turbo-1106)</td>\n",
       "      <td>(created, 1698959748)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>(id, text-embedding-3-large)</td>\n",
       "      <td>(created, 1705953180)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>(id, gpt-4-0125-preview)</td>\n",
       "      <td>(created, 1706037612)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               id                created  \\\n",
       "0           (id, gpt-4o-audio-preview-2024-10-01)  (created, 1727389042)   \n",
       "1                 (id, gpt-4o-mini-audio-preview)  (created, 1734387424)   \n",
       "2                   (id, gpt-4o-realtime-preview)  (created, 1727659998)   \n",
       "3      (id, gpt-4o-mini-audio-preview-2024-12-17)  (created, 1734115920)   \n",
       "4              (id, gpt-4o-mini-realtime-preview)  (created, 1734387380)   \n",
       "5                                  (id, dall-e-2)  (created, 1698798177)   \n",
       "6                     (id, o1-preview-2024-09-12)  (created, 1725648865)   \n",
       "7                               (id, gpt-4o-mini)  (created, 1721172741)   \n",
       "8                        (id, gpt-4-1106-preview)  (created, 1698957206)   \n",
       "9                    (id, gpt-4o-mini-2024-07-18)  (created, 1721172717)   \n",
       "10                            (id, gpt-3.5-turbo)  (created, 1677610602)   \n",
       "11                       (id, gpt-3.5-turbo-0125)  (created, 1706048358)   \n",
       "12                   (id, gpt-3.5-turbo-instruct)  (created, 1692901427)   \n",
       "13                               (id, gpt-4-0613)  (created, 1686588896)   \n",
       "14                              (id, babbage-002)  (created, 1692634615)   \n",
       "15                                  (id, o1-mini)  (created, 1725649008)   \n",
       "16                        (id, gpt-4o-2024-08-06)  (created, 1722814719)   \n",
       "17                       (id, o1-mini-2024-09-12)  (created, 1725648979)   \n",
       "18                                (id, whisper-1)  (created, 1677532384)   \n",
       "19                                   (id, gpt-4o)  (created, 1715367049)   \n",
       "20                                 (id, dall-e-3)  (created, 1698785189)   \n",
       "21                        (id, gpt-3.5-turbo-16k)  (created, 1683758102)   \n",
       "22       (id, gpt-4o-realtime-preview-2024-10-01)  (created, 1727131766)   \n",
       "23                   (id, omni-moderation-latest)  (created, 1731689265)   \n",
       "24               (id, omni-moderation-2024-09-26)  (created, 1732734466)   \n",
       "25                            (id, tts-1-hd-1106)  (created, 1699053533)   \n",
       "26                               (id, o1-preview)  (created, 1725648897)   \n",
       "27                                    (id, gpt-4)  (created, 1687882411)   \n",
       "28                        (id, chatgpt-4o-latest)  (created, 1723515131)   \n",
       "29                                 (id, tts-1-hd)  (created, 1699046015)   \n",
       "30                              (id, davinci-002)  (created, 1692634301)   \n",
       "31                   (id, text-embedding-ada-002)  (created, 1671217299)   \n",
       "32                   (id, gpt-4-turbo-2024-04-09)  (created, 1712601677)   \n",
       "33                              (id, gpt-4-turbo)  (created, 1712361441)   \n",
       "34                                    (id, tts-1)  (created, 1681940951)   \n",
       "35                               (id, tts-1-1106)  (created, 1699053241)   \n",
       "36              (id, gpt-3.5-turbo-instruct-0914)  (created, 1694122472)   \n",
       "37                      (id, gpt-4-turbo-preview)  (created, 1706037777)   \n",
       "38  (id, gpt-4o-mini-realtime-preview-2024-12-17)  (created, 1734112601)   \n",
       "39                     (id, gpt-4o-audio-preview)  (created, 1727460443)   \n",
       "40                        (id, gpt-4o-2024-05-13)  (created, 1715368132)   \n",
       "41                   (id, text-embedding-3-small)  (created, 1705948997)   \n",
       "42                        (id, gpt-4o-2024-11-20)  (created, 1731975040)   \n",
       "43          (id, gpt-4o-audio-preview-2024-12-17)  (created, 1734034239)   \n",
       "44       (id, gpt-4o-realtime-preview-2024-12-17)  (created, 1733945430)   \n",
       "45                       (id, gpt-3.5-turbo-1106)  (created, 1698959748)   \n",
       "46                   (id, text-embedding-3-large)  (created, 1705953180)   \n",
       "47                       (id, gpt-4-0125-preview)  (created, 1706037612)   \n",
       "\n",
       "             object                     owned_by  \n",
       "0   (object, model)           (owned_by, system)  \n",
       "1   (object, model)           (owned_by, system)  \n",
       "2   (object, model)           (owned_by, system)  \n",
       "3   (object, model)           (owned_by, system)  \n",
       "4   (object, model)           (owned_by, system)  \n",
       "5   (object, model)           (owned_by, system)  \n",
       "6   (object, model)           (owned_by, system)  \n",
       "7   (object, model)           (owned_by, system)  \n",
       "8   (object, model)           (owned_by, system)  \n",
       "9   (object, model)           (owned_by, system)  \n",
       "10  (object, model)           (owned_by, openai)  \n",
       "11  (object, model)           (owned_by, system)  \n",
       "12  (object, model)           (owned_by, system)  \n",
       "13  (object, model)           (owned_by, openai)  \n",
       "14  (object, model)           (owned_by, system)  \n",
       "15  (object, model)           (owned_by, system)  \n",
       "16  (object, model)           (owned_by, system)  \n",
       "17  (object, model)           (owned_by, system)  \n",
       "18  (object, model)  (owned_by, openai-internal)  \n",
       "19  (object, model)           (owned_by, system)  \n",
       "20  (object, model)           (owned_by, system)  \n",
       "21  (object, model)  (owned_by, openai-internal)  \n",
       "22  (object, model)           (owned_by, system)  \n",
       "23  (object, model)           (owned_by, system)  \n",
       "24  (object, model)           (owned_by, system)  \n",
       "25  (object, model)           (owned_by, system)  \n",
       "26  (object, model)           (owned_by, system)  \n",
       "27  (object, model)           (owned_by, openai)  \n",
       "28  (object, model)           (owned_by, system)  \n",
       "29  (object, model)           (owned_by, system)  \n",
       "30  (object, model)           (owned_by, system)  \n",
       "31  (object, model)  (owned_by, openai-internal)  \n",
       "32  (object, model)           (owned_by, system)  \n",
       "33  (object, model)           (owned_by, system)  \n",
       "34  (object, model)  (owned_by, openai-internal)  \n",
       "35  (object, model)           (owned_by, system)  \n",
       "36  (object, model)           (owned_by, system)  \n",
       "37  (object, model)           (owned_by, system)  \n",
       "38  (object, model)           (owned_by, system)  \n",
       "39  (object, model)           (owned_by, system)  \n",
       "40  (object, model)           (owned_by, system)  \n",
       "41  (object, model)           (owned_by, system)  \n",
       "42  (object, model)           (owned_by, system)  \n",
       "43  (object, model)           (owned_by, system)  \n",
       "44  (object, model)           (owned_by, system)  \n",
       "45  (object, model)           (owned_by, system)  \n",
       "46  (object, model)           (owned_by, system)  \n",
       "47  (object, model)           (owned_by, system)  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_list = list(models)\n",
    "models_df = pd.DataFrame(models, columns=[\"id\",\"created\",\"object\",\"owned_by\"])\n",
    "\n",
    "models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "94af96b2-7431-4d74-9c3f-8c310051c8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=my_openaiapi_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788de1bc-6486-4e48-b371-f17bbd4d5403",
   "metadata": {},
   "source": [
    "#### API Request: Use an HTTP client (like requests in Python) or OpenAI's official library to make a request. The request typically includes:\n",
    "\n",
    " - The API endpoint (https://api.openai.com/v1/completions or similar).\n",
    " - Headers, including the API key for authentication.\n",
    " - A JSON payload with parameters such as the model to use, the input prompt, and any configuration options (e.g., max_tokens, temperature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "50fe671a-ea62-4523-8c49-30284cf4cda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is Zero-shot approach implemented - no pre-fabricated answer is provided\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"How can I find a job?\"\n",
    "    }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f2c6129d-580b-448f-b3ae-ca6b855ee99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ChatCompletion(id='chatcmpl-AsvWTmHlzdER8GU4GY3tN6YOkzhS0', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"1. Update your resume and cover letter: Make sure your resume is up-to-date and highlights your skills and experience relevant to the job you are applying for. Tailor your cover letter to each job application to make a strong impression.\\n\\n2. Use job search websites: Websites like Indeed, Glassdoor, LinkedIn, and Monster are popular resources for finding job listings. Create a profile on these websites and set up job alerts to receive notifications for relevant job openings.\\n\\n3. Network: Reach out to your professional and personal contacts for job leads. Attend networking events, career fairs, and industry conferences to expand your network and learn about job opportunities.\\n\\n4. Contact companies directly: Research companies that you are interested in working for and reach out to their HR department or hiring manager to inquire about job openings. Even if they are not currently hiring, expressing your interest may lead to future job opportunities.\\n\\n5. Use social media: Utilize social media platforms like LinkedIn, Twitter, and Facebook to showcase your professional skills and network with potential employers. Join industry-specific groups and participate in online conversations to build connections and increase your visibility.\\n\\n6. Consider a recruitment agency: Recruitment agencies can help match you with job opportunities that align with your skills and goals. Submit your resume to reputable agencies that specialize in your industry or field of interest.\\n\\n7. Attend job fairs: Job fairs are a great way to meet with multiple employers in one place and learn about job opportunities in your field. Dress professionally, bring copies of your resume, and be prepared to talk about your skills and qualifications.\\n\\n8. Volunteer or intern: Consider volunteering or interning in your desired field to gain experience, build connections, and potentially lead to a job offer. Many organizations hire their interns or volunteers for full-time positions if they perform well.\\n\\n9. Stay persistent and positive: Job hunting can be a challenging process, but it's important to stay positive and motivated. Set goals, stay organized, and continue to search for opportunities that align with your career aspirations.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1737654193, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=406, prompt_tokens=14, total_tokens=420, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))),\n",
       " ChatCompletionMessage(content=\"1. Update your resume and cover letter: Make sure your resume is up-to-date and highlights your skills and experience relevant to the job you are applying for. Tailor your cover letter to each job application to make a strong impression.\\n\\n2. Use job search websites: Websites like Indeed, Glassdoor, LinkedIn, and Monster are popular resources for finding job listings. Create a profile on these websites and set up job alerts to receive notifications for relevant job openings.\\n\\n3. Network: Reach out to your professional and personal contacts for job leads. Attend networking events, career fairs, and industry conferences to expand your network and learn about job opportunities.\\n\\n4. Contact companies directly: Research companies that you are interested in working for and reach out to their HR department or hiring manager to inquire about job openings. Even if they are not currently hiring, expressing your interest may lead to future job opportunities.\\n\\n5. Use social media: Utilize social media platforms like LinkedIn, Twitter, and Facebook to showcase your professional skills and network with potential employers. Join industry-specific groups and participate in online conversations to build connections and increase your visibility.\\n\\n6. Consider a recruitment agency: Recruitment agencies can help match you with job opportunities that align with your skills and goals. Submit your resume to reputable agencies that specialize in your industry or field of interest.\\n\\n7. Attend job fairs: Job fairs are a great way to meet with multiple employers in one place and learn about job opportunities in your field. Dress professionally, bring copies of your resume, and be prepared to talk about your skills and qualifications.\\n\\n8. Volunteer or intern: Consider volunteering or interning in your desired field to gain experience, build connections, and potentially lead to a job offer. Many organizations hire their interns or volunteers for full-time positions if they perform well.\\n\\n9. Stay persistent and positive: Job hunting can be a challenging process, but it's important to stay positive and motivated. Set goals, stay organized, and continue to search for opportunities that align with your career aspirations.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response, response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "138c802e-788d-4b5e-a10f-8c631fe9a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"How can I find a job?\"\n",
    "    }\n",
    "    ],\n",
    "    max_tokens=25,\n",
    "    n=2\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "98698bd1-1551-4095-b1f5-e766d53f1263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ChatCompletion(id='chatcmpl-AsvWYFx7DAPFBN6zeLRbMCHgclbYc', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='1. Start by updating your resume and cover letter to highlight your skills and experiences that are relevant to the job you are applying', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)), Choice(finish_reason='length', index=1, logprobs=None, message=ChatCompletionMessage(content='There are several steps you can take to find a job:\\n\\n1. Update your resume and cover letter: Make sure your resume', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1737654198, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=50, prompt_tokens=14, total_tokens=64, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))),\n",
       " [Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='1. Start by updating your resume and cover letter to highlight your skills and experiences that are relevant to the job you are applying', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)),\n",
       "  Choice(finish_reason='length', index=1, logprobs=None, message=ChatCompletionMessage(content='There are several steps you can take to find a job:\\n\\n1. Update your resume and cover letter: Make sure your resume', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))],\n",
       " ChatCompletionMessage(content='1. Start by updating your resume and cover letter to highlight your skills and experiences that are relevant to the job you are applying', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None),\n",
       " ChatCompletionMessage(content='There are several steps you can take to find a job:\\n\\n1. Update your resume and cover letter: Make sure your resume', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2, response2.choices, response2.choices[0].message, response2.choices[1].message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc581c21-8935-489a-8b16-4fa6c65cf5ba",
   "metadata": {},
   "source": [
    "#### Zero-shot Prompt vs. Few-shot Prompt\n",
    "Zero-shot prompting and few-shot prompting are techniques in machine learning which refer to the amount of information you give to a generative AI model before asking it to complete a task.\n",
    "\n",
    "Zero-shot prompting involves giving a model a task without any examples, relying solely on the prompt's instructions. In contrast, few-shot prompting provides the model with a few examples (usually in the prompt) before asking it to complete a similar task, helping improve accuracy by offering context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "217be964-2598-4622-8084-bc3f7e71a765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nPlease extract the following information form the given decription:\\n\\nName\\nThesis Title\\nUniversity\\nDomain\\n\\nThe body of description to retrieve the information:\\nMilad is a dedicated and ambitious graduate from Politecnico di Torino, specifically from the DAUIN (Department of Control and Computer Engineering). He has specialized in Computer Engineering with a focus on Artificial Intelligence and Data Analytics. His research revolves around the intersection of AI and healthcare. His thesis, titled 'Injecting Prior Knowledge in Medical Image Interpretation,' showcases his passion for leveraging advanced AI techniques to enhance medical diagnostics. His work reflects a strong commitment to applying technical expertise in real-world, impactful domains, particularly in health and medicine.\\n\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = \"Milad is a dedicated and ambitious graduate from Politecnico di Torino, specifically from the DAUIN (Department of Control and Computer Engineering). He has specialized in Computer Engineering with a focus on Artificial Intelligence and Data Analytics. His research revolves around the intersection of AI and healthcare. His thesis, titled 'Injecting Prior Knowledge in Medical Image Interpretation,' showcases his passion for leveraging advanced AI techniques to enhance medical diagnostics. His work reflects a strong commitment to applying technical expertise in real-world, impactful domains, particularly in health and medicine.\"\n",
    "\n",
    "# few-shot prompt\n",
    "prompt = f'''\n",
    "Please extract the following information form the given decription:\n",
    "\n",
    "Name\n",
    "Thesis Title\n",
    "University\n",
    "Domain\n",
    "\n",
    "The body of description to retrieve the information:\n",
    "{description}\n",
    "'''\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "893ce55d-2306-4d65-b6b5-143e032040ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=my_openaiapi_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "245cc215-a1f7-413b-a1ab-9905f5a1f57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.OpenAI at 0x1dabaee6e10>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "011dea56-c6b8-4f66-afdc-144938ce81d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# passing the prompt, the response below will be produced\n",
    "response3 = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "83ed2b81-1b09-426d-ab06-2396672cc96b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AsvWan2Cr0eox9spLlgjwfbbKZJik', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Name: Milad\\nThesis Title: Injecting Prior Knowledge in Medical Image Interpretation\\nUniversity: Politecnico di Torino\\nDomain: Artificial Intelligence and Healthcare', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1737654200, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=36, prompt_tokens=147, total_tokens=183, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6eff1208-1f3a-4a52-a4ac-a5090d12ffa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Milad\n",
      "Thesis Title: Injecting Prior Knowledge in Medical Image Interpretation\n",
      "University: Politecnico di Torino\n",
      "Domain: Artificial Intelligence and Healthcare\n",
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Name: Milad\\nThesis Title: Injecting Prior Knowledge in Medical Image Interpretation\\nUniversity: Politecnico di Torino\\nDomain: Artificial Intelligence and Healthcare'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_content = response3.choices[0].message.content\n",
    "print(output_content)\n",
    "print(type(output_content))\n",
    "output_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6978a8e9-9ff8-4996-b70e-44568603a87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': 'Milad\\nThesis Title: Injecting Prior Knowledge in Medical Image Interpretation\\nUniversity: Politecnico di Torino\\nDomain: Artificial Intelligence and Healthcare'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Name': 'Milad\\nThesis Title: Injecting Prior Knowledge in Medical Image Interpretation\\nUniversity: Politecnico di Torino\\nDomain: Artificial Intelligence and Healthcare'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The content is produced as a string.\n",
    "# You can store the data retrieved in an organized way as a dictionary.\n",
    "\n",
    "# Split into lines\n",
    "lines = output_content.split('\\n\\n')\n",
    "\n",
    "# Convert to dictionary\n",
    "dictionary = {}\n",
    "for line in lines:\n",
    "    key, value = line.split(': ', 1)\n",
    "    dictionary[key] = value\n",
    "\n",
    "print(dictionary)\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a177d5-44f3-4ed3-bffa-bfd7f1b9e22b",
   "metadata": {},
   "source": [
    "#### Below let's create a custom function the functionality of which is defined to retrieve the student information based on the given prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "be0b2919-0c17-4111-ba07-e657d6bccdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom function\n",
    "# we use student_work as a library of functions that the model can call\n",
    "# even though it contains only a single function\n",
    "student_work = [{\n",
    "        \"name\": \"retrieve_student_data\",\n",
    "        \"description\": \"Extract information from the given prompt.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Name of the Student\"\n",
    "                },\n",
    "                \"thesis\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Title of the Thesis\"\n",
    "                },\n",
    "                \"university\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Name of the University\"\n",
    "                },\n",
    "                \"domain\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Domain of Research\"\n",
    "                }                \n",
    "            }\n",
    "\n",
    "        }\n",
    "\n",
    "        }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "03ae4b10-e622-4790-b2a2-3172c653568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response4 = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }],\n",
    "    functions=student_work\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b50eaf7-fe98-4d8f-968c-39e3aca2164d",
   "metadata": {},
   "source": [
    "#### The API returns the JSON response below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "68a46103-ea7e-4bd8-91ee-d56abc73ac28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AsvWbMZkBbaeW7DTYc8KVk8Hu9SG3', choices=[Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=FunctionCall(arguments='{\"name\":\"Milad\",\"thesis\":\"Injecting Prior Knowledge in Medical Image Interpretation\",\"university\":\"Politecnico di Torino\",\"domain\":\"Artificial Intelligence and Data Analytics\"}', name='retrieve_student_data'), tool_calls=None))], created=1737654201, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=49, prompt_tokens=223, total_tokens=272, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4370a64c-97bf-467d-8464-13a6eda30bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = response4.choices[0].message.function_call.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cc635072-1ab6-4ab4-8862-df3d52f85a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0439e217-8f94-4f10-88cc-0db4d1932f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "python_dict = json.loads(response4.choices[0].message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f2d6641a-11d7-4aee-930d-1f9fecb0cd0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(python_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcf4153-cbc3-4342-8e25-d919ebf4cb0d",
   "metadata": {},
   "source": [
    "#### According to what we all just noticed above checking types, the json.loads() method can be used to parse a valid JSON String and convert it into a Python Dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e693a5-2f56-4f2e-87a9-331f3b4374d0",
   "metadata": {},
   "source": [
    "#### But what if we have a list of descriptions? Can we manipulate each separately calling the API?\n",
    "#### Let's see..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ec9ea1f0-7073-4062-abb7-da54f3cd84fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "description2 = \"Shahab is a dedicated and ambitious graduate from Politecnico di Torino, specifically from the Environmental and Land Engineering. He has specialized in Environmental Engineering with a focus on Solution for Environmental Challenges. His thesis, titled 'A Study on the Impact of Perfluorinated Compounds on Human Health,' showcases his passion for leveraging advanced AI techniques to enhance medical diagnostics. His work reflects a strong commitment to applying technical expertise in real-world, impactful domains, particularly in Health and Environment.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9b953dc1-896d-4756-a355-8a4829a1bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of descriptions\n",
    "student_descriptions = [description, description2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6d9bb175-d957-40ff-9ca8-109ee113301a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About Milad:\n",
      "{'name': 'Milad', 'thesis': 'Injecting Prior Knowledge in Medical Image Interpretation', 'university': 'Politecnico di Torino', 'domain': 'Artificial Intelligence and Healthcare'}\n",
      "About Shahab:\n",
      "{'name': 'Shahab', 'thesis': 'A Study on the Impact of Perfluorinated Compounds on Human Health', 'university': 'Politecnico di Torino', 'domain': 'Environmental Engineering, Health'}\n"
     ]
    }
   ],
   "source": [
    "# loop over the list of descriptions\n",
    "for student in student_descriptions:\n",
    "    response = client.chat.completions.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\",\"content\": student}],\n",
    "        functions=student_work,\n",
    "        function_call=\"auto\"\n",
    "    )\n",
    "\n",
    "    dict = json.loads(response.choices[0].message.function_call.arguments)\n",
    "    name = dict[\"name\"]\n",
    "    print(f\"About {name}:\\n{dict}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0654bfb2-37be-4ab3-b9aa-13b60d8b6122",
   "metadata": {},
   "source": [
    "#### We can produce the information on a student more beautifully as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "44fa4075-ed2c-4975-903e-30eda492ca17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About Shahab:\n",
      " - Name: Shahab\n",
      " - Thesis: A Study on the Impact of Perfluorinated Compounds on Human Health\n",
      " - University: Politecnico di Torino \n",
      " - Domain: Environmental Engineering, Health\n"
     ]
    }
   ],
   "source": [
    "print(f\"About {name}:\\n - Name: {dict[\"name\"]}\\n - Thesis: {dict[\"thesis\"]}\\n - University: {dict[\"university\"]} \\n - Domain: {dict[\"domain\"]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d048afe-dd46-4933-bde8-ab09fa127da4",
   "metadata": {},
   "source": [
    "#### Now I have a few questions for you...\n",
    "#### Question 1: Do you think we can also manipulate several function as a list?\n",
    "(meaning if we can extract information based on the functions stored in the list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd614cb-5ee0-4e3d-b745-12d6ac36b421",
   "metadata": {},
   "source": [
    "The main difference compared to the previous example where we passed a prompt as the content would be... that here the functionalities are passed through a list of functions to decide what the respond should be like while in the previous example we had already made the request on what to return, in the prompt.\n",
    "Additionaly, through the argument function_call (function_call=\"auto\"), you allow the model some autonomy to determine when functions are relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c18485-0539-467d-818c-a30439d189a0",
   "metadata": {},
   "source": [
    "### Function Calling\n",
    "#### All what we did above was a simple demonstration of how function calling works and what is the purpose behind its utilization. We will have e few more examples during the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cc3cbf-6503-408b-8327-d8f650210478",
   "metadata": {},
   "source": [
    "#### Question 2: Can OpenAI provide us with real-time information?\n",
    "Below we will figure it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c8622088-fb55-4a58-942f-2a953cf7fa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response5 = client.chat.completions.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\",\n",
    "                   \"content\": \"When is the next bus from Turin to Milan?\"}],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6ecf693a-6106-4fe4-9fa4-882a973ed88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I do not have real-time information on bus schedules. It is best to check the website or contact the bus company for the most up-to-date schedule for buses from Turin to Milan.\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response5.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e55490a-08bc-4fdd-abb0-b8a165dd47d2",
   "metadata": {},
   "source": [
    "#### Then how is it possible to fetch real-time information via OpenAI API?\n",
    "Retrieving real-time information through the OpenAI API is not natively supported, as the OpenAI API itself does not access or fetch live data from the Internet. However, it can process and analyze data you provide to it. To access real-time information, you typically need to use a third-party API or service that provides live updates or real-time data. You will only have to identify an API that provides the real-time data you need (e.g., weather, financial data, or news). Examples include:\n",
    "- OpenWeather for weather updates.\n",
    "- Alpha Vantage for stock prices.\n",
    "- NewsAPI for breaking news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5b79380b-15f9-47c5-899d-bcdd092d090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_descriptions = [\n",
    "    {\n",
    "        \"name\": \"fetch_travel_info\",\n",
    "        \"description\": \"Get travel information between two locations\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"loc_origin\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The departure terminal (e.g. TOR)\"\n",
    "                },\n",
    "                \"loc_dest\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The departure terminal (e.g. MLN)\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"loc_origin\", \"loc_destination\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d50ca8f1-da63-4f83-a21e-91c8194df86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"When is the next bus from Torino to Milan?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4e5a943d-e179-4c88-a01c-4d6ee41b4a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response6 = client.chat.completions.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\",\"content\": user_prompt}],\n",
    "        functions=function_descriptions,\n",
    "        function_call=\"auto\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fb370164-2cf2-4745-aad7-f3cc60005944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AsvWglGdW7s71cfIWGb4dOVlrDZfV', choices=[Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=FunctionCall(arguments='{\"loc_origin\":\"Torino\",\"loc_dest\":\"Milan\"}', name='fetch_travel_info'), tool_calls=None))], created=1737654206, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=24, prompt_tokens=85, total_tokens=109, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "463dbf21-eeaf-440b-9a37-6d22eab1f4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(response6.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a27c897-3180-4b24-9ad0-5523bed719ec",
   "metadata": {},
   "source": [
    "#### Why `content=None`? Why does the request fail to return some valuable content?\n",
    "Let us explore the causes:\n",
    "1.  Function Call Triggered: The model's response includes this line:\n",
    "`function_call=FunctionCall(arguments='{\"loc_origin\":\"TOR\",\"loc_dest\":\"MLN\"}', name='fetch_travel_info')`\n",
    "This shows that the model has been instructed to call a function (`fetch_travel_info`) and provide arguments for it (`{\"loc_origin\": \"TOR\", \"loc_dest\": \"MLN\"}`).\n",
    "    - The `function_call` parameter in the request (`function_call=\"auto\"`) tells the model to decide whether to return a normal response or call one of the provided functions.\n",
    "    - The model decided to call a function and returned the arguments for that function instead of generating a regular completion (text response).\n",
    "2. No Direct Response (Content=None):\n",
    "The `content=None` in the model's response means that the model chose to defer the task to a function and did not generate a natural language answer.\n",
    "This is expected when:\n",
    "    - The model determines that calling a function is more appropriate to fulfill the user's request.\n",
    "    - The function definitions (`function_descriptions`) align with the user's query and the model interprets the query as a trigger for a function call.\n",
    "3. Configuration of `function_descriptions`:\n",
    "The model references a function in the provided `function_descriptions`. If the `function_descriptions` provided are detailed and align with the user's prompt, the model will prioritize calling the function (`fetch_travel_info`) over generating a textual response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6c4169-b399-4cbc-bfd8-5d2457c358ab",
   "metadata": {},
   "source": [
    "Additional Note: One option the model has to determine the usefulness of the available functions would be evaluating the context of the user's query in relation to the function descriptions provided in the `function_descriptions` parameter. The `function_descriptions` parameter includes metadata about the functions, such as their name, purpose, and required parameters. This metadata gives the model insight into:\n",
    "- What each function does (from its description).\n",
    "- The type of input the function expects (from its parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6f6cc940-c5f9-4d34-bc71-b5cf013b3629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"loc_origin\":\"Torino\",\"loc_dest\":\"Milan\"}'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response6.choices[0].message.function_call.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b5140628-5136-45eb-b48f-3c57b144f5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# below is defined a custom API in the form a function\n",
    "def fetch_travel_info(loc_origin, loc_dest):\n",
    "\n",
    "    # let's fabricate some dumb information\n",
    "    # suppose that below travel information are returned from an API\n",
    "    travel_info = {\n",
    "        \"loc_origin\": loc_origin,\n",
    "        \"loc_destination\": loc_dest,\n",
    "        \"datetime\": str(datetime.now() + timedelta(hours=2)),\n",
    "        \"terminal\": \"TO\",\n",
    "        \"drive\": \"SS34I\"\n",
    "    }\n",
    "\n",
    "    return json.dumps(travel_info) # transform the info into python dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8747f639-99f7-4a3c-b4d4-54f8d355cea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loc_origin': 'Torino', 'loc_dest': 'Milan'}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = json.loads(response6.choices[0].message.function_call.arguments)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a8f2be70-67cd-4c42-880f-1d2b894411e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Torino'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin = json.loads(response6.choices[0].message.function_call.arguments).get(\"loc_origin\")\n",
    "origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b1eb8cec-7ef6-469c-a0b2-d0189fe0a5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Milan'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destination = json.loads(response6.choices[0].message.function_call.arguments).get(\"loc_dest\")\n",
    "destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f3a05ace-7fb5-4089-bd7f-c7ad5f70f9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fetch_travel_info'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response6.choices[0].message.function_call.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0e3a99fb-25ab-486d-8932-10d0d150c1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.fetch_travel_info(loc_origin, loc_dest)>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(response6.choices[0].message.function_call.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0256a6-0250-4699-b872-9922b52b617f",
   "metadata": {},
   "source": [
    "### WARNING!!!\n",
    "#### Here is how eval works:\n",
    "eval() interprets a string as code. The reason why so many people have warned you about using this is because a user can use this as an option to run code on the computer. If you have eval(input()) and os imported, a person could type into input() os.system('rm -R *') which would delete all your files in your home directory. (Assuming you have a unix system). Using eval() is a security hole. If you need to convert strings to other formats, try to use things that do that, like int(). If you pass a string (e.g. \"234\") to eval(), then it will return the same value but of type int (e.g. 234)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8fc8a334-8086-45cf-b4ce-c18da61296af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract and return our chosen function\n",
    "extracted_function = eval(response6.choices[0].message.function_call.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "16a27de3-13f0-4e85-a851-9251177f8c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"loc_origin\": \"Torino\", \"loc_destination\": \"Milan\", \"datetime\": \"2025-01-23 20:43:26.224211\", \"terminal\": \"TO\", \"drive\": \"SS34I\"}\n"
     ]
    }
   ],
   "source": [
    "drive = extracted_function(**params)\n",
    "print(drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c25e8715-c1a8-4109-a307-ce1a14200cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "response7 = client.chat.completions.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\",\"content\": user_prompt},\n",
    "            {\"role\": \"function\",\n",
    "             \"name\": response6.choices[0].message.function_call.name, \n",
    "             \"content\": extracted_function(**json.loads(response6.choices[0].message.function_call.arguments))}\n",
    "        ],\n",
    "        # add function calling\n",
    "        functions=function_descriptions,\n",
    "        function_call=\"auto\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9ed7f891-ca06-465f-94e3-99d7fa15028e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AsvWhsAYaHS05vupvYAMOLmGfg3kG', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The next bus from Torino (TO) to Milan (MLN) departs on 2025-01-23 at 20:43:26. The bus will be on the SS34I route.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1737654207, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=46, prompt_tokens=141, total_tokens=187, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "51cd0097-6c63-4a0f-aba0-87ddc9d354b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The next bus from Torino (TO) to Milan (MLN) departs on 2025-01-23 at 20:43:26. The bus will be on the SS34I route.\n"
     ]
    }
   ],
   "source": [
    "print(response7.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cdbbb6-3e7c-40fc-9100-df57383fc8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
