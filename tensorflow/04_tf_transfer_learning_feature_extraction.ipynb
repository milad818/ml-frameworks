{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPMicio8MjmZVVk/jU1P36C"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## What is Transfer Learning?"],"metadata":{"id":"Y1D6Xu0JAQ-g"}},{"cell_type":"markdown","source":["**Transfer Learning** is a deep learning technique where a pre-trained model (trained on a large dataset) is fine-tuned or adapted to a new task, usually with a smaller dataset. This significantly reduces training time, computational cost, and data requirements while improving performance."],"metadata":{"id":"JR4vWX0iAm3d"}},{"cell_type":"markdown","source":["When we apply transfer learning, we typically freeze the early layers of a pre-trained model and only fine-tune the later layers or add a custom classifier.\n","\n","1. Pre-Trained Feature Extractor:\n","\n","The lower layers of a CNN (for vision tasks) or Transformer (for NLP tasks) extract generic low-level features such as edges, textures, or general patterns.\n","These features are universal across many datasets and do not need to be retrained.\n","\n","2. Freezing Lower Layers:\n","\n","Since early layers capture general features, they remain frozen to retain learned representations.\n","Freezing prevents unnecessary weight updates, allowing the model to leverage prior knowledge.\n","\n","3. Fine-Tuning Higher Layers:\n","\n","The deeper layers of the model are task-specific and need fine-tuning to adapt to new data.\n","These layers learn complex, high-level features such as object parts, shapes, or specific language patterns.\n","\n","4. Adding a Custom Classifier:\n","\n","The final fully connected layers are often replaced with a new classifier tailored for the target task.\n","This part of the model is trained from scratch while leveraging extracted features."],"metadata":{"id":"pL0q8PGgA956"}},{"cell_type":"markdown","source":["**NOTE!** Transfer learning helps you get reliable results with less data."],"metadata":{"id":"ZVOk3zaXC8mp"}},{"cell_type":"markdown","source":["Let's firstly check the processor info."],"metadata":{"id":"RKRhl1eNDOaL"}},{"cell_type":"code","source":["# GPU or CPU\n","!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XOeu9zqhAnjX","executionInfo":{"status":"ok","timestamp":1742674390700,"user_tz":-60,"elapsed":147,"user":{"displayName":"Milad Zakhireh","userId":"01326276303537213077"}},"outputId":"1621d0d5-36d2-4ad4-c859-764bb5267019"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Mar 22 20:13:09 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":["**Paho0o!**\n","Apprently, we're not on GPU for now.\n","\n","No worries, we will take care of it as soon as GPU is needed."],"metadata":{"id":"latXFjF9CKjg"}},{"cell_type":"markdown","source":["Now, let us install the necessary tools and packages."],"metadata":{"id":"mE0c5BkJIjO2"}},{"cell_type":"code","source":["!pip install -U tensorflow_hub\n","# !pip install tensorflow==2.15.0 tensorflow-hub keras==2.15.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qMpVSOSJDWH6","executionInfo":{"status":"ok","timestamp":1742674392971,"user_tz":-60,"elapsed":2275,"user":{"displayName":"Milad Zakhireh","userId":"01326276303537213077"}},"outputId":"8dcc3ab0-73e4-4912-9204-70c3a829d743"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.11/dist-packages (0.16.1)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_hub) (1.26.4)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow_hub) (4.25.6)\n","Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow_hub) (2.15.1)\n","Requirement already satisfied: tensorflow<2.16,>=2.15 in /usr/local/lib/python3.11/dist-packages (from tf-keras>=2.14.1->tensorflow_hub) (2.15.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (3.13.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (24.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (4.12.2)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (0.37.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (1.71.0)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (2.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (0.45.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (2.38.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (1.2.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (3.7)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (2.32.3)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (3.1.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (5.5.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (2.0.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (2025.1.31)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (3.0.2)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (0.6.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (3.2.2)\n"]}]},{"cell_type":"markdown","source":["### Data Preparation"],"metadata":{"id":"EmiYZuOnK5Zm"}},{"cell_type":"markdown","source":["It is clear that we will need a load of data to implement our model. So let's download one provided by [Daniel Bourke](https://www.mrdbourke.com/) (Food Classes). By the way, the whole document is inspired by his work."],"metadata":{"id":"-cXLTKVTDjB-"}},{"cell_type":"code","source":["import zipfile\n","\n","# Download data\n","!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n","\n","# Unzip the file\n","zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\", \"r\")\n","zip_ref.extractall()\n","zip_ref.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v6Cpk98yB864","executionInfo":{"status":"ok","timestamp":1742674395834,"user_tz":-60,"elapsed":2862,"user":{"displayName":"Milad Zakhireh","userId":"01326276303537213077"}},"outputId":"6c6a9436-7fda-4a21-a133-498bfd2a1f58"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-03-22 20:13:12--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.197.207, 74.125.135.207, 74.125.195.207, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.197.207|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 168546183 (161M) [application/zip]\n","Saving to: ‘10_food_classes_10_percent.zip.3’\n","\n","10_food_classes_10_ 100%[===================>] 160.74M   182MB/s    in 0.9s    \n","\n","2025-03-22 20:13:13 (182 MB/s) - ‘10_food_classes_10_percent.zip.3’ saved [168546183/168546183]\n","\n"]}]},{"cell_type":"code","source":["import os\n","\n","# explore the data\n","for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n","  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TzLnkfQtETpZ","executionInfo":{"status":"ok","timestamp":1742674395845,"user_tz":-60,"elapsed":10,"user":{"displayName":"Milad Zakhireh","userId":"01326276303537213077"}},"outputId":"feb5de43-69a9-44c1-847d-4a0ed7607b35"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 2 directories and 0 images in '10_food_classes_10_percent'.\n","There are 10 directories and 0 images in '10_food_classes_10_percent/train'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'.\n","There are 10 directories and 0 images in '10_food_classes_10_percent/test'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'.\n"]}]},{"cell_type":"markdown","source":["Our data is composed of 10 classes, that is, 10 different types of food."],"metadata":{"id":"KQ54rRNMFfKV"}},{"cell_type":"markdown","source":["In order to be able to load our images we will have to `ImageDataGenerator()`. `ImageDataGenerator()` is a class in Keras (part of TensorFlow) that allows real-time data augmentation and efficient loading of images during model training. It is mainly used to:\n","\n","- **Augment images** (apply transformations like rotation, flipping, scaling, etc.).\n","- **Normalize pixel values** (rescale intensity to a certain range).\n","- **Load images in batches** (useful for handling large datasets without loading everything into memory at once)."],"metadata":{"id":"1d31XQXIFzrn"}},{"cell_type":"markdown","source":["**How Does It Work?** When you create an ImageDataGenerator object, you specify the transformations you want to apply to your images. Then, you generate augmented batches from the dataset using `.flow()` or `.flow_from_directory()`."],"metadata":{"id":"NWi3fmXCJXgX"}},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","# import tensorflow as tf\n","\n","IMAGE_SHAPE = (224, 224)\n","BATCH_SIZE = 32\n","\n","train_dir = \"10_food_classes_10_percent/train/\"\n","test_dir = \"10_food_classes_10_percent/test/\"\n","\n","train_datagen = ImageDataGenerator(rescale=1/255.)\n","test_datagen = ImageDataGenerator(rescale=1/255.)\n","\n","train_data = train_datagen.flow_from_directory(train_dir,\n","                                               target_size=IMAGE_SHAPE,\n","                                               batch_size=BATCH_SIZE,\n","                                               class_mode=\"categorical\")\n","\n","test_data = test_datagen.flow_from_directory(test_dir,\n","                                             target_size=IMAGE_SHAPE,\n","                                             batch_size=BATCH_SIZE,\n","                                             class_mode=\"categorical\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SH_-PaQBFbDM","executionInfo":{"status":"ok","timestamp":1742674396015,"user_tz":-60,"elapsed":163,"user":{"displayName":"Milad Zakhireh","userId":"01326276303537213077"}},"outputId":"1709ec62-d483-4a9d-ae81-b64f3e4750af"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 750 images belonging to 10 classes.\n","Found 2500 images belonging to 10 classes.\n"]}]},{"cell_type":"markdown","source":["### TensorBoard Callback\n","**TensorBoard** is a visualization tool that helps monitor and debug deep learning models by tracking metrics like loss, accuracy, gradients, histograms, and more during training. A **TensorBoard Callback** is a function in deep learning frameworks (like TensorFlow/Keras) that automatically logs this data while training a model."],"metadata":{"id":"Rfh6Z2eKMi_1"}},{"cell_type":"code","source":["# import tensorflow as tf\n","import datetime"],"metadata":{"id":"zPJJlEt0O6JG","executionInfo":{"status":"ok","timestamp":1742674396034,"user_tz":-60,"elapsed":17,"user":{"displayName":"Milad Zakhireh","userId":"01326276303537213077"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# define a function to create tensorboard callback\n","# log name pattern: [dir_name]/[experiment_name]/[current_timestamp]\n","def create_tensorboard_callback(dir_name, experiment_name):\n","  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n","      log_dir=log_dir\n","  )\n","  print(f\"Saving TensorBoard log files to: {log_dir}\")\n","  return tensorboard_callback"],"metadata":{"id":"55wLoZ0LIaK3","executionInfo":{"status":"ok","timestamp":1742674396037,"user_tz":-60,"elapsed":1,"user":{"displayName":"Milad Zakhireh","userId":"01326276303537213077"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["### Creating Models using TensorFlow Hub"],"metadata":{"id":"G8-ejhv9QeZr"}},{"cell_type":"markdown","source":["**TensorFlow Hub** is a repository of pre-trained machine learning models (e.g., ResNetV2, EfficientNet, etc.) that can be reused for various tasks like image classification, text embedding, object detection, and more. It provides a way to easily download, fine-tune, or use models without training from scratch."],"metadata":{"id":"9lIWBnt-QukQ"}},{"cell_type":"markdown","source":["#### Comparison with Other Model Hubs:"],"metadata":{"id":"L14pnZRkR1XL"}},{"cell_type":"markdown","source":["| Feature        | TensorFlow Hub         | Hugging Face Model Hub | PyTorch Hub  |\n","|:---------------|:------------------------|:------------------------|:-------------|\n","| **Library**   | TensorFlow/Keras        | Mainly PyTorch (some TensorFlow) | PyTorch |\n","| **Models**    | Vision, NLP, Generative, Speech | NLP, Vision, Multimodal | Vision, NLP |\n","| **Fine-tuning** | Supported              | Highly supported       | Supported |\n","| **Ease of Use** | Very easy              | Very easy              | Easy |\n"],"metadata":{"id":"oJt3nsQbR3tL"}},{"cell_type":"markdown","source":["### Different Approaches for Transfer Learning"],"metadata":{"id":"p9t_P0vRVi7n"}},{"cell_type":"markdown","source":["Transfer learning is a technique where a pre-trained model is adapted to a new task. Depending on how much of the pre-trained model is reused or fine-tuned, transfer learning can be implemented in different ways:"],"metadata":{"id":"tTATu-AzV2yt"}},{"cell_type":"markdown","source":["1. **Feature Extraction (Frozen Pre-Trained Model)**\n","\n","Implementation:\n","- Use a pre-trained model as a fixed feature extractor.\n","- Freeze the convolutional (or encoder) layers so they retain learned features.\n","- Replace the fully connected (FC) layers with a new classifier suited for the new task.\n","- Train only the new classifier layers."],"metadata":{"id":"6dIs5n5GV9qh"}},{"cell_type":"markdown","source":["2. **Fine-Tuning (Partial Transfer Learning)\n","Implementation:**\n","\n","- Use a pre-trained model and fine-tune some of its layers.\n","- Freeze the initial layers (low-level features) but allow later layers to update.\n","- Fine-tune with a lower learning rate to prevent catastrophic forgetting."],"metadata":{"id":"gfYJmVdPWSdN"}},{"cell_type":"code","source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","from tensorflow.keras import layers\n","import gc"],"metadata":{"id":"U9XOXVZgPcHf","executionInfo":{"status":"ok","timestamp":1742674396063,"user_tz":-60,"elapsed":20,"user":{"displayName":"Milad Zakhireh","userId":"01326276303537213077"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["# Resnet 50 V2 feature vector\n","resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n","\n","# EfficientNetB0 feature vector (version 1)\n","efficientnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\"\n","\n","# EfficientNetB0 feature vector (version 2 NEW)\n","# efficientnet_url = \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2\""],"metadata":{"id":"9dRtNPIzYJqm","executionInfo":{"status":"ok","timestamp":1742674396127,"user_tz":-60,"elapsed":62,"user":{"displayName":"Milad Zakhireh","userId":"01326276303537213077"}}},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":["### Create Model"],"metadata":{"id":"sWuUMoaS-GJh"}},{"cell_type":"markdown","source":["We can create the models separately or define a function for it saving a good deal of unnecessary code."],"metadata":{"id":"vehdjy3I-IrD"}},{"cell_type":"markdown","source":["**NOTE!** Be careful that the code may crash if you don't wrap the hub layer into lambda function, even taking the functional approach! In case of facing a crash, it is necessary to wrap if `tf.keras.Sequential()` is implemented."],"metadata":{"id":"zBD4jwKYGF3l"}},{"cell_type":"markdown","source":["It might raise an error similar to the one below:\n","```\n","ValueError: Only instances of `keras.Layer` can be added to a Sequential model. Received: <tensorflow_hub.keras_layer.KerasLayer object at 0x78180cf9a7d0> (of type <class 'tensorflow_hub.keras_layer.KerasLayer'>)\n","```"],"metadata":{"id":"IW-wXGSJLGic"}},{"cell_type":"code","source":["# # define a function to create model\n","def create_model(model_url, num_classes=10):\n","  \"\"\"\n","  Takes a TensorFlow Hub URL and creates a Keras Sequential model\n","  Args:\n","    model_url (str): A TensorFlow Hub feature extraction URL\n","    num_classes (int): Number of output neurons in the output layer\n","    equal to number of target classes, default 10\n","  Returns:\n","    An uncompiled Keras Sequential model\n","  \"\"\"\n","\n","  # Download the pretrained model and store it as keras layer\n","  feature_extractor_layer = hub.KerasLayer(model_url,\n","                                           trainable=False, # freeze the underlying patterns\n","                                           name='feature_extraction_layer',\n","                                           input_shape=IMAGE_SHAPE+(3,))\n","\n","  # JUST IN CASE!\n","  # hub_layer_wrapper = tf.keras.layers.Lambda(lambda x: feature_extractor_layer(x))\n","\n","  # Create the model\n","  model = tf.keras.Sequential([\n","    # hub_layer_wrapper,\n","    feature_extractor_layer,\n","    layers.Dense(num_classes, activation='softmax', name='output_layer')\n","  ])\n","\n","  return model"],"metadata":{"id":"3od9LAgX2KbI","executionInfo":{"status":"ok","timestamp":1742674396128,"user_tz":-60,"elapsed":8,"user":{"displayName":"Milad Zakhireh","userId":"01326276303537213077"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["# Create model\n","resnet50_url = \"https://www.kaggle.com/models/tensorflow/resnet-50/TensorFlow2/feature-vector/1\"\n","resnet_model = create_model(resnet50_url, num_classes=train_data.num_classes)"],"metadata":{"id":"z8UVDqgT2OgE","executionInfo":{"status":"ok","timestamp":1742674405379,"user_tz":-60,"elapsed":9253,"user":{"displayName":"Milad Zakhireh","userId":"01326276303537213077"}}},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":["The model is created now; however, there will be a few more step afterwards. Let's carry on and see what they are..."],"metadata":{"id":"iY6blZSfHoSY"}},{"cell_type":"code","source":["# Compile\n","resnet_model.compile(loss='categorical_crossentropy',\n","                     optimizer=tf.keras.optimizers.Adam(),\n","                     metrics=['accuracy'])"],"metadata":{"id":"oXVAUR7SFWta","executionInfo":{"status":"ok","timestamp":1742674405400,"user_tz":-60,"elapsed":20,"user":{"displayName":"Milad Zakhireh","userId":"01326276303537213077"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["# fit the model\n","resnet_history = resnet_model.fit(train_data,\n","                                  epochs=5,\n","                                  steps_per_epoch=len(train_data),\n","                                  validation_data=test_data,\n","                                  validation_steps=len(test_data),\n","                                  batch_size=16,\n","                                  callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub_dir\",\n","                                                                         experiment_name=\"tensorflow_exp_resnet50V2\")])"],"metadata":{"id":"CGbtTBW3T_Q5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dcabe0ce-23ad-43ad-9748-2ee247afb667"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving TensorBoard log files to: tensorflow_hub_dir/tensorflow_exp_resnet50V2/20250322-201324\n","Epoch 1/5\n","24/24 [==============================] - 510s 22s/step - loss: 1.9350 - accuracy: 0.3853 - val_loss: 1.0479 - val_accuracy: 0.6888\n","Epoch 2/5\n","24/24 [==============================] - ETA: 0s - loss: 0.8523 - accuracy: 0.7467"]}]},{"cell_type":"code","source":[],"metadata":{"id":"VRfYBOKlIYC-"},"execution_count":null,"outputs":[]}]}