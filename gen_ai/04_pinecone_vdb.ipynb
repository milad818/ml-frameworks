{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c847ca86-6664-4423-b61c-1a261cb7aa41",
   "metadata": {},
   "source": [
    "## Introduction to Vector Databases (Vector DBs)\n",
    "### What is a Vector Database?\n",
    "A vector database is a type of database specifically designed to store, index, and retrieve high-dimensional vector embeddings efficiently. Unlike traditional relational databases that store structured data in tables, vector DBs are optimized for similarity search and nearest neighbor retrieval based on mathematical distances between vectors.\n",
    "\n",
    "#### Key Concept: Vector Embeddings\n",
    "A vector embedding is a numerical representation of an object (text, image, audio, video, etc.) in a multi-dimensional space. These embeddings are generated using machine learning models such as: Word2Vec, GloVe, and FastText (for text) BERT, GPT, or CLIP (for NLP and multimodal tasks) ResNet, EfficientNet, or ViT (for images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d7a0e1-2e75-402b-8b37-be58556b4522",
   "metadata": {},
   "source": [
    "Each embedding captures semantic meaning, enabling similarity-based retrieval rather than exact matching."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3c06f9-8e86-4615-b590-bdebb96e2722",
   "metadata": {},
   "source": [
    "### Characteristics\n",
    "Vector databases provide several advantages over traditional databases for AI-powered applications:\n",
    "\n",
    "- **Fast Similarity Search:** Supports efficient nearest neighbor search algorithms like Approximate Nearest Neighbors (ANN) for quick lookups. Useful in applications like recommendation systems, image/video search, and semantic search.\n",
    "- **Scalability:** Handles millions or even billions of vectors with optimized storage and indexing.\n",
    "- **High-Dimensional Data Support:** Unlike relational databases that store structured rows and columns, vector DBs work with hundreds or thousands of dimensions.\n",
    "- **Flexibility:** Supports unstructured data like text, images, audio, video, and multi-modal content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a67407-1cab-4d2c-8c7a-19ee24343a0c",
   "metadata": {},
   "source": [
    "Click [HERE](https://www.pinecone.io/learn/vector-database/) if you wish to learn more about Vactor Databases on Pinecone's website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111e39e6-5c34-4fd6-bc45-7fbd66931916",
   "metadata": {},
   "source": [
    "Now let's get our hands dirty with a little bit of Pinecone via building an LLM-based application! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e09fd3b3-779a-4f4f-b9f6-d049c6d9c136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (0.3.15)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain) (3.10.11)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.31 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain) (0.3.39)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain) (0.3.5)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain) (0.2.11)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain) (2.10.5)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.31->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\asus k513eq\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<0.4.0,>=0.3.31->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.31->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.31->langchain) (2.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: pypdf in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (5.2.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
      "Requirement already satisfied: openai in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (1.59.7)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from openai) (2.10.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (0.3.7)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.39 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain-openai) (0.3.39)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain-openai) (1.59.7)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (0.2.11)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\asus k513eq\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.39->langchain-openai) (2.10.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.66.5)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.39->langchain-openai) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.39->langchain-openai) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.39->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.39->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.39->langchain-openai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.58.1->langchain-openai) (0.4.6)\n",
      "Requirement already satisfied: pinecone in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (5.4.2)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from pinecone) (2024.8.30)\n",
      "Requirement already satisfied: pinecone-plugin-inference<4.0.0,>=2.0.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from pinecone) (3.1.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from pinecone) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\asus k513eq\\appdata\\roaming\\python\\python312\\site-packages (from pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from pinecone) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from pinecone) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from pinecone) (2.2.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus k513eq\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from tqdm>=4.64.1->pinecone) (0.4.6)\n",
      "Requirement already satisfied: langchain_pinecone in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (0.2.3)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain_pinecone) (0.3.39)\n",
      "Requirement already satisfied: pinecone<6.0.0,>=5.4.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain_pinecone) (5.4.2)\n",
      "Requirement already satisfied: aiohttp<3.11,>=3.10 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain_pinecone) (3.10.11)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.4 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain_pinecone) (1.26.4)\n",
      "Requirement already satisfied: langchain-tests<1.0.0,>=0.3.7 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain_pinecone) (0.3.12)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (1.18.3)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (0.2.11)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\asus k513eq\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (2.10.5)\n",
      "Requirement already satisfied: pytest<9,>=7 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (8.3.4)\n",
      "Requirement already satisfied: pytest-asyncio<1,>=0.20 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (0.25.3)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (0.28.1)\n",
      "Requirement already satisfied: syrupy<5,>=4 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (4.8.2)\n",
      "Requirement already satisfied: pytest-socket<1,>=0.6.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (0.7.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from pinecone<6.0.0,>=5.4.0->langchain_pinecone) (2024.8.30)\n",
      "Requirement already satisfied: pinecone-plugin-inference<4.0.0,>=2.0.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from pinecone<6.0.0,>=5.4.0->langchain_pinecone) (3.1.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from pinecone<6.0.0,>=5.4.0->langchain_pinecone) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\asus k513eq\\appdata\\roaming\\python\\python312\\site-packages (from pinecone<6.0.0,>=5.4.0->langchain_pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from pinecone<6.0.0,>=5.4.0->langchain_pinecone) (4.66.5)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from pinecone<6.0.0,>=5.4.0->langchain_pinecone) (2.2.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (3.10.15)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (2.27.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (0.4.6)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (1.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus k513eq\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.5.3->pinecone<6.0.0,>=5.4.0->langchain_pinecone) (1.17.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<3.11,>=3.10->langchain_pinecone) (0.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (3.3.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\asus k513eq\\miniconda3\\lib\\site-packages (from anyio->httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "# install packages\n",
    "!pip install langchain\n",
    "!pip install pypdf\n",
    "!pip install tiktoken\n",
    "!pip install openai\n",
    "!pip install langchain-openai\n",
    "!pip install pinecone\n",
    "!pip install langchain_pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "297ad0ad-7d7a-490f-bd3e-262ffe57b93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pinecone KEY\n",
    "KEY = \"YOUR PINECONE KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91ad1405-734d-4fde-b2d6-b68dc5614b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import os\n",
    "import pinecone\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone, ServerlessSpec, PodSpec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd147d6-2ebf-4e23-a7ea-007e979ef1c1",
   "metadata": {},
   "source": [
    "#### **NOTE!** You will need a/some pdf file(s) in a directory named as pdfs for instance!\n",
    "If it doesn't already exist, you can create it through the command `!mkdir pdfs` and then it will appear in the same directory as your Jupyter Notebook file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7cb20ed9-420b-4f55-ab09-976375c8fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pdfs\n",
    "pdf_loader = PyPDFDirectoryLoader(\"pdfs\")\n",
    "data = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "64763c00-b5eb-4b73-a7e4-8fb652c43b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print and display the data\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac60473-3a3c-4a8b-9643-9e8f27dc45a1",
   "metadata": {},
   "source": [
    "You will need `RecursiveCharacterTextSplitter()` to split text by recursively look at characters. The `RecursiveCharacterTextSplitter()` is a utility class typically used for splitting large texts into smaller chunks in natural language processing (NLP) tasks. This is particularly helpful when dealing with long documents or text data, where you need to process or analyze text in manageable parts without losing any important context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff71bf53-3142-40d5-af41-51813b9b5396",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a4d0e15-52e9-4975-b7d8-3079ec1182d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_chunks = txt_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82622e8f-79e9-4760-a3cd-f24ce4dce001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(txt_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7ce92ce-a8c5-4373-b3ee-b8de0117e862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print and display the data chunks\n",
    "# txt_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7166c0e-c035-4667-9653-7bee81f8dfea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'pdfs\\\\attention-is-all-you-need.pdf', 'page': 0, 'page_label': '1'}, page_content='Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\nAttention Is All You Need\\nAshish Vaswaniâˆ—\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeerâˆ—\\nGoogle Brain\\nnoam@google.com\\nNiki Parmarâˆ—\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreitâˆ—\\nGoogle Research\\nusz@google.com\\nLlion Jonesâˆ—\\nGoogle Research\\nllion@google.com\\nAidan N. Gomezâˆ— â€ \\nUniversity of Toronto\\naidan@cs.toronto.edu')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b52cc531-7f1e-4fd2-a6d2-23fbcc518ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "Ashish Vaswaniâˆ—\n",
      "Google Brain\n",
      "avaswani@google.com\n",
      "Noam Shazeerâˆ—\n",
      "Google Brain\n",
      "noam@google.com\n",
      "Niki Parmarâˆ—\n",
      "Google Research\n",
      "nikip@google.com\n",
      "Jakob Uszkoreitâˆ—\n",
      "Google Research\n",
      "usz@google.com\n",
      "Llion Jonesâˆ—\n",
      "Google Research\n",
      "llion@google.com\n",
      "Aidan N. Gomezâˆ— â€ \n",
      "University of Toronto\n",
      "aidan@cs.toronto.edu\n"
     ]
    }
   ],
   "source": [
    "print(txt_chunks[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f6ae0a93-d300-4280-8fe0-ff4b30428eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txt_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a4ff1796-ac32-469e-9d44-341c666a1e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set OpenAI API KEY\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"YOUR OPENAI API KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5d26f11-9288-438a-9e54-46cbb60e3c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding=OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a2cb780-b7c3-4e50-afe6-e3155ed00c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embedding = embedding.embed_query(\"What is your name?\")\n",
    "len(sample_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c06557-616d-4da4-a072-cca9a5232ef1",
   "metadata": {},
   "source": [
    "**Pinecone** with **LangChain** requires explicitly initializing Pinecone, creating an index manually, generating embeddings separately, and storing them using the Pinecone class. This replaces the older Pinecone.from_texts() method, providing more flexibility and better compatibility with the latest versions of Pinecone and LangChain. ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "36ec4f3b-3729-4a69-bf01-0c5d9b1b9d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\", KEY)\n",
    "PINECONE_API_ENV = os.environ.get(\"PINECONE_API_ENV\", \"gcp-starter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "143cde21-6b69-4e57-b0cc-d5bcb72a752e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index pinecone-index already exist.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Pinecone client\n",
    "pc = pinecone.Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "cloud = os.getenv(\"PINECONE_CLOUD\", \"aws\")\n",
    "region = os.getenv(\"PINECONE_REGION\", \"us-east-1\")\n",
    "\n",
    "index_name = \"pinecone-index\"\n",
    "\n",
    "spec = ServerlessSpec(cloud=cloud, region=region)\n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "# Check if the index exists, otherwise create it\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(name=index_name, dimension=1536, metric=\"cosine\", spec=spec)  # Use dimension = 1536 for OpenAI embeddings\n",
    "    # Wait for index to be initialized\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "    print(f\"Index {index_name} has been successfully created.\")\n",
    "else:\n",
    "    print(f\"Index {index_name} already exist.\")\n",
    "    \n",
    "# Connect to the index\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb8a257c-2d53-4d4a-8117-747e9f5879b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 90}},\n",
       " 'total_vector_count': 90}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9653fd7-f06d-4f7f-aa33-cacfe20e512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docsearch = Pinecone.from_texts([t.page_content for t in txt_chunks], embedding, index_name=index_name)\n",
    "\n",
    "#Extract texts\n",
    "texts = [t.page_content for t in txt_chunks]\n",
    "\n",
    "# Generate embeddings\n",
    "txt_embeddings = embedding.embed_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ab3e504a-fd36-454e-ab32-52848a301c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txt_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8dbf7bad-53fd-4308-83b6-6b42913e557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt_embeddings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a12229-a704-42b6-9e97-87c0c920e559",
   "metadata": {},
   "source": [
    "#### Time to prepare data for Pinecone in a desired format (Each entry: `(ID, vector, metadata)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8e1220b1-c0fd-463c-b1c6-2536d4c15eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Pinecone (each chunk needs an ID)\n",
    "vector_data = [\n",
    "    (str(i), txt_embeddings[i], {\"text\": texts[i]})  # Each entry: (ID, vector, metadata)\n",
    "    for i in range(len(txt_chunks))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d96b6fa5-2b8c-44cb-88a8-cc5bfbb64dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 90}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload to Pinecone\n",
    "index.upsert(vectors=vector_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f06fdb0-95af-4373-83da-9c9a980c10dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e44ffb9-8721-420b-9e63-4f270763cb69",
   "metadata": {},
   "source": [
    "Aa soon as your embeddings identified by a particular index are uploaded into your Pinecone, you can simply verify their presence as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "27be023d-c03e-4ad7-970d-7dfac8731850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 90}},\n",
      " 'total_vector_count': 90}\n"
     ]
    }
   ],
   "source": [
    "# Verify inserted data (Optional)\n",
    "print(index.describe_index_stats())  # Shows number of vectors stored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e91fc0-0025-4e0d-834e-722585a9dc7a",
   "metadata": {},
   "source": [
    "It is clearly noticeable that `total_vector_count` has become equal to 90."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3611f011-dc0c-4194-9f18-f4093f2d102d",
   "metadata": {},
   "source": [
    "The observed changes in the output of `index.describe_index_stats()` indicate that vectors have been successfully added to the index between the two function calls. Initially, the index was empty, as seen in the `total_vector_count` being `0` and the `namespaces` dictionary being empty (`{}`). After running the function again, the `total_vector_count` increased to `90`, and the `namespaces` field now contains an entry (`''`) with `vector_count` set to `90`. This suggests that 90 vectors were inserted into the index under the default namespace.\n",
    "\n",
    "Despite the increase in the number of stored vectors, other index properties, such as `dimension` (1536), `metric` (cosine similarity), `vector_type` (dense), and `index_fullness` (0.0), remain unchanged. This means that the structure and settings of the index have not been modified; rather, only the content has been updated. The presence of a populated namespace reinforces the idea that vectors were added under a specific category, which by default appears to be an unnamed namespace (`''`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d9e8bedf-66fe-4750-860e-f7e9621f5cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is sometimes called intra-attention?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "683546c0-b3b8-489d-9237-4d2c2dded682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embedding for the query\n",
    "query_embedding = embedding.embed_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5c9e0b8a-a9db-4e1e-b4f2-7d85e9565d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the search in Pinecone\n",
    "search_results = index.query(vector=query_embedding, top_k=3, include_metadata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280e2f24-fbba-4d92-9102-b4810de974db",
   "metadata": {},
   "source": [
    "#### Below you can see the top 3 matching results each of which has its own ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0c7a3551-15a7-468d-8d1f-19d7e3237537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '12',\n",
       "              'metadata': {'text': 'reduced to a constant number of '\n",
       "                                   'operations, albeit at the cost of reduced '\n",
       "                                   'effective resolution due\\n'\n",
       "                                   'to averaging attention-weighted positions, '\n",
       "                                   'an effect we counteract with Multi-Head '\n",
       "                                   'Attention as\\n'\n",
       "                                   'described in section 3.2.\\n'\n",
       "                                   'Self-attention, sometimes called '\n",
       "                                   'intra-attention is an attention mechanism '\n",
       "                                   'relating different positions\\n'\n",
       "                                   'of a single sequence in order to compute a '\n",
       "                                   'representation of the sequence. '\n",
       "                                   'Self-attention has been'},\n",
       "              'score': 0.86995846,\n",
       "              'values': []},\n",
       "             {'id': '87',\n",
       "              'metadata': {'text': 'just\\n'\n",
       "                                   '-\\n'\n",
       "                                   'this\\n'\n",
       "                                   'is\\n'\n",
       "                                   'what\\n'\n",
       "                                   'we\\n'\n",
       "                                   'are\\n'\n",
       "                                   'missing\\n'\n",
       "                                   ',\\n'\n",
       "                                   'in\\n'\n",
       "                                   'my\\n'\n",
       "                                   'opinion\\n'\n",
       "                                   '.\\n'\n",
       "                                   '<EOS>\\n'\n",
       "                                   '<pad>\\n'\n",
       "                                   'Figure 4: Two attention heads, also in '\n",
       "                                   'layer 5 of 6, apparently involved in '\n",
       "                                   'anaphora resolution. Top:\\n'\n",
       "                                   'Full attentions for head 5. Bottom: '\n",
       "                                   'Isolated attentions from just the word '\n",
       "                                   'â€˜itsâ€™ for attention heads 5\\n'\n",
       "                                   'and 6. Note that the attentions are very '\n",
       "                                   'sharp for this word.\\n'\n",
       "                                   '14'},\n",
       "              'score': 0.812918723,\n",
       "              'values': []},\n",
       "             {'id': '89',\n",
       "              'metadata': {'text': 'just\\n'\n",
       "                                   '-\\n'\n",
       "                                   'this\\n'\n",
       "                                   'is\\n'\n",
       "                                   'what\\n'\n",
       "                                   'we\\n'\n",
       "                                   'are\\n'\n",
       "                                   'missing\\n'\n",
       "                                   ',\\n'\n",
       "                                   'in\\n'\n",
       "                                   'my\\n'\n",
       "                                   'opinion\\n'\n",
       "                                   '.\\n'\n",
       "                                   '<EOS>\\n'\n",
       "                                   '<pad>\\n'\n",
       "                                   'Figure 5: Many of the attention heads '\n",
       "                                   'exhibit behaviour that seems related to '\n",
       "                                   'the structure of the\\n'\n",
       "                                   'sentence. We give two such examples above, '\n",
       "                                   'from two different heads from the encoder '\n",
       "                                   'self-attention\\n'\n",
       "                                   'at layer 5 of 6. The heads clearly learned '\n",
       "                                   'to perform different tasks.\\n'\n",
       "                                   '15'},\n",
       "              'score': 0.806828,\n",
       "              'values': []}],\n",
       " 'namespace': '',\n",
       " 'usage': {'read_units': 6}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c67ad7c-bfcd-46f0-8d77-365b4cd67a9e",
   "metadata": {},
   "source": [
    "#### **BUT** is it really what we were looking for...? Naah!\n",
    "The result would be even more meaningful if an LLM model is involved to retrieve and format the corresponding answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f33cf72f-b9d7-4f9a-8c0d-f0f4d901a832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index retreival-qa already exist.\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"PINECONE_API_KEY\"]=KEY\n",
    "\n",
    "# Let's create a new index\n",
    "index_name2 = \"retreival-qa\"\n",
    "\n",
    "# Check if the index exists, otherwise create it\n",
    "if index_name2 not in existing_indexes:\n",
    "    pc.create_index(name=index_name2, dimension=1536, metric=\"cosine\", spec=spec)  # Use dimension = 1536 for OpenAI embeddings\n",
    "    # Wait for index to be initialized\n",
    "    while not pc.describe_index(index_name2).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "    print(f\"Index {index_name2} has been successfully created.\")\n",
    "else:\n",
    "    print(f\"Index {index_name2} already exist.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b24f939-3794-436d-9daa-5d4b9afb8ae9",
   "metadata": {},
   "source": [
    "`vectorstore_from_chunks` is, in our case, a **Pinecone** vector database storing chunked document embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fdbff782-1542-468d-9cd7-1baeac65f239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a VectorScore from the text chunks already generated\n",
    "# through which you can add more records to Pincone index\n",
    "\n",
    "vectorstore_from_chunks = PineconeVectorStore.from_documents(\n",
    "    txt_chunks,\n",
    "    index_name=index_name2,\n",
    "    embedding=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "003ac193-f9bc-42ab-8ac6-3e19e817055f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 90}},\n",
       " 'total_vector_count': 90}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8a926553-21a2-42a8-bf42-bf50c0411207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='e58f09f1-91e7-4c6d-83cb-3ead8cea9067', metadata={'page': 14.0, 'page_label': '15', 'source': 'pdfs\\\\attention-is-all-you-need.pdf'}, page_content='just\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nFigure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the\\nsentence. We give two such examples above, from two different heads from the encoder self-attention\\nat layer 5 of 6. The heads clearly learned to perform different tasks.\\n15'),\n",
       " Document(id='ef6ec2c5-9ba6-4995-bb0d-2d04e631cd49', metadata={'page': 14.0, 'page_label': '15', 'source': 'pdfs\\\\attention-is-all-you-need.pdf'}, page_content='just\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nFigure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the\\nsentence. We give two such examples above, from two different heads from the encoder self-attention\\nat layer 5 of 6. The heads clearly learned to perform different tasks.\\n15'),\n",
       " Document(id='a913b71b-793d-467d-a10d-9b7b87f7792a', metadata={'page': 12.0, 'page_label': '13', 'source': 'pdfs\\\\attention-is-all-you-need.pdf'}, page_content='<pad>\\n<pad>\\n<pad>\\nFigure 3: An example of the attention mechanism following long-distance dependencies in the\\nencoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of\\nthe verb â€˜makingâ€™, completing the phrase â€˜making...more difficultâ€™. Attentions here shown only for\\nthe word â€˜makingâ€™. Different colors represent different heads. Best viewed in color.\\n13'),\n",
       " Document(id='76ea95d9-e052-4994-acbc-c0b0adbb5bc5', metadata={'page': 12.0, 'page_label': '13', 'source': 'pdfs\\\\attention-is-all-you-need.pdf'}, page_content='<pad>\\n<pad>\\n<pad>\\nFigure 3: An example of the attention mechanism following long-distance dependencies in the\\nencoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of\\nthe verb â€˜makingâ€™, completing the phrase â€˜making...more difficultâ€™. Attentions here shown only for\\nthe word â€˜makingâ€™. Different colors represent different heads. Best viewed in color.\\n13')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform a similarity search\n",
    "query2 = \"What behaviour do many attention heads exhibit?\"\n",
    "response2 = vectorstore_from_chunks.similarity_search(query2)\n",
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3f8ce150-51a8-47c0-aca8-a795f81e4768",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\",\n",
    "                temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b937cc4-6305-45b8-b998-258cd2ab376f",
   "metadata": {},
   "source": [
    "**NOTE!** OpenAI API Key is not passed to ChatOpenAI() since it has already been declared and added through `os.environ[...] = \"<YOUR API KEY>\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58ae493-d425-4de5-b9d5-b9d10a3764fb",
   "metadata": {},
   "source": [
    "The code line below is creating a **Retrieval-Augmented Generation (RAG)** pipeline using RetrievalQA from LangChain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b5bc462f-052b-4f50-9b81-f09a7edc6f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                 chain_type=\"stuff\",\n",
    "                                 retriever=vectorstore_from_chunks.as_retriever())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf042630-26f3-42a5-9724-bfafa79672f6",
   "metadata": {},
   "source": [
    "This initializes a RetrievalQA pipeline that integrates a retriever with a language model (LLM). The RetrievalQA model first retrieves relevant documents and then generates answers based on them.\n",
    "\n",
    "When `qa.invoke(query2)` is called, the system:\n",
    "- Searches for relevant documents in the vector store.\n",
    "- Feeds them into the LLM using the \"stuff\" method.\n",
    "- Generates an answer based on both retrieved data and the LLMâ€™s knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "be254036-1802-4f7f-b59b-f7b67daf930c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What behaviour do many attention heads exhibit?',\n",
       " 'result': 'Many of the attention heads exhibit behavior related to the structure of the sentence and seem to have learned to perform different tasks.'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.invoke(query2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ca169a-de7d-420b-8cb9-112fb283c6cc",
   "metadata": {},
   "source": [
    "#### Basic Application\n",
    "Let's create a very simple application throught which the process can be uncerstood in a much clearer way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "797578c1-ccbb-47f1-880f-5e2f22ca7494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your prompt:  What is attention?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Attention is an mechanism in natural language processing that allows a model to focus on specific parts of the input sequence when making predictions or generating output. It helps the model weigh the importance of different words or tokens in the input sequence.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your prompt:  Who has authored Attention?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Attention has been authored by Noam, Niki, and Llion.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your prompt:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting...\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS K513EQ\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "while True:\n",
    "    user_input = input(f\"Enter your prompt: \")\n",
    "    if user_input == \"exit\":\n",
    "        print(\"Exiting...\")\n",
    "        sys.exit()\n",
    "    if user_input == \"\":\n",
    "        continue\n",
    "    result = qa({\"query\": user_input})\n",
    "    print(f\"Answer: {result['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451e8ec7-771a-4be9-9955-e62c6ba65ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
