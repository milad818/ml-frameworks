{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ¤– Agentic Chatbot with LangGraph\n",
        "\n",
        "An agentic chatbot leverages KangGraph to build complex, autonomous, and dynamic conversational flows. KangGraph, a framework within LangChain, enables the creation of state machines that manage the chatbot's behavior, allowing it to make decisions, use tools, and respond to user input in a more sophisticated way than traditional chatbots.\n",
        "\n",
        "#### Here's a more detailed explanation:\n",
        "\n",
        "**Traditional Chatbots:** Typically follow pre-defined rules and scripts, offering limited conversational flexibility.\n",
        "\n",
        "**Agentic Chatbots:**\n",
        "Employ AI agents with reasoning and decision-making capabilities. They can adapt their responses, use external tools, and handle complex tasks, says Salesforce.\n",
        "\n",
        "**KangGraph's Role:**\n",
        "KangGraph is the core framework that enables the construction of agentic chatbots. It allows developers to define the chatbot's state transitions, routing logic, and tool usage, says Medium.\n",
        "\n",
        "Example: \\\\\n",
        "Imagine a weather chatbot. A traditional chatbot might simply provide the current weather. An agentic chatbot, using KangGraph, could also:\n",
        "- Ask if the user wants the forecast for tomorrow, says Medium\n",
        "- Check the user's location (with user consent) to provide a more relevant forecast\n",
        "- Alert the user if there's a severe weather warning in their area, says Medium.\n",
        "\n",
        "according to [Medium](https://medium.com/data-science-collective/langgraph-mcp-ollama-the-key-to-powerful-agentic-ai-e1881f43cf63).\n",
        "\n",
        "#### Benefits of Agentic Chatbots:\n",
        "- **Higher Personalization:** Tailor responses based on user profiles and preferences.\n",
        "- **Complex Task Handling:** Manage intricate inquiries and tasks beyond the capabilities of traditional chatbots.\n",
        "- **Autonomous Decision-Making:** Agents can make decisions and take actions without constant human supervision."
      ],
      "metadata": {
        "id": "oPtIe_0YwUo6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What is ReAct and how is it related to LangGraph and Agentic AI?\n",
        "\n",
        "**ReAct (Reasoning and Acting)** is a powerful pattern that combines reasoning traces with actions. ReAct architecture basically refers to a framework that combines reasoning and action to enable AI agents to solve complex tasks and decision-making in agentic workflows. It's a machine learning paradigm that integrates the reasoning and action-taking capabilities of large language models (LLMs). ReAct agents don't separate decision-making from task execution, unlike traditional AI systems.\n",
        "\n",
        "In LangGraph, we can implement this by adding a reasoning step before each action.\n",
        "\n"
      ],
      "metadata": {
        "id": "fosWakGkX6ML"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The agentic chatbot implemented in this specific project is designed to autonomously process user queries by dynamically deciding the best (or even all) sources of information, utilizing a LangGraph-based flow. It leverages specialized runners and API wrappers to search and retrieve data from Wikipedia for general knowledge and from Arxiv for academic research. Based on the nature of the query, the chatbot intelligently orchestrates these resources in parallel, aggregates the retrieved information, and synthesizes a clear, coherent final response. Its modular design ensures flexible, efficient information gathering and enables the chatbot to handle both casual and technical inquiries with depth and precision."
      ],
      "metadata": {
        "id": "yTgUAwEm7P-R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewqJ2uPqtijM",
        "outputId": "d1fdd676-7382-41e6-fdfb-2562d00f6672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m148.2/148.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m437.2/437.2 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.4/127.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install the necessary libraries and frameworks\n",
        "!pip install -q -U pydantic langchain langgraph langchain-core langchain-community\n",
        "!pip install -q -U python-dotenv langchain-groq\n",
        "!pip install -q -U arxiv\n",
        "!pip install -q -U wikipedia"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What do you think enables us to utilize resources like Wikipedia and Arxiv to gather all the information we need? \\\\\n",
        "You're right! \\\\\n",
        "Simply through the two pairs of tools listed below to deal with Wikipedia and Arxiv content:\n",
        "1. `WikipediaAPIWrapper`, `WikipediaQueryRun`\n",
        "2. `ArxivAPIWrapper`, `ArxivQueryRun`"
      ],
      "metadata": {
        "id": "5nGSzGV48L-t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ArxivAPIWrapper** and **WikipediaAPIWrapper**:\n",
        "\n",
        "These are lower-level helpers or tools which wrap the raw API (Arxiv API, Wikipedia API) and provide easy Python methods to interact with them (like `.run()`, `.search()`). *They don't decide when/how to query â€” they just provide functions for querying.* Think of them as \"tools\" that the `QueryRun` classes use underneath."
      ],
      "metadata": {
        "id": "7R7cUHBMPmbP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ArxivQueryRun** and **WikipediaQueryRun**:\n",
        "\n",
        "These are Runnable classes or functions in LangChain (or similar frameworks) designed to execute a search/query operation directly. They take a query (like a research topic or a question) and return search results (papers from Arxiv, articles from Wikipedia). Think of them as the \"doers\" â€” you give them a task, and they go fetch the data."
      ],
      "metadata": {
        "id": "F_X_iuM69Ip3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### In short:\n",
        "\n",
        "|                | **QueryRun** (Runner)             | **APIWrapper** (Helper)             |\n",
        "|----------------|------------------------------------|-------------------------------------|\n",
        "| Purpose        | Run full queries easily            | Provide methods to query APIs       |\n",
        "| Usage          | High-level, one-step search        | Lower-level, more flexible          |\n",
        "| Think of as    | \"Do it for me\"                     | \"Give me tools, I'll do it\"          |\n",
        "| Example        | `.invoke(\"machine learning\")`      | `.run(\"machine learning\")`           |\n"
      ],
      "metadata": {
        "id": "_O3B-BJuQsKI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### âš¡ A Real-world Analogy:\n",
        "\n",
        "APIWrapper = You own a car (manual control â€” steering wheel, brakes).\n",
        "\n",
        "QueryRun = You hire a driver (just say \"take me to the library,\" and he drives)."
      ],
      "metadata": {
        "id": "57_1SSfLRdK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import ArxivQueryRun, WikipediaQueryRun\n",
        "from langchain_community.utilities import ArxivAPIWrapper, WikipediaAPIWrapper"
      ],
      "metadata": {
        "id": "SNvQbag_yjkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_api_wrapper = ArxivAPIWrapper(top_k_results=2, doc_content_chars_max=500)\n",
        "arxiv = ArxivQueryRun(api_wrapper=arxiv_api_wrapper, description=\"Used to query Arxiv for recent papers.\")"
      ],
      "metadata": {
        "id": "-6aIdCEH4vsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(arxiv.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VG_2iHqQRl9h",
        "outputId": "6247deea-b5bd-4d26-bf34-3b9de1d2403d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "arxiv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make query to retrieve papers on a specific topic\n",
        "arxiv.invoke(\"Logic Tensor Network\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "7QBrLF0vSb1x",
        "outputId": "b0f9ed88-944d-4221-c149-a5f6ee3d5df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Published: 2016-07-07\\nTitle: Logic Tensor Networks: Deep Learning and Logical Reasoning from Data and Knowledge\\nAuthors: Luciano Serafini, Artur d'Avila Garcez\\nSummary: We propose Logic Tensor Networks: a uniform framework for integrating\\nautomatic learning and reasoning. A logic formalism called Real Logic is\\ndefined on a first-order language whereby formulas have truth-value in the\\ninterval [0,1] and semantics defined concretely on the domain of real numbers.\\nLogical constants are interpreted \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wikipedia_api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=500)\n",
        "wikipedia = WikipediaQueryRun(api_wrapper=wikipedia_api_wrapper, description=\"Used to query Wikipedia for recent articles.\")\n",
        "wikipedia.name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "N5PR5ZnqSpPn",
        "outputId": "65b012f0-d8c2-471a-90a6-b3da63aa03ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'wikipedia'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make query to retrieve articles on a specific topic\n",
        "# Note that the number of content characters is already set andlimited to 500\n",
        "wikipedia.invoke(\"LangGraph\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "Zn0DuHQNVX3h",
        "outputId": "62fde03e-f550-469d-c892-09c97b8394b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Page: LangChain\\nSummary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Very well!  \\\\\n",
        "Having prepared the tools above regarding particular resources (Wikipedia & Arxiv in our case) through which one can perform real-time information extraction, we can also consider a search engine API designed specifically for AI agents and Large Language Models (LLMs), for instance, **Tavily** to search the live web for broad, up-to-date information."
      ],
      "metadata": {
        "id": "eNe0Vn5K-0W8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tavily is a search engine API designed specifically for AI agents and Large Language Models (LLMs). It provides real-time, accurate, and relevant information from the web, tailored for AI applications like those using Retrieval-Augmented Generation (RAG). Unlike traditional search APIs, *Tavily focuses on delivering information in a format optimized for AI processing, including dynamically searching the web, reviewing multiple sources, and extracting relevant content.*"
      ],
      "metadata": {
        "id": "HI34t0V_AGnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get api keys for both Groq and Tavily\n",
        "\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"tavily-api-key\")\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get(\"groq-api-key\")"
      ],
      "metadata": {
        "id": "0F_156u5V1BY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Tavily search tool\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "tavily = TavilySearchResults()"
      ],
      "metadata": {
        "id": "FNzPn3YNGGqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tavily.invoke(\"Provide news on the most modern techs.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2XYWP59IEbT",
        "outputId": "0f1bc258-3244-4b9b-917b-d40474cfe7d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'title': 'TechNewsWorld - Technology News and Information',\n",
              "  'url': 'https://www.technewsworld.com/',\n",
              "  'content': \"Audio/Video\\nEmerging Tech\\nArtificial Intelligence\\nRobotics\\nVirtual Reality\\n\\n\\nGaming\\nHome Tech\\nHow To\\nPhotography\\nScience\\nHealth\\nSpace\\n\\n\\nTech Buzz\\nTech Law\\nTransportation\\nWomen In Tech\\n\\nNewsletters\\nSee all Newsletters\\n\\nE-Commerce Minute\\nTech News Flash\\n\\nEditors' Pick\\n\\n\\nCRM Buyer\\n\\nE-Commerce Times\\n\\nLinuxInsider\\n\\n\\nTechNewsWorld\\n\\nTop Stories [...] Online Entertainment\\nSearch Tech\\nSocial Networking\\nWeb Apps\\n\\nIT\\n\\n\\nDevelopers\\n\\nIT Leadership\\nNetwork Management\\n\\nMobile Tech\\n\\n\\nMobile Apps\\n\\nSmartphones\\nTablets\\nWearable Tech\\nWireless Networking\\n\\nReviews\\n\\n\\n\\n\\nSecurity\\n\\nCybersecurity\\nHacking\\nMalware\\nPrivacy\\n\\nTech Blog\\n\\n\\n\\n\\nTechnology\\n\\nAudio/Video\\nEmerging Tech\\nArtificial Intelligence\\nRobotics\\nVirtual Reality\\n\\n\\nGaming\\nHome Tech\\nHow To\\nPhotography\\nScience\\nHealth\\nSpace\\n\\n\\nTech Buzz\\nTech Law\\nTransportation\\nWomen In Tech\\n\\nMost Popular\\n\\n\\n\\n\\nSite Map [...] ###### The Future of AI in Retail: Smarter Merchandising, Better CX February 18, 2025\\n ###### Videoâ€™s Growing Role in Customer Engagement February 11, 2025\\nLinuxInsider\\n ###### A Practical Guide to Kubernetes Autoscalers February 20, 2025\\n ###### 30 Lines of Code Could Cut Data Center Power Use by 30% February 6, 2025\\n ###### Open Source's Complexities in 2025: From Sustainability to Security January 28, 2025\\nCRM Buyer\",\n",
              "  'score': 0.4186262},\n",
              " {'title': \"Tech News | Today's Latest Technology News | Reuters\",\n",
              "  'url': 'https://www.reuters.com/technology/',\n",
              "  'content': \"Artificial IntelligencecategoryChina's Baidu says its Kunlun chip cluster can train DeepSeek-like modelsApril 25, 2025\\n\\n\\n\\nWorld at WorkcategorySamsung to invest $117 million in southern Indian facility, minister saysApril 25, 2025\\n\\n\\n\\nSustainabilitycategoryNew US SEC chair says crypto sector deserves clear regulationsApril 25, 2025\\n\\n\\n\\nBusinesscategoryAutomakers rush to meet surging China demand for long-range hybridsApril 25, 2025 [...] categoryChina's Xi calls for self sufficiency in AI development amid U.S. rivalry4:21 AM UTC\\n\\n\\n\\nANALYSISAfter years of failed AI deals, Intel plans homegrown challenge to NvidiaApril 25, 2025\\n\\n\\n\\nBusinesscategoryElon Musk's xAI Holdings in talks to raise $20 billion from investors, Bloomberg News reports2:30 AM UTC\\n\\n\\n\\nFuture of MoneycategoryNike sued over closure of crypto businessApril 25, 2025 [...] Technology Video\\nTechnologyApril 15, 2025 Â· 6:15 PM UTC\\nHow AI can help to detect oil spills at sea\\nArtificial intelligence is helping the offshore oil and gas industry detect spills and predict future sea states, says Norway's Miros Group. Rachel Judah has more.\\nUp next\\n\\n\\nApple moving most US iphone production from China to India\\n\\n\\n\\nTech earnings: bullish Google, bearish Intel\\n\\n\\n\\nAI Weekly: Huawei's chips, humanoid robots get competitive\\n\\n\\n\\nKawasaki unveils four-legged ride-on robot 'Lion'\",\n",
              "  'score': 0.3925004},\n",
              " {'title': 'The Latest News in Technology | PCMag',\n",
              "  'url': 'https://www.pcmag.com/news',\n",
              "  'content': '3D Printers\\nAndroid Phones\\nAndroid Tablets\\nAntivirus Apps\\nApple iPads\\nApple iPhones\\nApple Watches\\n\\nBluetooth Speakers\\n\\n\\nCar Phone Mounts\\n\\nCPUs For Gaming\\nEreaders\\nFastest VPNs\\nFitness Trackers\\nGaming Keyboards\\nGaming Laptops\\n\\nGaming Monitors\\n\\n\\nGraphics Cards\\n\\nHeadphones\\nKeyboards\\nLaptops\\nLaptops For College Students\\nMedia Streaming Devices\\nPassword Managers\\n\\nPhoto Printers\\n\\n\\nRobot Vacuums\\n\\nSmart Thermostats\\nSmartwatches\\nSoundbars\\nTablets\\nTax Software\\nTVs\\n\\nVideo Editing Software\\n\\n\\nVPN Services [...] Electronics\\nTVs\\nProjectors\\nMedia Streaming Devices\\nHeadphones\\nSpeakers\\nEbook Readers\\nCameras\\nLenses\\nDrones\\nVR\\nElectric & Hybrid Cars\\nCar Accessories\\n\\n\\nSmart Home\\nSmart Home\\nHome Security\\nHome Security Cameras\\nRobot Vacuums\\nSmart Displays\\nSmart Lighting\\nSmart Locks\\nSmart Plugs\\nSmart Thermostats\\nSmart Lawn Mowers\\nAppliances\\nConnected Kitchen\\n\\n\\nHealth & Fitness\\nHealth & Fitness\\nWearables\\nFitness Trackers\\nHeart Rate Monitors\\nSmart Scales\\nMedical Alert Systems [...] Comparisons\\nReviews\\nHow-To\\nNews\\nOpinions\\nDeals\\nPCs & Hardware\\nLaptops\\nDesktop Computers\\nTablets\\nMonitors\\nHard Drives\\nSSDs\\nNetwork Attached Storage\\nWi-Fi Routers\\nWi-Fi Range Extenders\\nWi-Fi Mesh Networking Systems\\nPrinters\\n3D Printers\\nScanners\\nWebcams\\nComputer Mice\\nKeyboards\\nGraphics Cards\\nProcessors\\nMotherboards\\nPC Cases\\n\\n\\nMobile\\nMobile Phones\\nWireless Carriers\\nModems & Hotspots\\nBluetooth Headsets\\nMobile Phone Accessories\\nMobile Apps\\nAndroid Apps\\niPhone Apps\\niPad Apps',\n",
              "  'score': 0.37038535},\n",
              " {'title': 'Tech | The Verge',\n",
              "  'url': 'https://www.theverge.com/tech',\n",
              "  'content': 'Tech\\nThe latest tech news about the worldâ€™s best (and sometimes worst) hardware, apps, and much more. From top companies like Google and Apple to tiny startups vying for your attention, Verge Tech has the latest in what matters in technology daily.\\n\\nShein and Temu raise prices in response to Trump tariffs\\nBoth companies warned shoppers earlier this month that prices would increase on April 25th.\\nMia SatoApr 25 [...] News\\nNews\\nChromebooks could get a boost from Snapdragon X Plus chips soon\\nUmar ShakirApr 25\\n\\nNews\\nNews\\nWindows 11â€™s voice typing will soon let you turn off the ****ing profanity filter\\nTom WarrenApr 25\\n\\nNews\\nNews\\nSignalgate: Pete Hegsethâ€™s problematic passion for groupchats\\nTina NguyenMar 25\\n0\\nTech\\nTech\\nWDâ€™s 2TB SSD for Xbox is $50 off and the M4 MacBook Air is just $899\\nTodd HaseltonApr 25\\n\\nNews\\nNews\\nGoogle is killing software support for early Nest Thermostats\\nChris WelchApr 25 [...] News\\nNews\\nMicrosoft launches Recall and AI-powered Windows search for Copilot Plus PCs\\nTom WarrenApr 25\\n\\nNews\\nNews\\nAdidasâ€™ 3D-printed shoes are launching globally on May 2nd\\nAndrew LiszewskiApr 25\\n\\nNews\\nNews\\nBill Gatesâ€™ daughter Phoebe launched a shopping app\\nEmma RothApr 25\\n\\nE',\n",
              "  'score': 0.35608885},\n",
              " {'title': 'Where do you get your daily doze of interesting tech news? - Reddit',\n",
              "  'url': 'https://www.reddit.com/r/selfhosted/comments/ta41qf/where_do_you_get_your_daily_doze_of_interesting/',\n",
              "  'content': '3D Printing Artificial Intelligence & Machine Learning Computers & Hardware Consumer Electronics DIY Electronics Programming Software & Apps Streaming Services Tech News & Discussion*   Virtual & Augmented Reality\\n\\n\\nPop Culture\\n\\n\\nCelebrities Creators & Influencers Generations & Nostalgia Podcasts Streamers*   Tarot & Astrology\\n\\n\\nMovies & TV',\n",
              "  'score': 0.33796838}]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Putting all tools together, you can exploit an LLM model via Grok Cloud to integrate with..."
      ],
      "metadata": {
        "id": "aqm3degUK6hS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# embrace all the tools in a list\n",
        "tools = [arxiv, wikipedia, tavily]"
      ],
      "metadata": {
        "id": "0dP57KjfIXXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the LLM model\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm=ChatGroq(model=\"qwen-qwq-32b\")"
      ],
      "metadata": {
        "id": "aRziXvjHKuuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"What is Deep Learning?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE5bf5HmMGbS",
        "outputId": "e70a43a1-42e5-4c38-c2b3-ca109478fecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='\\n<think>\\nOkay, so I need to explain what deep learning is. Let me start by recalling what I know. Deep learning is part of machine learning, right? It\\'s related to neural networks, especially the ones with multiple layers. But wait, how exactly does it differ from regular neural networks? Maybe it\\'s when the networks are \"deep,\" meaning they have many layers, hence the name. But I should make sure that\\'s accurate.\\n\\nI remember that machine learning is about algorithms learning from data, and deep learning is a subset that uses these multi-layered neural networks. These networks are inspired by the human brain\\'s structure, with neurons and synapses. The layers in a deep learning network are called hidden layers, and each layer processes information in a way that builds on the previous layer. The inputs go through these layers, and each layer extracts features from the data. For example, in image recognition, the first layers might detect edges, then more complex shapes, and so on until the final layers can recognize objects.\\n\\nWait, but how does the learning process work? It uses backpropagation, right? The network adjusts the weights of connections between neurons based on the error it makes during training. The more data it\\'s trained on, the better it gets. Deep learning requires a lot of data, more than traditional machine learning models, because the complexity of the model needs sufficient data to prevent overfitting. \\n\\nApplications of deep learning include things like image and speech recognition, natural language processing (like in chatbots), self-driving cars, and recommendation systems. I should mention some common architectures, like convolutional neural networks (CNNs) for images, recurrent neural networks (RNNs) for sequences like text or time series, and maybe transformers, which are newer and used in things like GPT.\\n\\nI should also note that deep learning has limitations. It can be computationally intensive, requiring powerful GPUs or TPUs. It might also be a black box, making it hard to interpret how decisions are made. Overfitting is a risk if not enough data is used. Plus, there are ethical considerations around bias in training data leading to biased outcomes.\\n\\nHmm, maybe I should start with a definition, then break down the components: neural networks, how they learn, the role of layers, types of networks, applications, and then the pros and cons. That structure might make it clearer. I should also make sure to connect it back to machine learning as a subset. Let me check if I\\'m mixing up any terms. For instance, is a deep neural network (DNN) the same as a deep learning model? Yes, I think that\\'s correct. Also, mention that the term \"deep\" refers to the depth of layers, not the depth of knowledge. \\n\\nWait, maybe I should explain activation functions too? Like ReLU, sigmoid, etc., which introduce non-linearity so the network can learn complex patterns. Those are important because without them, the network couldn\\'t model non-linear relationships. Backpropagation uses gradient descent to optimize the weights by minimizing the loss function. The loss function measures how well the predictions match the actual data.\\n\\nOh, and transfer learning is another concept where pre-trained models are used as a starting point, which is common in deep learning. This is useful because training from scratch on a large dataset is time-consuming and resource-heavy. \\n\\nIncluding examples would help. For instance, AlphaGo using deep learning to beat humans at Go, or how Netflix uses it for recommendations. Maybe also mention some famous models like AlexNet, which was a milestone in image recognition. \\n\\nI should also touch on the difference between neural networks and deep learning. Neural networks can have just a few layers, but deep learning specifically uses many layers to achieve higher accuracy. The term \"deep learning\" became popular as computing power increased, allowing for training of these large models.\\n\\nWait, maybe I should clarify that not all neural networks are deep, but deep learning is characterized by the depth of the network. Also, the availability of big data and better algorithms (like better optimization techniques) has made deep learning feasible now compared to earlier times when it was too slow.\\n\\nSo putting it all together, the explanation should start with a definition, then explain neural networks, the concept of depth, how training works with backpropagation and gradient descent, types of architectures, applications, benefits, and limitations. Make sure to highlight that it\\'s a subset of machine learning and depends on large datasets and computational resources.\\n</think>\\n\\n**Deep Learning** is a subset of **machine learning** that employs artificial neural networks with multiple layers (hence \"deep\") to model and solve complex problems. It is designed to automatically learn and extract hierarchical features from raw data, enabling it to perform tasks such as image recognition, speech processing, and natural language understanding with high accuracy.\\n\\n---\\n\\n### **Key Components and Concepts**:\\n1. **Artificial Neural Networks (ANNs)**:\\n   - Inspired by the structure of the human brain, ANNs consist of interconnected nodes (neurons) organized into **layers**: an input layer, multiple **hidden layers**, and an output layer.\\n   - **Depth**: \"Deep\" refers to having many hidden layers (typically more than three), allowing the network to learn increasingly abstract representations of data.\\n\\n2. **Learning Process**:\\n   - **Training**: The network adjusts its internal parameters (weights and biases) through **backpropagation** and **gradient descent** to minimize a **loss function** (e.g., prediction error).\\n   - **Activation Functions**: Non-linear functions (e.g., ReLU, Sigmoid) are applied at each layer to enable the network to model complex patterns.\\n\\n3. **Hierarchical Feature Extraction**:\\n   - Lower layers detect simple features (e.g., edges in images).\\n   - Higher layers combine these to form complex patterns (e.g., shapes, objects).\\n\\n---\\n\\n### **Core Architectures**:\\n- **Convolutional Neural Networks (CNNs)**: Specialized for spatial data (e.g., images). Use convolutional layers to detect local patterns.\\n- **Recurrent Neural Networks (RNNs)**: Handle sequential data (e.g., text, time series) by maintaining \"memory\" of past inputs via loops.\\n- **Transformers**: Modern architecture for sequential data (e.g., language models like GPT), using attention mechanisms to weigh the importance of input elements.\\n- **Generative Adversarial Networks (GANs)**: Comprise two networks contesting each other to generate realistic data (e.g., images, videos).\\n\\n---\\n\\n### **Applications**:\\n- **Computer Vision**: Image classification (ResNet, YOLO), object detection, medical imaging.\\n- **Natural Language Processing (NLP)**: Translation (Google Translate), chatbots, sentiment analysis.\\n- **Speech Recognition**: Voice assistants (Siri, Alexa), speech-to-text systems.\\n- **Autonomous Systems**: Self-driving cars (Tesla), robotics.\\n- **Recommendation Systems**: Netflix, Spotify,ç”µå•† personalized recommendations.\\n\\n---\\n\\n### **Why Deep Learning Works**:\\n- **Scalability**: Excels with large datasets and computational resources (GPUs, TPUs).\\n- **Automatic Feature Learning**: Reduces the need for manual feature engineering (e.g., extracting edges in images).\\n- **State-of-the-Art Performance**: Achieves human-level or better accuracy in many tasks (e.g., AlphaGo, image recognition benchmarks).\\n\\n---\\n\\n### **Challenges and Limitations**:\\n- **Data Hunger**: Requires vast amounts of labeled training data.\\n- **Computational Cost**: Training large models needs significant processing power and time.\\n- **Black-Box Nature**: Models can be opaque, making it hard to interpret decisions (a challenge in critical applications like healthcare).\\n- **Overfitting Risk**: May memorize training data instead of generalizing, especially with insufficient data.\\n- **Ethical Concerns**: Bias in training data can lead to unfair outcomes (e.g., facial recognition systems).\\n\\n---\\n\\n### **History and Evolution**:\\n- Emerged with advancements in **computational power** (GPUs), **big data**, and algorithmic innovations (e.g., ReLU activation, dropout regularization).\\n- Landmark milestones include AlexNet (2012), which won the ImageNet competition, and more recent models like BERT (NLP) and DALL-E (image generation).\\n\\n---\\n\\n### **Relationship to Machine Learning**:\\n- **Deep learning** is a specialized form of **machine learning**, focusing on multi-layered neural networks. Traditional machine learning models (e.g., SVMs, decision trees) typically rely on manually engineered features and simpler architectures.\\n\\n---\\n\\n### **Key Takeaways**:\\n- Deep learning automates feature extraction and scales to large, unstructured data.\\n- It revolutionized fields like AI, healthcare, and robotics but requires careful handling of ethical and technical challenges.\\n\\nBy leveraging depth and scale, deep learning continues to push the boundaries of what machines can achieve.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1823, 'prompt_tokens': 15, 'total_tokens': 1838, 'completion_time': 4.447682336, 'prompt_time': 0.002882128, 'queue_time': 0.02007947, 'total_time': 4.450564464}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_3796682456', 'finish_reason': 'stop', 'logprobs': None}, id='run-5a1afb18-de82-462e-940e-93f6e1047aa7-0', usage_metadata={'input_tokens': 15, 'output_tokens': 1823, 'total_tokens': 1838})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bind llm with tools\n",
        "llm_with_tools = llm.bind_tools(tools=tools)"
      ],
      "metadata": {
        "id": "S02a-NlTMaDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = llm_with_tools.invoke(\"What isnew on AI?\")"
      ],
      "metadata": {
        "id": "J9os_Z-jN6Gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efmv3wofOAox",
        "outputId": "7465e0f7-3934-4267-bad4-43f36c0c08f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_gy9j', 'function': {'arguments': '{\"query\": \"latest advances in artificial intelligence\"}', 'name': 'arxiv'}, 'type': 'function'}, {'id': 'call_vjhk', 'function': {'arguments': '{\"query\": \"recent advancements in AI technology 2023\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 315, 'prompt_tokens': 329, 'total_tokens': 644, 'completion_time': 0.765895693, 'prompt_time': 0.025285404, 'queue_time': 0.179575552, 'total_time': 0.791181097}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_07cd5d759a', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-485e829d-6efc-4bb9-a1f4-411a3f5e827f-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'latest advances in artificial intelligence'}, 'id': 'call_gy9j', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'recent advancements in AI technology 2023'}, 'id': 'call_vjhk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 329, 'output_tokens': 315, 'total_tokens': 644})"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yE6rqIBIOf5K",
        "outputId": "099cabed-2c16-4971-e9ec-81602c96a041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QBheKJNaOhlx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}