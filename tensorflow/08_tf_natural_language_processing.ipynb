{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Natural Language Processing (NLP) with TensorFlow\n",
        "\n",
        "Natural Language Processing (NLP) is a field of artificial intelligence (AI) that focuses on enabling computers to understand, interpret, generate, and respond to human language in a way that is both meaningful and useful.\n",
        "\n",
        "### üß† In Simple Terms:\n",
        "NLP is how we teach computers to read, write, and understand human language‚Äîwhether that's spoken or written. It bridges the gap between how humans naturally communicate and how computers process information.\n",
        "\n",
        "### üîç Key Goals of NLP:\n",
        "\n",
        "- Understanding language (e.g., ‚ÄúWhat is the meaning of this sentence?‚Äù)\n",
        "\n",
        "- Generating language (e.g., chatbots or translation tools)\n",
        "\n",
        "- Classifying text (e.g., spam detection)\n",
        "\n",
        "- Extracting information (e.g., pulling names or dates from documents)\n",
        "\n",
        "- Conversational AI (e.g., Siri, Alexa, ChatGPT)\n",
        "\n",
        "### üõ†Ô∏è Examples of NLP in Action:\n",
        "\n",
        "- Google Translate: Translates text between languages.\n",
        "\n",
        "- Spam Filters: Detect spam based on words and phrases.\n",
        "\n",
        "- Chatbots: Understand and respond to customer questions.\n",
        "\n",
        "- Sentiment Analysis: Determines whether a sentence expresses a positive or negative opinion.\n",
        "\n",
        "- Search Engines: Interpret what users really mean by their queries.\n",
        "\n",
        "### üîó Relation to AI and ML:\n",
        "\n",
        "NLP often combines linguistics (rules of language) with machine learning (learning from data) so that systems can improve over time with more examples."
      ],
      "metadata": {
        "id": "tBXykNat1wIX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you may already know, for production-level deep learning or model training on large datasets, having a GPU (or using cloud services with GPUs) is much more efficient. So let us firstly learn about the specifications of the GPU we have at our disposal."
      ],
      "metadata": {
        "id": "4AGCkUZaFLfF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHmytjw10jUW",
        "outputId": "b5a61857-bf0d-4678-f29c-6a4af9ac5c1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U tensorflow==2.15.0 tensorflow-hub keras==2.15.0"
      ],
      "metadata": {
        "id": "Vp4aER7GKem7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step would be getting the helper functions created and developed by **Daniel Bourke** which have frequently been used in his own tutorials - Click [here](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/helper_functions.py) to open `helper_functions.py` on his github.\n",
        "\n",
        "P.E.: This notebook is kind of inspired by his work just like many others. So I would like to send him all my gratitude for the great he has done. To learn more about his tutorials, visit [Zero to Mastery (ZTM)](https://zerotomastery.io/)."
      ],
      "metadata": {
        "id": "PvaV7EQSGHGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download helper functions script\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jLEO4Q3EcNB",
        "outputId": "035b32cc-dc2e-4b6a-9a68-76c2c9c248d1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-10 21:47:34--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‚Äòhelper_functions.py.1‚Äô\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-05-10 21:47:34 (88.4 MB/s) - ‚Äòhelper_functions.py.1‚Äô saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "metadata": {
        "id": "r4d1JsiYHuh5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oh! What about data?\n",
        "\n",
        "Well, let us also download a dataset from Kaggle. You can read about the specifications of the dataset at [Natural Language Processing with Disaster Tweets](https://www.kaggle.com/c/nlp-getting-started/data)."
      ],
      "metadata": {
        "id": "gGOf3loXKVgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset\n",
        "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\"\n",
        "\n",
        "# Unzip data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY05OdeMH-wo",
        "outputId": "89e9931d-4e9d-4740-f59e-829410e0c4b9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-10 21:47:47--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.193.207, 173.194.194.207, 173.194.195.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.193.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‚Äònlp_getting_started.zip.1‚Äô\n",
            "\n",
            "\r          nlp_getti   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-05-10 21:47:47 (27.0 MB/s) - ‚Äònlp_getting_started.zip.1‚Äô saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize data\n",
        "\n",
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "g9NQrmjIKN3d",
        "outputId": "6ce7c8d1-1bb5-4502-f406-a7615b8babca"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-08755e0b-8fe5-4cb5-8d95-06ecdf875814\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08755e0b-8fe5-4cb5-8d95-06ecdf875814')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-08755e0b-8fe5-4cb5-8d95-06ecdf875814 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-08755e0b-8fe5-4cb5-8d95-06ecdf875814');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-def906c7-58a4-4645-9942-a3337bcd5e68\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-def906c7-58a4-4645-9942-a3337bcd5e68')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-def906c7-58a4-4645-9942-a3337bcd5e68 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 7613,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3137,\n        \"min\": 1,\n        \"max\": 10873,\n        \"num_unique_values\": 7613,\n        \"samples\": [\n          3796,\n          3185,\n          7769\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keyword\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 221,\n        \"samples\": [\n          \"injury\",\n          \"nuclear%20reactor\",\n          \"engulfed\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3341,\n        \"samples\": [\n          \"Oklahoma\",\n          \"Starling City\",\n          \"Trinidad and Tobago\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7503,\n        \"samples\": [\n          \"Three Homes Demolished in Unrecognized Arab Village - International Middle East Media Center http://t.co/ik8m4Yi9T4\",\n          \"Reid Lake fire prompts campground evacuation order http://t.co/jBODKM6rBU\",\n          \"FAAN orders evacuation of abandoned aircraft at MMA http://t.co/dEvYbnVXGQ via @todayng\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle train frame\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
        "train_df_shuffled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "yFvMVuf4NBLa",
        "outputId": "574856f4-411a-4bd0-d022-af7ddd113e24"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id      keyword               location  \\\n",
              "2644  3796  destruction                    NaN   \n",
              "2227  3185       deluge                    NaN   \n",
              "5448  7769       police                     UK   \n",
              "132    191   aftershock                    NaN   \n",
              "6845  9810       trauma  Montgomery County, MD   \n",
              "\n",
              "                                                   text  target  \n",
              "2644  So you have a new weapon that can cause un-ima...       1  \n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ¬â√õ√èThe...       1  \n",
              "132   Aftershock back to school kick off was great. ...       0  \n",
              "6845  in response to trauma Children of Addicts deve...       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-95587f2d-4b0e-43bc-8da5-35c358594523\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ¬â√õ√èThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95587f2d-4b0e-43bc-8da5-35c358594523')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-95587f2d-4b0e-43bc-8da5-35c358594523 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-95587f2d-4b0e-43bc-8da5-35c358594523');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ec1362d3-4291-434e-bc0b-925eb9bf5731\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ec1362d3-4291-434e-bc0b-925eb9bf5731')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ec1362d3-4291-434e-bc0b-925eb9bf5731 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df_shuffled",
              "summary": "{\n  \"name\": \"train_df_shuffled\",\n  \"rows\": 7613,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3137,\n        \"min\": 1,\n        \"max\": 10873,\n        \"num_unique_values\": 7613,\n        \"samples\": [\n          7061,\n          843,\n          10603\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keyword\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 221,\n        \"samples\": [\n          \"blazing\",\n          \"emergency\",\n          \"rescue\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3341,\n        \"samples\": [\n          \"617-BTOWN-BEATDOWN\",\n          \"Newcastle Upon Tyne, England\",\n          \"Federal Capital Territory\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7503,\n        \"samples\": [\n          \"This week first responders and DART members are participating in a four day intensive Technical Large Animal... http://t.co/tL93AOd3ER\",\n          \"My mom is watching a show about bridges breaking/falling and the people on them drowning in their cars aka one of my biggest fears ????\",\n          \"@NickLee8  i went to school in a bombed out East End of London3 families to one house no bathroom outside loo &amp; poor so whats yr point\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model we are going to train on the above dataset is expected to resolve the problem of classifying whether a Tweet is about a disaster or not."
      ],
      "metadata": {
        "id": "SM6EQRleQ5Ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the number of samples in each class\n",
        "# This can help us understand how well the dataset is balanced\n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "z3GSCvhVOL2p",
        "outputId": "e540a385-f320-4a4a-b4ad-46113e5daf50"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target\n",
              "0    4342\n",
              "1    3271\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3271</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlvK00hlRfef",
        "outputId": "35b50cf6-50d8-498b-99a0-1d29293224d7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Canberra's first Mr Fluffy homes demolition schedule released  http://t.co/B77T2QxDCS\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "Learning from the Legacy of a Catastrophic Eruption http://t.co/25sY9Y295L via @newyorker\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "@ChristyCroley Not in the works yet. Did you see the new Vela Short in Blaze? http://t.co/Q8rEoEVluE\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "RT NotExplained: The only known image of infamous hijacker D.B. Cooper. http://t.co/JlzK2HdeTG\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "@Judson1360 @XTRA1360 O-line and pass rush.  Rest of roster is stout barring injuries\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE!** When creating a random index, the top of the range is subtracted by 5 (`len(train_df)-5`) because the code following this line is accessing the next 5 rows starting at `random_index`. Subtracting 5 ensures that the selected index plus 4 more steps won't go out of bounds."
      ],
      "metadata": {
        "id": "6wt6cx5aUPSo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's split our data..."
      ],
      "metadata": {
        "id": "B96QuyY7WYVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1, # dedicate 10% of samples to validation set\n",
        "                                                                            random_state=42) # random state for reproducibility"
      ],
      "metadata": {
        "id": "SZ4_K4P4T3yN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE!** Using `.to_numpy()` converts a DataFrame to a NumPy array, which is often required by machine learning models (like in scikit-learn) that expect input as arrays, not pandas objects. It also improves performance slightly during training."
      ],
      "metadata": {
        "id": "1uQzjO_bdIEd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before feeding an NLP model with textual data, there are a series of preprocessing steps typically performed to clean, structure, and convert the text into a model-friendly format."
      ],
      "metadata": {
        "id": "hNujUGohePBS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### tf.keras.layers.TextVectorization\n",
        "\n",
        "`tf.keras.layers.TextVectorization` is a built-in TensorFlow Keras preprocessing layer used to convert raw text into numeric tensors‚Äîa crucial step before feeding text into neural networks.\n",
        "\n",
        "#### üîç What It Does\n",
        "The TextVectorization layer automates text standardization, tokenization, and vectorization, enabling a full text preprocessing pipeline inside the model."
      ],
      "metadata": {
        "id": "66o9t8oealMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "max_vocab_length = 10000\n",
        "max_length = 15\n",
        "\n",
        "# Other than the two values for max_tokens and output_sequence_length, the rest are default\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length, # how many words in the vocabulary (all of the different words in your text)\n",
        "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
        "                                    split=\"whitespace\", # how to split tokens\n",
        "                                    ngrams=None, # create groups of n-words?\n",
        "                                    output_mode=\"int\", # how to map tokens to numbers\n",
        "                                    output_sequence_length=max_length) # how long should the output sequence of tokens be?\n",
        "                                    # pad_to_max_tokens=True) # Not valid if using max_tokens=None"
      ],
      "metadata": {
        "id": "1a3Qpf6tdRjz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### text_vectorizer.adapt()\n",
        "\n",
        "#### üîç What it does:\n",
        "This step builds the vocabulary from your dataset (texts). Think of it like training the TextVectorization layer to understand what words exist in your data and how to index them.\n",
        "\n",
        "üß† Internally:\n",
        "- It standardizes the text (e.g., lowercases, removes punctuation, etc.).\n",
        "- Then it tokenizes the text into words (or characters, based on config).\n",
        "- Finally, it counts the frequency of tokens and keeps the most frequent `max_tokens` - further explanation will be given a bit later."
      ],
      "metadata": {
        "id": "IzdS7UL7hnNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Map TextVectorization instance text_vectorizer to data\n",
        "# In other words, fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "puowJZbIh5W-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### vectorized_text = text_vectorizer(texts)\n",
        "#### üîç What it does:\n",
        "This converts your raw text into a sequence of integers, where each word is replaced by its corresponding index from the vocabulary built during `adapt()`.\n",
        "\n",
        "#### üß† Internally:\n",
        "- Each text string is standardized and tokenized the same way as during `adapt()`.\n",
        "- Each token is replaced with its index (from the learned vocab).\n",
        "- If `output_sequence_length` is set, the sequences are padded/truncated to that length."
      ],
      "metadata": {
        "id": "SIP30KdkihaS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Step                      | Purpose                          | Outcome                        |\n",
        "|---------------------------|-----------------------------------|--------------------------------|\n",
        "| `text_vectorizer.adapt()`            | Learn vocabulary from data        | Builds word ‚Üí index mapping   |\n",
        "| `text_vectorizer(texts)`       | Vectorize text using vocab        | Converts text to integer sequences |\n"
      ],
      "metadata": {
        "id": "TBERU65Cjakx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random sample sentence and tokenize it\n",
        "sample_sentence = \"There is a flood in my street!\"\n",
        "vectorized_text = text_vectorizer([sample_sentence])\n",
        "vectorized_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r7LH2Yhjcml",
        "outputId": "3b44722a-dd6e-4070-9aef-babf49e6b1e9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[ 74,   9,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE!** Keep in mind that the vocabulary size of a certain text vectorizer (`text_vectorizer()` in this case) is determined by the number of distinct words present in the train data (`train_sentences` in this case) which is learned during adaptation (`text_vectorizer.adapt(train_sentences)`)."
      ],
      "metadata": {
        "id": "B0WfkAPInTQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10 out of all words present in train data\n",
        "text_vectorizer.get_vocabulary()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHLellsrmvyD",
        "outputId": "ed740327-baa6-43ea-dbc2-a42fe9eaf58b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "longer_sample_sentence = \"Since the test set has no labels and we need a way to evalaute our trained models, we'll split off some of the training data and create a validation set.\"\n",
        "longer_vectorized_text = text_vectorizer([longer_sample_sentence])\n",
        "longer_vectorized_text"
      ],
      "metadata": {
        "id": "7iRU0t8mkMPB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f8901b5-ebd8-4b9f-e519-27d3397fec79"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[ 216,    2, 1246,  284,   41,   40,    1,    7,   46,  162,    3,\n",
              "         147,    5,    1,  103]])>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is clearly noticeable that a longer sentence as in `longer_vectorized_text` has resulted in different values but the same sequence length (15) since `output_sequence_length=max_length=15` which is the average number of tokens per Tweet in the training set."
      ],
      "metadata": {
        "id": "FH7KfwZMpeDL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE!** Please note the 0's at the end of the returned tensor, which is because of setting `output_sequence_length=15`, that is, no matter the size of the sequence we pass to `text_vectorizer`, it always returns a sequence with a length of 15."
      ],
      "metadata": {
        "id": "LRSnEKIeuvYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find average number of tokens (words) in training Tweets\n",
        "avg_no_tokens = round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))\n",
        "avg_no_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07dPZnOvrykK",
        "outputId": "41807698-9c26-412a-99e1-332e74e68253"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also, as explained by Daniel himself...\n",
        "\n",
        "\"For `max_tokens` (the number of words in the vocabulary), multiples of 10,000 (10,000, 20,000, 30,000) or the exact number of unique words in your text (e.g. 32,179) are common values.\"\n",
        "\n",
        "However, in TensorFlow documentation the explanation below is given on `max_tokens`:\n",
        "\n",
        "\"Maximum size of the vocabulary for this layer. This should only be specified when adapting a vocabulary or when setting `pad_to_max_tokens=True`. Note that this vocabulary contains 1 OOV token, so the effective number of tokens is (`max_tokens - 1 - (1 if output_mode == \"int\" else 0)`).\""
      ],
      "metadata": {
        "id": "DG23-vNhtPhQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us try it also with some random sentences..."
      ],
      "metadata": {
        "id": "T1gDbcQL7tlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed to produce the same result/sentence\n",
        "# You can comment the line below to produce different random results/sentences\n",
        "seed = random.seed(42)\n",
        "\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original Sentence: {random_sentence}\")\n",
        "random_sentence\n",
        "print(f\"Vectorized Sentence: {text_vectorizer([random_sentence])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhKZKfD6pF3o",
        "outputId": "a3e81f39-8ba5-4c86-9f32-fc5d9b039038"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence: You are listening to LLEGASTE TU - TWISTER EL REY\n",
            "Vectorized Sentence: [[  12   22 1820    5    1 7321  358 1684 4739    0    0    0    0    0\n",
            "     0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is also another method which returns the current vocabulary of the layer:"
      ],
      "metadata": {
        "id": "SoQSpKAtC2SF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words = text_vectorizer.get_vocabulary()\n",
        "top_3_words = words[:3]\n",
        "top_3_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iXCaWvN8VNU",
        "outputId": "b4d5b5ee-d19e-4c56-fed7-c518f51ace0d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get vocab size\n",
        "vocab_size = text_vectorizer.vocabulary_size()\n",
        "print(vocab_size)\n",
        "\n",
        "# text_vectorizer.vocabulary_size() vs. len(text_vectorizer.get_vocabulary())\n",
        "vocab_size == len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BliFOLJDyRR",
        "outputId": "5803eb0a-7c46-436a-941f-2290c8de1a64"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create an Embedding Using an Embedding Layer"
      ],
      "metadata": {
        "id": "smnxdAuVtGZ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`tf.keras.layers.Embedding` is a key layer used in NLP models after vectorizing text, and it plays a crucial role in teaching the model how to understand words numerically."
      ],
      "metadata": {
        "id": "71fDKazwwLl2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What is `tf.keras.layers.Embedding`?\n",
        "It‚Äôs a lookup table that maps each word (represented by an integer index) to a dense vector of fixed size. If you're using the Embedding layer as part of a trainable model and you haven't trained it yet, here's what happens:\n",
        "\n",
        "üöß Before Training:\n",
        "\n",
        "- The Embedding layer assigns random vectors to each word index.\n",
        "- These vectors have no semantic meaning yet.\n",
        "- So, when you pass in a sentence like \"I love pizza\":\n",
        "\n",
        "  - It's tokenized and mapped to integers (e.g., `[12, 85, 210]`)\n",
        "  - Each integer gets a random embedding vector (e.g., shape `(3, 128)` if `output_dim=128`)\n",
        "  - These vectors are not meaningful yet ‚Äî just initial placeholders. In fact, they are learned during training to capture semantic meaning.\n",
        "\n",
        "üß† During Training:\n",
        "\n",
        "- The embedding vectors are updated via backpropagation.\n",
        "- The model learns to adjust these vectors so that:\n",
        "  - Words with similar contexts get closer in vector space.\n",
        "  - Semantic relationships start to emerge (e.g., \"king\" and \"queen\" become related).\n",
        "\n",
        "‚úÖ After Training:\n",
        "\n",
        "- The embeddings now encode semantics and syntax.\n",
        "- They can be visualized, analyzed, or reused in other models."
      ],
      "metadata": {
        "id": "I7gPiZiOwj-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                             output_dim=128, # set size of embedding vector\n",
        "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
        "                             input_length=max_length, # how long is each input\n",
        "                             name=\"embedding_1\")\n",
        "\n",
        "embedding"
      ],
      "metadata": {
        "id": "oOYRLoB8sdMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5cec55b-ab4a-4d71-fa95-b6dceeb75035"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.layers.core.embedding.Embedding at 0x7bf807c667d0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a random sentence from training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into numerical representation)\n",
        "rnd_sentence_embedding = embedding(text_vectorizer([random_sentence]))\n",
        "rnd_sentence_embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXiC6kLw1-wM",
        "outputId": "ab1bc262-6856-42ed-c083-cc60126a317a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "The cryptic words that guided pilots on the Hiroshima bombing mission http://t.co/FCe0K1Ihti      \n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-0.02149647, -0.02937633,  0.00342622, ..., -0.00879005,\n",
              "         -0.04194181, -0.04818932],\n",
              "        [ 0.03033764, -0.03137288,  0.03979082, ..., -0.00300504,\n",
              "         -0.03248589, -0.00583199],\n",
              "        [ 0.03978116,  0.03836597,  0.01918827, ..., -0.02279679,\n",
              "          0.04335965, -0.00362466],\n",
              "        ...,\n",
              "        [ 0.03428488, -0.00230921, -0.01177281, ..., -0.00837744,\n",
              "          0.02710113,  0.02781477],\n",
              "        [ 0.03428488, -0.00230921, -0.01177281, ..., -0.00837744,\n",
              "          0.02710113,  0.02781477],\n",
              "        [ 0.03428488, -0.00230921, -0.01177281, ..., -0.00837744,\n",
              "          0.02710113,  0.02781477]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's have a look at a single token's embedding..."
      ],
      "metadata": {
        "id": "3HPPKvI05D2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out a single token's embedding\n",
        "rnd_sentence_embedding[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sUHJ3vk3VA1",
        "outputId": "48ea522a-fd09-4539-e514-7ee81ed2c107"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              "array([-0.02149647, -0.02937633,  0.00342622, -0.04875937,  0.01049016,\n",
              "       -0.0016209 ,  0.01262898, -0.02825054, -0.01185179,  0.02357045,\n",
              "       -0.02679315,  0.03386286, -0.0406562 , -0.04717294,  0.00756089,\n",
              "       -0.02818035, -0.00385709,  0.04560195, -0.04534809, -0.01251936,\n",
              "        0.03380794, -0.01760418,  0.02386892, -0.0202601 ,  0.01390995,\n",
              "       -0.00929542,  0.02087094, -0.00366124,  0.00596233, -0.03519595,\n",
              "        0.04493082,  0.03867403,  0.04164764, -0.01133325, -0.01300217,\n",
              "        0.01502884,  0.01238938, -0.02950954, -0.04531053,  0.01939373,\n",
              "        0.04747811,  0.02187475, -0.03974015,  0.03498482,  0.0472417 ,\n",
              "       -0.01039379,  0.02388047,  0.03469309,  0.01214756, -0.00050084,\n",
              "        0.03851438, -0.03839665, -0.04137223, -0.00572108,  0.03308627,\n",
              "        0.0125089 ,  0.01831282,  0.00337977,  0.03702444, -0.03393061,\n",
              "        0.04728509, -0.00533633,  0.03613198, -0.00791448,  0.01165885,\n",
              "        0.03052888, -0.00058987, -0.03527973,  0.03813635,  0.02546315,\n",
              "       -0.04621897,  0.02006957, -0.02439301,  0.00047873, -0.00037599,\n",
              "       -0.03760893,  0.03153832,  0.03799072, -0.04671775,  0.01218159,\n",
              "       -0.01476971, -0.04143243, -0.02966694, -0.01690187, -0.02491552,\n",
              "       -0.0437225 ,  0.03385   , -0.03414904, -0.02580606, -0.04600474,\n",
              "        0.00936762, -0.0447425 ,  0.02939926,  0.04367847, -0.01101174,\n",
              "       -0.02588015, -0.00375106, -0.00394498,  0.01699474,  0.02415497,\n",
              "       -0.04680715, -0.01550188,  0.00830709, -0.00775826,  0.04991231,\n",
              "        0.03962591,  0.00705081, -0.01106985,  0.02334272,  0.03018976,\n",
              "       -0.03381892,  0.00768943,  0.03963352, -0.01944309, -0.04176271,\n",
              "        0.01516313,  0.02687665, -0.02571272, -0.00850836,  0.04546452,\n",
              "        0.01708356, -0.01198357, -0.00786327,  0.03180313, -0.0415609 ,\n",
              "       -0.00879005, -0.04194181, -0.04818932], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary:\n",
        "\n",
        "| Stage            | Meaning Captured? | Description                               |\n",
        "|------------------|-------------------|-------------------------------------------|\n",
        "| Before Training  | ‚ùå No              | Random vectors; no understanding          |\n",
        "| During Training  | ‚öôÔ∏è Gradual        | Vectors updated to reflect meaning        |\n",
        "| After Training   | ‚úÖ Yes            | Embeddings reflect word semantics         |\n"
      ],
      "metadata": {
        "id": "nbRMcR9bRphT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelling\n",
        "Having said all the long but sweet tale above, seems like the stage is set to buld our models. Conventionally, we will start with a baseline and then experimenting with other alternatives, we will try to improve performance based on the the results achieved."
      ],
      "metadata": {
        "id": "dAkJbx8G5eXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "More specifically, we'll be building the following:\n",
        "\n",
        "- **Model 0**: Naive Bayes (baseline)\n",
        "- **Model 1**: Feed-forward neural network (dense model)\n",
        "- **Model 2**: LSTM model\n",
        "- **Model 3**: GRU model\n",
        "- **Model 4**: Bidirectional-LSTM model\n",
        "- **Model 5**: 1D Convolutional Neural Network\n",
        "- **Model 6**: TensorFlow Hub Pretrained Feature Extractor\n",
        "- Model 7: Same as model 6 with 10% of training data"
      ],
      "metadata": {
        "id": "CMgN3_VdG4nM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 1: Dense Model\n"
      ],
      "metadata": {
        "id": "vmVu43d1rRLN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **baseline** in machine learning is a simple model or method used as a point of comparison for more complex models. It might be as basic as predicting the most frequent class (in classification) or the mean value (in regression). A **benchmark** refers to the standard performance level‚Äîoften set by the baseline or an existing best model‚Äîagainst which new models are evaluated."
      ],
      "metadata": {
        "id": "-5tB7-TLsvDb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In short, baselines provide simple starting points to evaluate whether a more advanced model is truly learning something meaningful."
      ],
      "metadata": {
        "id": "R2-OjBT7tV0O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The combination of actions we take below is widely used as a lightweight, interpretable baseline for tasks like spam detection, sentiment analysis, and topic classification."
      ],
      "metadata": {
        "id": "ZNG-rxmAvFgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create pipeline\n",
        "model0 = Pipeline([\n",
        "    (\"tfid\", TfidfVectorizer()),    # convert word to numerical representations\n",
        "    (\"classifier\", MultinomialNB()) # model the converted data\n",
        "])"
      ],
      "metadata": {
        "id": "uANIuupx5OAs"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit themodel\n",
        "model0.fit(train_sentences, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "623QXOu83h8T",
        "outputId": "8f412350-bbe6-4147-a7a8-4893a31449ef"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfid', TfidfVectorizer()), ('classifier', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"‚ñ∏\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"‚ñæ\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfid&#x27;, TfidfVectorizer()), (&#x27;classifier&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tfid&#x27;, TfidfVectorizer()), (&#x27;classifier&#x27;, MultinomialNB())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So when the model is fit, it actually learns about whether an e-mail for instance is *Spam* or *Ham* based on the frequency of word accurances (word count) collectively."
      ],
      "metadata": {
        "id": "I1C1BPv122Lu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For example, after fitting:\n",
        "\n",
        "- The model knows \"buy\" and \"now\" are common in class 1 (spam).\n",
        "- \"hello\" and \"friend\" are seen in class 0 (not spam).\n",
        "- It can now classify new texts like \"buy friend\" based on learned probabilities."
      ],
      "metadata": {
        "id": "masWWx5S4IH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "score_baseline = model0.score(val_sentences, val_labels)\n",
        "print(f\"Outcome: The baseline model achieves an accuracy of {score_baseline*100:.2f}%.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtsUhxCB3gGO",
        "outputId": "5e171687-bcdf-40dc-d74c-3df11e2a2ade"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outcome: The baseline model achieves an accuracy of 79.27%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction\n",
        "model0.predict(val_sentences[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7NK3STq4k1f",
        "outputId": "32714864-6f58-494b-d2a7-d1543307bcf4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get baseline predictions\n",
        "baseline_preds = model0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw2NRwhyKzOD",
        "outputId": "dca2d31b-12f5-4df6-85da-756b2c16b66b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Evaluation Function"
      ],
      "metadata": {
        "id": "svbltwAVA1X0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to evaluate accuracy, precision, recall, fscore\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def compute_results(y_true: list, y_pred: list) -> dict:\n",
        "  \"\"\"\n",
        "  Computes model accuracy, precision, recall and f1-score of a binary classification mode\n",
        "\n",
        "  Args:\n",
        "  ----\n",
        "  y_true (list): list of true labels\n",
        "  y_pred (ilst): list of predicted labels\n",
        "\n",
        "  Returns a dictionary of precision, recall, f1-score and accuracy\n",
        "  \"\"\"\n",
        "\n",
        "  # Compute model accuracy\n",
        "  accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "\n",
        "  # Compute model precision, recall and f1-score using \"weighted\" average\n",
        "  precision, recall, f1score, _ = precision_recall_fscore_support(y_true=y_true, y_pred=y_pred, average=\"weighted\")\n",
        "  results = {\"accuracy\": accuracy,\n",
        "             \"precision\": precision,\n",
        "             \"recall\": recall,\n",
        "             \"f1score\": f1score}\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "id": "TWBORfBQAC43"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE!** The term *weighted average* means that when combining the precision, recall, and F1-score values across different classes, each class contributes to the final score proportionally to its support ‚Äî i.e., the number of true instances for that class in the dataset."
      ],
      "metadata": {
        "id": "l1w1dCjqJGVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Produce baseline results\n",
        "baseline_results = compute_results(y_true=val_labels, y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n16diOgQCSjv",
        "outputId": "f81771dc-53ee-45f1-b927-48e419a79dd3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1score': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To keep track of the results achieved by different models and configurations, which are mainly based TensorFlow framework, it would be wise to use `tf.keras.callbacks.TensorBoard()` and create a tensorboard callback."
      ],
      "metadata": {
        "id": "YYuTYgKRBmsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "\n",
        "def create_tb_callback(dir_name, experiment_name):\n",
        "  \"\"\"\n",
        "  Creates a TensorBoard callback instand to store log files.\n",
        "\n",
        "  Stores log files with the filepath:\n",
        "    \"dir_name/experiment_name/current_datetime/\"\n",
        "\n",
        "  Args:\n",
        "  -----\n",
        "    dir_name: target directory to store TensorBoard log files\n",
        "    experiment_name: name of experiment directory (e.g. efficientnet_model_1)\n",
        "\n",
        "  Returns a TensorBoard callback.\n",
        "  \"\"\"\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tb_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tb_callback"
      ],
      "metadata": {
        "id": "MaFDEz2AjwFb"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory to Save logs\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "metadata": {
        "id": "A4vX-seFDGzi"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 2: Dense Model"
      ],
      "metadata": {
        "id": "2Wi12tjWGvFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model with the Functional API\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\") # inputs are 1-dimensional since they're raw strings\n",
        "\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GlobalAveragePooling1D()(x) # [Optional] lower the dimensionality of the embedding (try running the model without this layer and see what happens)\n",
        "\n",
        "# Create the output layer\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # want binary outputs so use sigmoid activation\n",
        "\n",
        "# Construct the model\n",
        "model1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")"
      ],
      "metadata": {
        "id": "MHkmFYCQFcOJ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model1.compile(loss=\"binary_crossentropy\",\n",
        "               optimizer=tf.keras.optimizers.Adam(),\n",
        "               metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "p9DatNB7IsTL"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tO8u_LuLsf1",
        "outputId": "159a6221-0aff-4841-8c42-394a99a1bcab"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVe  (None, 15)                0         \n",
            " ctorization)                                                    \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 128)               0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1280129 (4.88 MB)\n",
            "Trainable params: 1280129 (4.88 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our model is compiled, let us fit it to our training data for a few epochs..."
      ],
      "metadata": {
        "id": "W2MeWni8Mt_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                             experiment_name=\"simple_dense_model\")]\n",
        "\n",
        "model1_history = model1.fit(\n",
        "    train_sentences,\n",
        "    train_labels,\n",
        "    epochs=6,\n",
        "    validation_data=(val_sentences, val_labels),\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6wskoCmLu4z",
        "outputId": "c8c8c596-3681-45b9-cf47-c2ee437036f2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/simple_dense_model/20250510-214751\n",
            "Epoch 1/6\n",
            "215/215 [==============================] - 10s 35ms/step - loss: 0.6089 - accuracy: 0.7002 - val_loss: 0.5356 - val_accuracy: 0.7572\n",
            "Epoch 2/6\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.4406 - accuracy: 0.8193 - val_loss: 0.4690 - val_accuracy: 0.7887\n",
            "Epoch 3/6\n",
            "215/215 [==============================] - 7s 33ms/step - loss: 0.3459 - accuracy: 0.8612 - val_loss: 0.4590 - val_accuracy: 0.7927\n",
            "Epoch 4/6\n",
            "215/215 [==============================] - 7s 33ms/step - loss: 0.2845 - accuracy: 0.8915 - val_loss: 0.4645 - val_accuracy: 0.7887\n",
            "Epoch 5/6\n",
            "215/215 [==============================] - 6s 26ms/step - loss: 0.2376 - accuracy: 0.9127 - val_loss: 0.4772 - val_accuracy: 0.7861\n",
            "Epoch 6/6\n",
            "215/215 [==============================] - 5s 23ms/step - loss: 0.2015 - accuracy: 0.9285 - val_loss: 0.5003 - val_accuracy: 0.7848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the results\n",
        "model1.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "id": "Zjx_7eBHNubD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88c5c870-536e-4839-f24b-af816cbafaa7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step - loss: 0.5003 - accuracy: 0.7848\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5003155469894409, 0.7847769260406494]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding.weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHj3xXSgGPBo",
        "outputId": "961ceb7f-cdc2-444e-a9b9-8e538a6f794b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'embedding_1/embeddings:0' shape=(10000, 128) dtype=float32, numpy=\n",
              " array([[ 0.01675929, -0.01866265, -0.01172006, ...,  0.00767409,\n",
              "          0.04422944,  0.0468277 ],\n",
              "        [-0.03171993, -0.05382708,  0.0260134 , ..., -0.04385087,\n",
              "         -0.03489233, -0.00707702],\n",
              "        [-0.02946997, -0.03839888, -0.00826059, ...,  0.00028563,\n",
              "         -0.03272296, -0.03984141],\n",
              "        ...,\n",
              "        [-0.03674648,  0.03967234, -0.02804722, ..., -0.03340916,\n",
              "         -0.02385895,  0.0039628 ],\n",
              "        [-0.03436453, -0.0385634 , -0.06618966, ...,  0.06185308,\n",
              "          0.04328023, -0.00472206],\n",
              "        [-0.05327442, -0.05338037, -0.0960642 , ...,  0.07603045,\n",
              "          0.10914066,  0.07501896]], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_weights = model1.get_layer(\"embedding_1\").get_weights()[0]\n",
        "embedding_weights, embedding_weights.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tplLOhObGXcu",
        "outputId": "751b9efb-85a6-4ca9-a5ef-5dba1e1533f6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 0.01675929, -0.01866265, -0.01172006, ...,  0.00767409,\n",
              "          0.04422944,  0.0468277 ],\n",
              "        [-0.03171993, -0.05382708,  0.0260134 , ..., -0.04385087,\n",
              "         -0.03489233, -0.00707702],\n",
              "        [-0.02946997, -0.03839888, -0.00826059, ...,  0.00028563,\n",
              "         -0.03272296, -0.03984141],\n",
              "        ...,\n",
              "        [-0.03674648,  0.03967234, -0.02804722, ..., -0.03340916,\n",
              "         -0.02385895,  0.0039628 ],\n",
              "        [-0.03436453, -0.0385634 , -0.06618966, ...,  0.06185308,\n",
              "          0.04328023, -0.00472206],\n",
              "        [-0.05327442, -0.05338037, -0.0960642 , ...,  0.07603045,\n",
              "          0.10914066,  0.07501896]], dtype=float32),\n",
              " (10000, 128))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions in the form of probabilities\n",
        "model1_pred_probs = model1.predict(val_sentences)\n",
        "model1_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZ79dSX1GiS_",
        "outputId": "df56f34d-721c-45b6-80e3-152cfffe7d74"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.40704438],\n",
              "       [0.747801  ],\n",
              "       [0.9986084 ],\n",
              "       [0.07432393],\n",
              "       [0.06996122],\n",
              "       [0.9569832 ],\n",
              "       [0.9307086 ],\n",
              "       [0.9969457 ],\n",
              "       [0.98479366],\n",
              "       [0.27558458]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1_pred_probs[:10].round()  # round up/down"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U85fLjC9LOkP",
        "outputId": "16538c2f-02ca-432e-9ba4-ffed029bb558"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model1_preds = tf.squeeze(model1_pred_probs.round())\n",
        "\n",
        "# OR alternatively\n",
        "model1_preds = model1_pred_probs.round().squeeze()\n",
        "\n",
        "model1_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3_x4fHXLSTf",
        "outputId": "3b79e5d3-d012-4348-b353-2371d26573ea"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the predictions are produced in the form of 0/1 values (binary classification), we can compare them to the ground truth values and produce results for different metrics."
      ],
      "metadata": {
        "id": "DA5vqw2BNiFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute model_1 metrics\n",
        "model1_results = compute_results(y_true=val_labels,\n",
        "                                 y_pred=model1_preds)\n",
        "model1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1RkQeZpLm63",
        "outputId": "688ab0ff-70b2-4fa3-8a7e-3eac1fce5c5e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.4776902887139,\n",
              " 'precision': 0.7880247798695493,\n",
              " 'recall': 0.7847769028871391,\n",
              " 'f1score': 0.7823139263800303}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us compare the results achieved by the two models so far..."
      ],
      "metadata": {
        "id": "S42c8C23GBjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.array(list(model1_results.values())) >= np.array(list(baseline_results.values()))"
      ],
      "metadata": {
        "id": "xDdNCK0eOUHX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d75a2bfd-9eb5-483d-b8ec-f1c8424bf7da"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_models(model1_res, model2_res):\n",
        "  comp_res = np.array(list(model1_res.values())) >= np.array(list(model2_res.values()))\n",
        "  for key, value in model1_res.items():\n",
        "    print(f\"Baseline {key}: {value:.2f}, New Model {key}: {model2_res[key]:.2f}, Difference: {model2_res[key] - value:.2f}\")\n",
        "\n",
        "compare_models(baseline_results, model1_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6D6eLYWhGYPl",
        "outputId": "a5e94188-9c68-4ad2-a78a-0560ec2b7ca1"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New Model accuracy: 78.48, Difference: -0.79\n",
            "Baseline precision: 0.81, New Model precision: 0.79, Difference: -0.02\n",
            "Baseline recall: 0.79, New Model recall: 0.78, Difference: -0.01\n",
            "Baseline f1score: 0.79, New Model f1score: 0.78, Difference: -0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first model (`model1`) contained an embedding layer (`embedding`) which learned a way of representing words as feature vectors by passing over the training data."
      ],
      "metadata": {
        "id": "aCVXtxhQR2ox"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize Embeddings\n",
        "Let us now visualize the embedding our model has learned."
      ],
      "metadata": {
        "id": "oS2tlxGPSQxA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "But first let me ask you a question...\n",
        "\n",
        "**Question:** Have you ever thought to yourself what the differences between the embedding learned during training and the embedding model we use to transform texts and words into their numerical representations e.g., RAG systems?\n",
        "\n",
        "**Answer:** The former ones are task-specific embeddings that are learned as part of training a deep learning model ‚Äî such as a classifier or a language model ‚Äî produced by backpropagation during supervised training while the latter ones are precomputed semantic embeddings used to represent chunks of documents, questions, or passages generated by pretrained embedding models like:\n",
        "\n",
        "- OpenAI's text-embedding-ada-002\n",
        "- Hugging Face's sentence-transformers\n",
        "- BERT-based encoders"
      ],
      "metadata": {
        "id": "qmPzsnqDf9Iw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize our embedding using the **[TensorFlow Embedding Projector Tool](http://projector.tensorflow.org/)**, we will need two objects/files:\n",
        "- The embedding vectors (same as embedding weights).\n",
        "- The meta data of the embedding vectors (the words they represent - our vocabulary)."
      ],
      "metadata": {
        "id": "mEHbGq11nBXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Code below is adapted from: https://www.tensorflow.org/tutorials/text/word_embeddings#retrieve_the_trained_word_embeddings_and_save_them_to_disk\n",
        "# import io\n",
        "\n",
        "# # Create output writers\n",
        "# out_v = io.open(\"embedding_vectors.tsv\", \"w\", encoding=\"utf-8\")\n",
        "# out_m = io.open(\"embedding_metadata.tsv\", \"w\", encoding=\"utf-8\")\n",
        "\n",
        "# # Write embedding vectors and words to file\n",
        "# for num, word in enumerate(words):\n",
        "#   if num == 0:\n",
        "#      continue # skip padding token\n",
        "#   vec = embedding_weights[num]\n",
        "#   out_m.write(word + \"\\n\") # write words to file\n",
        "#   out_v.write(\"\\t\".join([str(x) for x in vec]) + \"\\n\") # write corresponding word vector to file\n",
        "# out_v.close()\n",
        "# out_m.close()\n",
        "\n",
        "# # Download files locally to upload to Embedding Projector\n",
        "# try:\n",
        "#   from google.colab import files\n",
        "# except ImportError:\n",
        "#   pass\n",
        "# else:\n",
        "#   files.download(\"embedding_vectors.tsv\")\n",
        "#   files.download(\"embedding_metadata.tsv\")"
      ],
      "metadata": {
        "id": "8lFEie8cLzVt"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Once you have downloaded the embedding vectors and metadata, you can visualize them using **Embedding Vector Tool**:\n",
        "\n",
        "1. Go to http://projector.tensorflow.org/\n",
        "2. Click on \"Load data\"\n",
        "3. Upload the two files you downloaded (`embedding_vectors.tsv` and `embedding_metadata.tsv`)\n",
        "4. Explore\n",
        "5. Optional: You can share the data you've created by clicking \"Publish\""
      ],
      "metadata": {
        "id": "-2_tK-1_V-EL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recurrent Neural Networks (RNN's)"
      ],
      "metadata": {
        "id": "qdBYfpxdYLWt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For our next series of modelling experiments we're going to be using a special kind of neural network called a **Recurrent Neural Network (RNN)**. Recurrent Neural Networks (RNNs) are a type of neural network architecture designed for sequence data. Unlike traditional feedforward networks, RNNs have a memory of previous inputs, which allows them to process data where context or order matters ‚Äî such as time series, text, or speech."
      ],
      "metadata": {
        "id": "QgfVvNgXYb-h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In other words, RNNs process one element of a sequence at a time and maintain a hidden state that gets updated at each step. This hidden state acts like memory, carrying information from previous inputs forward to influence future predictions."
      ],
      "metadata": {
        "id": "fAmIShfqcRBg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recurrent neural networks can be used for a number of sequence-based problems:\n",
        "\n",
        "- **One to one:** one input, one output, such as image classification.\n",
        "- **One to many:** one input, many outputs, such as image captioning (image input, a sequence of text as caption output).\n",
        "- **Many to one:** many inputs, one outputs, such as text classification (classifying a Tweet as real diaster or not real diaster).\n",
        "- **Many to many:** many inputs, many outputs, such as machine translation (translating English to Spanish) or speech to text (audio wave as input, text as output) - taken from [Zero to Mastery TensorFlow for Deep Learning](https://dev.mrdbourke.com/tensorflow-deep-learning/08_introduction_to_nlp_in_tensorflow/)."
      ],
      "metadata": {
        "id": "xJpKx8dafPQa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Challenges:\n",
        "\n",
        "- Vanishing/exploding gradient problems for long sequences.\n",
        "- Limited long-term memory (this led to variants like LSTM and GRU).\n",
        "  - Long short-term memory cells (LSTMs).\n",
        "  - Gated recurrent units (GRUs).\n",
        "  - Bidirectional RNN's (passes forward and backward along a sequence, left to right and right to left)."
      ],
      "metadata": {
        "id": "iXPeuxPncns6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Use Cases:\n",
        "\n",
        "- Language modeling\n",
        "- Time series prediction\n",
        "- Speech recognition\n",
        "- Machine translation (as part of encoder-decoder models)"
      ],
      "metadata": {
        "id": "Myvr4AoncvpS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 2: LSTM"
      ],
      "metadata": {
        "id": "x52Um6MkhqKU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main difference comparing to the previous model is that we will add an LSTM layer between the embedding layer and the output. Even though the previous trained embeddings will not be reused but replaced with a new one, the text vectorizer can be reused as it won't update during training."
      ],
      "metadata": {
        "id": "MWsNM7xAiS7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model2_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                    output_dim=128,\n",
        "                                    embeddings_initializer=\"uniform\",\n",
        "                                    input_length=max_length,\n",
        "                                    name=\"embedding_2\")"
      ],
      "metadata": {
        "id": "EQLD-oJOpfib"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create LSTM model\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model2_embedding(x)\n",
        "print(x.shape)\n",
        "# x = layers.LSTM(64, return_sequences=True)(x) # return vector for each word in the Tweet (you can stack RNN cells as long as return_sequences=True)\n",
        "x = layers.LSTM(64)(x) # return vector for whole sequence (only the last output from the final time step).\n",
        "                       # use when you only need the summary of the input sequence\n",
        "print(x.shape)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hx6NP_nepCbY",
        "outputId": "ccb95d70-1e8a-4f1c-8151-8d41c263ebbb"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 15, 128)\n",
            "(None, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "FlrkW1fipc3X"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgP2dk9y5jzZ",
        "outputId": "34b45a23-a341-466c-e04f-060518d5e3c3"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVe  (None, 15)                0         \n",
            " ctorization)                                                    \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1329473 (5.07 MB)\n",
            "Trainable params: 1329473 (5.07 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Formula to compute the number of params:\n",
        "```\n",
        "params = 4 * ((size_of_input + 1) * size_of_output + size_of_output^2)\n",
        "```\n",
        "Or covering with NN concepts and terminology:\n",
        "```\n",
        "num_params = [(num_units + input_dim + 1) * num_units] * 4\n",
        "```"
      ],
      "metadata": {
        "id": "UeH8HM3T7HUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit model\n",
        "model2_history = model2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"LSTM\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUwn5JNM58TA",
        "outputId": "4b0d2421-2467-4d45-d923-e1566580806e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/LSTM/20250510-214834\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 11s 38ms/step - loss: 0.5125 - accuracy: 0.7430 - val_loss: 0.4575 - val_accuracy: 0.7822\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 6s 30ms/step - loss: 0.3160 - accuracy: 0.8718 - val_loss: 0.5103 - val_accuracy: 0.7756\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 7s 35ms/step - loss: 0.2166 - accuracy: 0.9175 - val_loss: 0.5949 - val_accuracy: 0.7690\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 6s 30ms/step - loss: 0.1495 - accuracy: 0.9483 - val_loss: 0.6486 - val_accuracy: 0.7677\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 8s 35ms/step - loss: 0.1038 - accuracy: 0.9634 - val_loss: 0.8199 - val_accuracy: 0.7612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on test/validation\n",
        "model2_pred_probs = model2.predict(val_sentences)\n",
        "model2_pred_probs.shape, model2_pred_probs[:10] # view the first 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rh1yscY89up",
        "outputId": "71c4f3b1-fda4-46f9-8e06-2d85ff048e2f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((762, 1),\n",
              " array([[0.01214359],\n",
              "        [0.7536886 ],\n",
              "        [0.999332  ],\n",
              "        [0.12561704],\n",
              "        [0.00793038],\n",
              "        [0.9996916 ],\n",
              "        [0.857947  ],\n",
              "        [0.99984264],\n",
              "        [0.9997174 ],\n",
              "        [0.20223187]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn prediction probabilities into prediction classes\n",
        "model2_preds = tf.squeeze(tf.round(model2_pred_probs))\n",
        "model2_preds[:10]"
      ],
      "metadata": {
        "id": "VdIawYu09bv5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d12cdbe-d8fa-4a3d-b5d8-dd4224bf15ca"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2 Resuls\n",
        "model2_results = compute_results(y_true=val_labels, y_pred=model2_preds)\n",
        "model2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tmlhn7SRgoyJ",
        "outputId": "c2cf381f-9cb3-4456-ba67-11dec642a5d4"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.11548556430446,\n",
              " 'precision': 0.7618883943071393,\n",
              " 'recall': 0.7611548556430446,\n",
              " 'f1score': 0.7593763358258424}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alright! We all remember that the first dense model could not excel in performance compared to the baseline. Now let us compare the baseline model with this new one in order to understand whether a better performance is achieved or not..."
      ],
      "metadata": {
        "id": "MEJdi87cjViJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparison: model 1 vs. model 2\n",
        "compare_models(model1_results, model2_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OA59MVdKi9RB",
        "outputId": "49e596bd-a262-49d1-9b94-bf3575d5e3de"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 78.48, New Model accuracy: 76.12, Difference: -2.36\n",
            "Baseline precision: 0.79, New Model precision: 0.76, Difference: -0.03\n",
            "Baseline recall: 0.78, New Model recall: 0.76, Difference: -0.02\n",
            "Baseline f1score: 0.78, New Model f1score: 0.76, Difference: -0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahh!\n",
        "No, still no improvement achieved! üò¢"
      ],
      "metadata": {
        "id": "VnTaidi4k82W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No other choice left but trying another approach!"
      ],
      "metadata": {
        "id": "jemtCDIDlP1V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 3: GRU (Gated Recurrent Units)"
      ],
      "metadata": {
        "id": "FOqISxMGlXoN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRU is a type of Recurrent Neural Network (RNN) that addresses the vanishing gradient problem and improves the efficiency when processing sequential data. Gated Recurrent Units (GRUs) are similar to Long Short-Term Memory (LSTM) networks but have a simpler structure which effectively contributes to faster to training."
      ],
      "metadata": {
        "id": "EDkn7t8ul6kI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model3_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_3\")"
      ],
      "metadata": {
        "id": "z7Ki74F5jHdo"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build an RNN using the GRU cell\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model3_embedding(x)\n",
        "# x = layers.GRU(64, return_sequences=True) # stacking recurrent cells requires return_sequences=True\n",
        "x = layers.GRU(64)(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer after GRU cell\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
      ],
      "metadata": {
        "id": "MP_Jjp9cnAVA"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile GRU model\n",
        "model3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "xBppjZ4enBMo"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary of the GRU model\n",
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbdct7C3nReL",
        "outputId": "bacac6de-b662-4ac5-fd04-c61ef77f6375"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVe  (None, 15)                0         \n",
            " ctorization)                                                    \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1317313 (5.03 MB)\n",
            "Trainable params: 1317313 (5.03 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit model\n",
        "model3_history = model3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"GRU\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtEETv_ZnSOY",
        "outputId": "dcadf4f0-0eba-411a-cab9-b6726d53b9ec"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/GRU/20250510-214919\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 13s 46ms/step - loss: 0.5215 - accuracy: 0.7370 - val_loss: 0.4539 - val_accuracy: 0.7808\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 7s 35ms/step - loss: 0.3162 - accuracy: 0.8707 - val_loss: 0.5007 - val_accuracy: 0.7822\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 6s 30ms/step - loss: 0.2172 - accuracy: 0.9169 - val_loss: 0.5750 - val_accuracy: 0.7690\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 8s 35ms/step - loss: 0.1570 - accuracy: 0.9445 - val_loss: 0.6279 - val_accuracy: 0.7782\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 7s 32ms/step - loss: 0.1208 - accuracy: 0.9581 - val_loss: 0.6199 - val_accuracy: 0.7690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on test/validation data\n",
        "model3_pred_probs = model3.predict(val_sentences)\n",
        "model3_pred_probs.shape, model3_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Xe-XLfMneqo",
        "outputId": "b53238a1-7917-41e1-b66a-4f5294eb4d2b"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((762, 1),\n",
              " array([[0.32572207],\n",
              "        [0.8714175 ],\n",
              "        [0.99541366],\n",
              "        [0.14191122],\n",
              "        [0.00663859],\n",
              "        [0.99057794],\n",
              "        [0.7328347 ],\n",
              "        [0.99712884],\n",
              "        [0.99682105],\n",
              "        [0.4661461 ]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn prediction probabilities into prediction classes\n",
        "model3_preds = tf.squeeze(tf.round(model3_pred_probs))\n",
        "model3_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDXmeKxWny-_",
        "outputId": "56739c25-0526-4ca1-9f66-114e19426d7a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 3 Resuls\n",
        "# Calcuate model_3 results\n",
        "model3_results = compute_results(y_true=val_labels,\n",
        "                                    y_pred=model3_preds)\n",
        "model3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIsISJdEoBCI",
        "outputId": "eaf402fd-b2d1-4adb-bfb7-61bf00026ba5"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.9028871391076,\n",
              " 'precision': 0.7690112053301029,\n",
              " 'recall': 0.7690288713910761,\n",
              " 'f1score': 0.7679657243023703}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compare_models(baseline_results, model3_results)\n",
        "# compare_models(model2_results, model3_results)"
      ],
      "metadata": {
        "id": "f60M9N2NoRav",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15257b4e-2610-4d1a-f415-fe723221940f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New Model accuracy: 76.90, Difference: -2.36\n",
            "Baseline precision: 0.81, New Model precision: 0.77, Difference: -0.04\n",
            "Baseline recall: 0.79, New Model recall: 0.77, Difference: -0.02\n",
            "Baseline f1score: 0.79, New Model f1score: 0.77, Difference: -0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 4: Bidirectonal RNN"
      ],
      "metadata": {
        "id": "h55EfLTfXQwe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Bidirectional Recurrent Neural Network (Bi-RNN) processes sequential data by analyzing it in both forward and backward directions. Unlike standard RNNs, which only look at past context, Bi-RNNs capture information from both the past and future, which is crucial for tasks like natural language processing where understanding the entire context is necessary.\n",
        "\n",
        "It is also impoprtant to note that improvement in performance often comes at the cost of longer training times and increased model parameters - if there is any improvement of course - (since the model goes left to right and right to left, the number of trainable parameters doubles)."
      ],
      "metadata": {
        "id": "TMiNq9nDX-6W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use `tensorflow.keras.layers.Bidirectional` class making the existing RNNs bidirectional."
      ],
      "metadata": {
        "id": "AnFZexLOZWS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model4_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_4\")\n",
        "\n",
        "# Build a Bidirectional RNN in TensorFlow\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model4_embedding(x)\n",
        "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional\")"
      ],
      "metadata": {
        "id": "LvyCvj7YWyJA"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model4.compile(loss=\"binary_crossentropy\",\n",
        "               optimizer=tf.keras.optimizers.Adam(),\n",
        "               metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "97MWVJJlaTo3"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit model\n",
        "model4.fit(train_sentences,\n",
        "           train_labels,\n",
        "           epochs=5,\n",
        "           validation_data=(val_sentences, val_labels),\n",
        "           callbacks=[create_tensorboard_callback(SAVE_DIR, \"bidirectional_RNN\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J37_lPhGa4BZ",
        "outputId": "723e215f-22f0-49eb-df9f-4a00736b5549"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/bidirectional_RNN/20250510-215005\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 15s 50ms/step - loss: 0.5090 - accuracy: 0.7435 - val_loss: 0.4559 - val_accuracy: 0.7848\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 9s 44ms/step - loss: 0.3145 - accuracy: 0.8730 - val_loss: 0.5090 - val_accuracy: 0.7703\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.2153 - accuracy: 0.9174 - val_loss: 0.5561 - val_accuracy: 0.7717\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 10s 44ms/step - loss: 0.1513 - accuracy: 0.9489 - val_loss: 0.6420 - val_accuracy: 0.7822\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 10s 44ms/step - loss: 0.1091 - accuracy: 0.9628 - val_loss: 0.6954 - val_accuracy: 0.7559\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bf802418c90>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test/validation data with bidirectional RNN\n",
        "model4_pred_probs = model4.predict(val_sentences)\n",
        "model4_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff7PkPCIcxT2",
        "outputId": "3865c7b6-99e0-403e-b97e-f98092ef0cdf"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 7ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.24479653],\n",
              "       [0.9449209 ],\n",
              "       [0.9995634 ],\n",
              "       [0.25350705],\n",
              "       [0.00982348],\n",
              "       [0.9972099 ],\n",
              "       [0.9779234 ],\n",
              "       [0.999616  ],\n",
              "       [0.9997785 ],\n",
              "       [0.41626948]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn prediction probabilities into prediction classes\n",
        "model4_preds = tf.squeeze(tf.round(model4_pred_probs))\n",
        "model4_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raRacrbydIjc",
        "outputId": "a3bd9885-4af3-4466-d84b-c8d374b26b8b"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute bidirectional RNN results\n",
        "model4_results = compute_results(y_true=model4_preds, y_pred=val_labels)\n",
        "model4_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X70TaqJ8dqIB",
        "outputId": "1ba63326-da47-4608-a1c2-9300f9413316"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.59055118110236,\n",
              " 'precision': 0.7559055118110236,\n",
              " 'recall': 0.7559055118110236,\n",
              " 'f1score': 0.7559055118110236}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare results\n",
        "compare_models(baseline_results, model4_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUy_T6dReRy-",
        "outputId": "04309ab2-d56e-4076-f432-a2440add33ca"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New Model accuracy: 75.59, Difference: -3.67\n",
            "Baseline precision: 0.81, New Model precision: 0.76, Difference: -0.06\n",
            "Baseline recall: 0.79, New Model recall: 0.76, Difference: -0.04\n",
            "Baseline f1score: 0.79, New Model f1score: 0.76, Difference: -0.03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Convolutional Neural Networks (CNNs) for Text\n",
        "\n",
        "CNNs are a type of deep learning model primarily used for image recognition and processing. They are inspired by the visual cortex of animals, where neurons are organized to respond to specific areas of the visual field. CNNs use \"filters\" (or kernels) to detect patterns and features in images, and these filters are learned automatically during training."
      ],
      "metadata": {
        "id": "vUCckO4tfaXh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How it Works (Simplified):\n",
        "\n",
        "- **Input:** An image is fed into the network.\n",
        "Convolutional Layers: Filters are applied to the input image, detecting features and creating feature maps.\n",
        "- **Pooling Layers:** Reduce the size of the feature maps.\n",
        "- **Non-Linearity:** Activation functions (like ReLU) introduce non-linearity, allowing the network to learn complex patterns.\n",
        "- **Fully Connected Layers:** These layers classify the learned features into different categories.\n",
        "- **Output:** The network outputs a prediction, like the object in the image or the probability of it belonging to a certain category."
      ],
      "metadata": {
        "id": "EszHCYOIijTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, we will simply use a `tensorflow.keras.layers.Conv1D()` layer followed by a `tensorflow.keras.layers.GlobablMaxPool1D()` layer instead of using."
      ],
      "metadata": {
        "id": "xq3MjPr2f7t4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 5: Convolutional (Conv1D)"
      ],
      "metadata": {
        "id": "h0Hghm_8g-DH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It would be a good practice, as suggested by Daniel himself, to see/test a 1-dimensional convolutional layer (temporal layer) before building a full 1-dimesional CNN model for which we will only need a single sentence rather than a full dataset."
      ],
      "metadata": {
        "id": "lKVpXuYThZ54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out the embedding, 1D convolutional and max pooling\n",
        "\n",
        "embedding_test = embedding(text_vectorizer([\"There is a flood in my street!\"]))\n",
        "\n",
        "# Detect local n-gram patterns (like phrases of 5 words) in the embedding sequence.\n",
        "conv_1d = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")\n",
        "conv_1d_output = conv_1d(embedding_test) # pass embedding through 1D convolutional layer\n",
        "\n",
        "# Downsample and extract the most important feature from each filter.\n",
        "max_pool = layers.GlobalMaxPool1D()\n",
        "max_pool_output = max_pool(conv_1d_output) # get the most important features\n",
        "\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKLCHdgNebbf",
        "outputId": "e1be1b3e-96ef-4319-aeba-0b1f8f367779"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As before, the embedding has an output shape dimension of the parameters decided by us (`input_length=15` and `output_dim=128`)."
      ],
      "metadata": {
        "id": "k9ME1My2s7Jp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation on the previous code block:\n",
        "\n",
        "**1. Embedding Phase**\n",
        "```\n",
        "embedding_test = embedding(text_vectorizer([\"There is a flood in my street!\"]))\n",
        "```\n",
        "- text_vectorizer: Converts raw text to a sequence of integer tokens.\n",
        "- embedding: Maps those tokens to dense vectors (e.g., 128-dimensional vectors per token).\n",
        "- Resulting embedding_test shape is likely: `(1, sequence_length, embedding_dim)` ‚Äî a 3D tensor."
      ],
      "metadata": {
        "id": "sMfng67Rrc98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. 1D Convolution Phase\n",
        "```\n",
        "conv_1d = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")\n",
        "conv_1d_output = conv_1d(embedding_test)\n",
        "```"
      ],
      "metadata": {
        "id": "_nl-5NSEsC-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Purpose:** Detect local n-gram patterns (like phrases of 5 words) in the embedding sequence.\n",
        "\n",
        "- `kernel_size=5`: The \"window\" size sliding across the sequence ‚Äî captures 5-word features.\n",
        "- `filters=32`: Learns 32 unique patterns (feature maps).\n",
        "- `activation='relu'`: Introduces non-linearity, helping model complex patterns.\n",
        "- **Output shape becomes:** (1, new_sequence_length, 32)"
      ],
      "metadata": {
        "id": "axz43n-CsNUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# See the outputs of each layer\n",
        "embedding_test[:1], conv_1d_output[:1], max_pool_output[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkD_6ZxWjVZf",
        "outputId": "6255512e-5ab7-4ec6-f78a-ee428fd041d0"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              " array([[[-0.067531  , -0.0942602 , -0.05811977, ...,  0.04177343,\n",
              "           0.01639797,  0.02691073],\n",
              "         [-0.00724583,  0.02223225, -0.03798582, ...,  0.01873329,\n",
              "           0.04067542,  0.01779009],\n",
              "         [-0.01364749,  0.01614984,  0.00385709, ...,  0.03777356,\n",
              "          -0.02009601, -0.0093325 ],\n",
              "         ...,\n",
              "         [ 0.01675929, -0.01866265, -0.01172006, ...,  0.00767409,\n",
              "           0.04422944,  0.0468277 ],\n",
              "         [ 0.01675929, -0.01866265, -0.01172006, ...,  0.00767409,\n",
              "           0.04422944,  0.0468277 ],\n",
              "         [ 0.01675929, -0.01866265, -0.01172006, ...,  0.00767409,\n",
              "           0.04422944,  0.0468277 ]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 11, 32), dtype=float32, numpy=\n",
              " array([[[0.03691543, 0.        , 0.09772582, 0.        , 0.        ,\n",
              "          0.        , 0.        , 0.05979717, 0.22034499, 0.        ,\n",
              "          0.        , 0.        , 0.12757385, 0.        , 0.05357994,\n",
              "          0.07474877, 0.00961921, 0.09703878, 0.00599404, 0.        ,\n",
              "          0.        , 0.        , 0.11436655, 0.08370298, 0.14648645,\n",
              "          0.05584553, 0.        , 0.        , 0.1014013 , 0.09090932,\n",
              "          0.01062986, 0.        ],\n",
              "         [0.00082929, 0.17493607, 0.        , 0.        , 0.12498618,\n",
              "          0.00590327, 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.        , 0.0471484 , 0.16131125, 0.09070493, 0.        ,\n",
              "          0.        , 0.        , 0.05137086, 0.02938335, 0.        ,\n",
              "          0.00276041, 0.06165076, 0.        , 0.        , 0.04908223,\n",
              "          0.03872577, 0.        , 0.        , 0.10904083, 0.00247027,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.05372851, 0.08261853, 0.21245451,\n",
              "          0.        , 0.0506245 , 0.22603151, 0.06016207, 0.33676785,\n",
              "          0.        , 0.17965499, 0.11274925, 0.15518698, 0.        ,\n",
              "          0.        , 0.        , 0.        , 0.15194668, 0.24672839,\n",
              "          0.        , 0.12563162, 0.        , 0.05720868, 0.02110312,\n",
              "          0.        , 0.        , 0.0136467 , 0.05198727, 0.        ,\n",
              "          0.18833824, 0.06468508],\n",
              "         [0.15132944, 0.06219361, 0.08154699, 0.10471743, 0.        ,\n",
              "          0.        , 0.        , 0.04288257, 0.24432103, 0.        ,\n",
              "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.24880132, 0.        , 0.        , 0.22973105, 0.04371893,\n",
              "          0.01763021, 0.        , 0.3051732 , 0.        , 0.12783827,\n",
              "          0.3079784 , 0.10207006, 0.05001   , 0.        , 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.16478644, 0.        , 0.        , 0.12446897,\n",
              "          0.        , 0.        , 0.        , 0.        , 0.04139908,\n",
              "          0.13705024, 0.09005347, 0.03732495, 0.        , 0.1151292 ,\n",
              "          0.        , 0.        , 0.        , 0.09332687, 0.        ,\n",
              "          0.02858899, 0.04942027, 0.        , 0.        , 0.0646842 ,\n",
              "          0.06778564, 0.08879541, 0.0370077 , 0.        , 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.04824762, 0.10812932, 0.        , 0.        ,\n",
              "          0.08118073, 0.        , 0.09872236, 0.08435198, 0.04352904,\n",
              "          0.        , 0.        , 0.04660659, 0.03105292, 0.        ,\n",
              "          0.09956346, 0.        , 0.        , 0.        , 0.11922493,\n",
              "          0.0238171 , 0.02497274, 0.        , 0.        , 0.        ,\n",
              "          0.        , 0.        , 0.        , 0.01266015, 0.04545894,\n",
              "          0.09248727, 0.01486459],\n",
              "         [0.10119165, 0.08348484, 0.02989363, 0.1529312 , 0.        ,\n",
              "          0.00065585, 0.        , 0.        , 0.02090868, 0.        ,\n",
              "          0.10985328, 0.        , 0.        , 0.        , 0.01514422,\n",
              "          0.07436796, 0.        , 0.        , 0.06615153, 0.        ,\n",
              "          0.0520729 , 0.00324663, 0.12666094, 0.        , 0.03808872,\n",
              "          0.14934132, 0.13694996, 0.06845999, 0.        , 0.        ,\n",
              "          0.00920875, 0.        ],\n",
              "         [0.        , 0.04237333, 0.05484655, 0.        , 0.        ,\n",
              "          0.05397878, 0.        , 0.        , 0.        , 0.0448524 ,\n",
              "          0.03531891, 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.04663172, 0.        , 0.03075122, 0.        , 0.        ,\n",
              "          0.00177933, 0.        , 0.        , 0.00329927, 0.        ,\n",
              "          0.        , 0.01063531, 0.        , 0.        , 0.0237326 ,\n",
              "          0.02205611, 0.        ],\n",
              "         [0.        , 0.04237333, 0.05484655, 0.        , 0.        ,\n",
              "          0.05397878, 0.        , 0.        , 0.        , 0.0448524 ,\n",
              "          0.03531891, 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.04663172, 0.        , 0.03075122, 0.        , 0.        ,\n",
              "          0.00177933, 0.        , 0.        , 0.00329927, 0.        ,\n",
              "          0.        , 0.01063531, 0.        , 0.        , 0.0237326 ,\n",
              "          0.02205611, 0.        ],\n",
              "         [0.        , 0.04237333, 0.05484655, 0.        , 0.        ,\n",
              "          0.05397878, 0.        , 0.        , 0.        , 0.0448524 ,\n",
              "          0.03531891, 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.04663172, 0.        , 0.03075122, 0.        , 0.        ,\n",
              "          0.00177933, 0.        , 0.        , 0.00329927, 0.        ,\n",
              "          0.        , 0.01063531, 0.        , 0.        , 0.0237326 ,\n",
              "          0.02205611, 0.        ],\n",
              "         [0.        , 0.04237333, 0.05484655, 0.        , 0.        ,\n",
              "          0.05397878, 0.        , 0.        , 0.        , 0.0448524 ,\n",
              "          0.03531891, 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.04663172, 0.        , 0.03075122, 0.        , 0.        ,\n",
              "          0.00177933, 0.        , 0.        , 0.00329927, 0.        ,\n",
              "          0.        , 0.01063531, 0.        , 0.        , 0.0237326 ,\n",
              "          0.02205611, 0.        ]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
              " array([[0.15132944, 0.17493607, 0.10812932, 0.1529312 , 0.21245451,\n",
              "         0.08118073, 0.0506245 , 0.22603151, 0.24432103, 0.33676785,\n",
              "         0.13705024, 0.17965499, 0.16131125, 0.15518698, 0.1151292 ,\n",
              "         0.24880132, 0.00961921, 0.09703878, 0.22973105, 0.24672839,\n",
              "         0.0520729 , 0.12563162, 0.3051732 , 0.08370298, 0.14648645,\n",
              "         0.3079784 , 0.13694996, 0.06845999, 0.10904083, 0.09090932,\n",
              "         0.18833824, 0.06468508]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the seed and crate a new embedding layer (already motivated)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model5_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_5\")"
      ],
      "metadata": {
        "id": "C-hXr7RgshDd"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 1-dimensional convolutional layer\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model5_embedding(x)\n",
        "x = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")"
      ],
      "metadata": {
        "id": "Th4HMvjfuGIU"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile Conv1D model\n",
        "model5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "nOXNjurou6XX"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the summary\n",
        "model5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDDocGY9u9nC",
        "outputId": "8810b20e-79e4-4248-a2e7-012dd689d8f6"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVe  (None, 15)                0         \n",
            " ctorization)                                                    \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 11, 32)            20512     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Gl  (None, 32)                0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1300545 (4.96 MB)\n",
            "Trainable params: 1300545 (4.96 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model5_history = model5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"Conv1D\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ib1JsCV3vCg6",
        "outputId": "45c6ed2c-5f40-4329-b8bf-301d3f79e876"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/Conv1D/20250510-215132\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 22ms/step - loss: 0.5606 - accuracy: 0.7241 - val_loss: 0.4696 - val_accuracy: 0.7835\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 5s 25ms/step - loss: 0.3386 - accuracy: 0.8647 - val_loss: 0.4719 - val_accuracy: 0.7861\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.2109 - accuracy: 0.9225 - val_loss: 0.5281 - val_accuracy: 0.7835\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 5s 22ms/step - loss: 0.1342 - accuracy: 0.9566 - val_loss: 0.6048 - val_accuracy: 0.7769\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 5s 23ms/step - loss: 0.0927 - accuracy: 0.9696 - val_loss: 0.6483 - val_accuracy: 0.7900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test/validation data\n",
        "model5_pred_probs = model5.predict(val_sentences)\n",
        "model5_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3CzXM3uvRAn",
        "outputId": "4f96b271-d9ec-4c5c-f65f-561f6dc99dd7"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.53222036],\n",
              "       [0.86132085],\n",
              "       [0.99990755],\n",
              "       [0.06678511],\n",
              "       [0.00652243],\n",
              "       [0.99338216],\n",
              "       [0.8991505 ],\n",
              "       [0.99783653],\n",
              "       [0.99990207],\n",
              "       [0.07208823]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn prediction probabilities into prediction classes\n",
        "model5_preds = tf.squeeze(tf.round(model5_pred_probs))\n",
        "model5_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0t2RJlAwosz",
        "outputId": "9f125f11-246a-46ec-9016-dee41735e081"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model 5 results\n",
        "model5_results = compute_results(y_true=val_labels,\n",
        "                                    y_pred=model5_preds)\n",
        "model5_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRUMxLupw6n3",
        "outputId": "431246a5-d411-49e7-c819-f541ec7f3a7b"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.00262467191601,\n",
              " 'precision': 0.7955103864713003,\n",
              " 'recall': 0.7900262467191601,\n",
              " 'f1score': 0.7869273549752186}"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare results\n",
        "compare_models(baseline_results, model5_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1gWCv-pxIpL",
        "outputId": "e3836da4-7f1b-4dc8-a44b-382e76fbcb81"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New Model accuracy: 79.00, Difference: -0.26\n",
            "Baseline precision: 0.81, New Model precision: 0.80, Difference: -0.02\n",
            "Baseline recall: 0.79, New Model recall: 0.79, Difference: -0.00\n",
            "Baseline f1score: 0.79, New Model f1score: 0.79, Difference: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Pretrained Embeddings (Transfer Learning)"
      ],
      "metadata": {
        "id": "LvyCo8hF2Enp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Previously, we have been creating our own embeddings during training different various models. However, there is also a common practice among domain experts where pretrained embedding are leveraged through **Transfer Learning**."
      ],
      "metadata": {
        "id": "0n3yCvh92Kea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 6: TensorFlow Hub Pretrained Sentence Encoder"
      ],
      "metadata": {
        "id": "3BL1iec11-hF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of converting each individual word into a separate vector (as is done with models like Word2Vec or GloVe), the Universal Sentence Encoder (USE) produces a single vector that represents the entire sentence as a unit."
      ],
      "metadata": {
        "id": "eRy1uEPU4TX-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### üîç Why is this important?\n",
        "\n",
        "Sentence-level context: The embedding captures not just the words, but also their meaning in context, including word order and interactions.\n",
        "\n",
        "Fixed-size output: Regardless of whether the sentence is \"Hello\" or \"The flood destroyed everything in our neighborhood last night,\" the encoder outputs a fixed-size vector (e.g., 512-dimensional).\n",
        "\n",
        "Useful for:\n",
        "\n",
        "- Semantic similarity comparisons between sentences\n",
        "- Sentence-level classification tasks (e.g., sentiment, intent)\n",
        "- Clustering and retrieval tasks"
      ],
      "metadata": {
        "id": "fqsbrXTR4rrT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### üß† A simple analogy:\n",
        "\n",
        "If word embeddings are like understanding the meaning of individual ingredients, sentence embeddings are like grasping the flavor of the whole dish‚Äîyou capture the combination and interactions."
      ],
      "metadata": {
        "id": "kist9-yg6-83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of pretrained embedding with Universal Sentence Encoder - https://tfhub.dev/google/universal-sentence-encoder/4\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# Load Universal Sentence Encoder\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "\n",
        "# Embed a sample sentence as a whole\n",
        "embed_samples = embed([sample_sentence,\n",
        "                      \"Calling Universal Sentence Encoder on a sentence, it turns the sentence into numbers.\",\n",
        "                       \"Mi chiamo Milad. Io vengo dall'iran. Io abito a Torino da quatro anni.\"])\n",
        "\n",
        "print(embed_samples[0][:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1aHmpKI0UrV",
        "outputId": "1f96b7a0-cbc1-46fc-bdd5-319bc0364bc5"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.01602833  0.01068851  0.02425468 -0.01405769  0.01434425  0.08292627\n",
            "  0.01963371  0.06160141 -0.00352699 -0.01216413  0.00978648 -0.01248495\n",
            "  0.01232345  0.09748451  0.06141113 -0.03728356  0.01860886 -0.04669855\n",
            "  0.00413911 -0.06363906 -0.02469901  0.02713689  0.02284444 -0.00210026\n",
            " -0.00630594 -0.03964961  0.02220404  0.00115079 -0.03132175  0.00119525\n",
            " -0.0401255   0.04561893 -0.015306   -0.00175918  0.02173131 -0.08450424\n",
            "  0.03340026  0.0460455  -0.02480252 -0.08681665  0.00702694 -0.0077048\n",
            " -0.01434538  0.07814164 -0.10676058 -0.05152993 -0.00858158 -0.03232231\n",
            " -0.03871096  0.02581467], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Each sentence has been encoded into a 512 dimension vector\n",
        "embed_samples[0].shape, embed_samples[1].shape, embed_samples[2].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qNIb9s877bW",
        "outputId": "16ef4df6-18d3-4ab9-983f-cb4199819114"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([512]), TensorShape([512]), TensorShape([512]))"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, you understood correctly! \\\\\n",
        "All sentences passed to Universal Sentence Encoder are encoded from strings to 512 dimensional vectors."
      ],
      "metadata": {
        "id": "ALaXWIpaFPE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can use this encoding layer in place of our text_vectorizer and embedding layer\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[], # shape of inputs coming to our model\n",
        "                                        dtype=tf.string, # data type of inputs coming to the USE layer\n",
        "                                        trainable=False, # keep the pretrained weights (we'll create a feature extractor)\n",
        "                                        name=\"USE\")"
      ],
      "metadata": {
        "id": "IIru9BC8EcXO"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model using the Sequential API\n",
        "model6 = tf.keras.Sequential([\n",
        "  sentence_encoder_layer, # take in sentences and then encode them into an embedding\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(1, activation=\"sigmoid\")\n",
        "], name=\"model_6_USE\")"
      ],
      "metadata": {
        "id": "WEHXIMNmF3bl"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "t2pj1ehvGGd_"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTyuswyjGIcu",
        "outputId": "34e5fe22-e664-4659-d279-05abe14adf30"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256830721 (979.73 MB)\n",
            "Trainable params: 32897 (128.50 KB)\n",
            "Non-trainable params: 256797824 (979.61 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a classifier on top of pretrained embeddings\n",
        "model6_history = model6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"tf_hub_sentence_encoder\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XCZCz1GGMvu",
        "outputId": "60109a3d-27d4-464d-a683-7205404597cc"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20250510-215329\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 14s 28ms/step - loss: 0.5057 - accuracy: 0.7856 - val_loss: 0.4489 - val_accuracy: 0.8005\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 5s 23ms/step - loss: 0.4158 - accuracy: 0.8143 - val_loss: 0.4379 - val_accuracy: 0.8110\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.4015 - accuracy: 0.8203 - val_loss: 0.4338 - val_accuracy: 0.8097\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.3948 - accuracy: 0.8254 - val_loss: 0.4292 - val_accuracy: 0.8123\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.3891 - accuracy: 0.8270 - val_loss: 0.4305 - val_accuracy: 0.8150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with USE TF Hub model\n",
        "model6_pred_probs = model6.predict(val_sentences)\n",
        "model6_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IjGBKtQMF7e",
        "outputId": "e5b60719-5f98-4f58-b9d6-0e404af811a0"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 2s 28ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.15790224],\n",
              "       [0.7427377 ],\n",
              "       [0.98272204],\n",
              "       [0.19397716],\n",
              "       [0.7443394 ],\n",
              "       [0.6689887 ],\n",
              "       [0.9782104 ],\n",
              "       [0.9742464 ],\n",
              "       [0.9154632 ],\n",
              "       [0.08346344]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn prediction probabilities into prediction classes\n",
        "model6_preds = tf.squeeze(tf.round(model6_pred_probs))\n",
        "model6_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOSxEJaUMfaB",
        "outputId": "da5fc824-3f2d-48d6-fda3-70ec2a7f5b7a"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model 6 performance metrics\n",
        "model6_results = compute_results(val_labels, model6_preds)\n",
        "model6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2e4SvVIMSi9",
        "outputId": "458df965-e1b7-4a7a-e6f4-05d04fb8e3ae"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.49606299212599,\n",
              " 'precision': 0.8172549323109193,\n",
              " 'recall': 0.8149606299212598,\n",
              " 'f1score': 0.8134357776936025}"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare TF Hub model to baseline\n",
        "compare_models(baseline_results, model6_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kx4GzAJLMYfF",
        "outputId": "9b6a55c7-ee39-4f4d-cfae-36e4df4368bb"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New Model accuracy: 81.50, Difference: 2.23\n",
            "Baseline precision: 0.81, New Model precision: 0.82, Difference: 0.01\n",
            "Baseline recall: 0.79, New Model recall: 0.81, Difference: 0.02\n",
            "Baseline f1score: 0.79, New Model f1score: 0.81, Difference: 0.03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4DxF2vO0Mxd9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}